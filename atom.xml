<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Woody</title>
  
  
  <link href="http://woody0819.github.io/atom.xml" rel="self"/>
  
  <link href="http://woody0819.github.io/"/>
  <updated>2021-08-20T07:28:49.458Z</updated>
  <id>http://woody0819.github.io/</id>
  
  <author>
    <name>Woody</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Telco Customer Churn</title>
    <link href="http://woody0819.github.io/2021/08/20/Telco%20Customer%20Churn/"/>
    <id>http://woody0819.github.io/2021/08/20/Telco%20Customer%20Churn/</id>
    <published>2021-08-19T17:00:48.955Z</published>
    <updated>2021-08-20T07:28:49.458Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Telcom-Customer-Churn"><a href="#Telcom-Customer-Churn" class="headerlink" title="Telcom Customer Churn"></a><strong>Telcom Customer Churn</strong></h1><p>每行代表一个客户每列是一个特征，原始数据包含 7043 行 21 列. “Churn” 是标签.</p><ul><li><p><strong>customerID</strong> : 客户 ID</p></li><li><p><strong>gender</strong> : 客户性别</p></li><li><p><strong>SeniorCitizen</strong> : 用户是否退休 (1, 0)</p></li><li><p><strong>Partner</strong> : 客户是否有合作伙伴 (Yes, No)</p></li><li><p><strong>Dependents</strong> : 客户是否有家属 (Yes, No)</p></li><li><p><strong>tenure</strong> : 客户留存月数</p></li><li><p><strong>PhoneService</strong> : 客户是否有电话服务 (Yes, No)</p></li><li><p><strong>MultipleLines</strong> : 客户是否有多条线路 (Yes, No, No phone service)</p></li><li><p><strong>InternetService</strong> : 客户网络服务提供商 (DSL, Fiber optic, No)</p></li><li><p><strong>OnlineSecurity</strong> : 客户是否有在线安全 (Yes, No, No internet service)</p></li><li><p><strong>OnlineBackup</strong> : 客户是否有在线备份 (Yes, No, No internet service)</p></li><li><p><strong>DeviceProtection</strong> : 客户是否有设备保护 (Yes, No, No internet service)</p></li><li><p><strong>TechSupport</strong> : 客户是否有技术支持 (Yes, No, No internet service)</p></li><li><p><strong>StreamingTV</strong> : 客户是否有流媒体电视 (Yes, No, No internet service)</p></li><li><p><strong>StreamingMovies</strong> : 客户是否有流媒体电影 (Yes, No, No internet service)</p></li><li><p><strong>Contract</strong> : 客户合同期限 (Month-to-month, One year, Two year)</p></li><li><p><strong>PaperlessBilling</strong> : 客户是否有无纸化计费 (Yes, No)</p></li><li><p><strong>PaymentMethod</strong> : 客户付款方式 (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))</p></li><li><p><strong>MonthlyCharges</strong> : 客户月付金额</p></li><li><p><strong>TotalCharges</strong> : 客户付款总金额</p></li><li><p><strong>Churn</strong> : 客户是否流失 (Yes or No)</p></li></ul><span id="more"></span><ul><li><ol><li>Load libraries and read the data</li></ol><ul><li><p>1.1. Load libraries</p></li><li><p>1.2. Read the data</p></li><li><p>1.3. Head, describe, shape and info</p></li><li><p>1.4. Reassign target, encode variables and replace missing values</p></li></ul></li><li><ol start="2"><li>Exploratory Data Analysis (EDA)</li></ol><ul><li><p>2.1. Target distribution (number and %)</p></li><li><p>2.2. Numeric features : Seaborn</p></li><li><p>2.3. Numeric features : Correlation</p></li><li><p>2.4. Object features : Seaborn </p></li></ul></li><li><ol start="3"><li>Feature engineering and selection</li></ol><ul><li><p>3.1. New features</p></li><li><p>3.2. Drop some features</p></li><li><p>3.3. Features encoding and scaling</p></li><li><p>3.4. Correlation Matrix</p></li><li><p>3.5. Remove collinear features</p></li></ul></li><li><ol start="4"><li>Prepare dataset and stylized report</li></ol><ul><li><p>4.1. Define (X,  y)</p></li><li><p>4.2. Train test split</p></li><li><p>4.3. Stylized report with sns (confusion matrix, roc, precision-recall, etc…)</p></li><li><p>4.4. Define cross validation metrics</p></li></ul></li><li><ol start="5"><li>Light GBM Model</li></ol><ul><li><p>5.1. LightGBM - Before RandomizedSearchCV</p></li><li><p>5.2. LightGBM - RandomizedSearchCV to optimise hyperparameters  (1000 fits)</p></li><li><p>5.3. LightGBM - After RandomizedSearchCV</p></li><li><p>5.4. LightGBM – Cross validation (5 folds)</p></li></ul></li></ul><h1 id="1-Load-libraries-and-read-the-data"><a href="#1-Load-libraries-and-read-the-data" class="headerlink" title="1. Load libraries and read the data"></a>1. Load libraries and read the data</h1><h2 id="1-1-Load-libraries"><a href="#1-1-Load-libraries" class="headerlink" title="1.1. Load libraries"></a>1.1. Load libraries</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> mtick</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scipy.stats <span class="keyword">as</span> ss</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc, precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score, roc_auc_score, classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgbm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> randint <span class="keyword">as</span> sp_randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> uniform <span class="keyword">as</span> sp_uniform</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>) <span class="comment">#ignore warning messages </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> contextmanager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@contextmanager</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timer</span>(<span class="params">title</span>):</span></span><br><span class="line"></span><br><span class="line">    t0 = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">yield</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; - done in &#123;:.0f&#125;s&quot;</span>.<span class="built_in">format</span>(title, time.time() - t0))</span><br></pre></td></tr></table></figure><h2 id="1-2-Read-the-data"><a href="#1-2-Read-the-data" class="headerlink" title="1.2. Read the data"></a>1.2. Read the data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">r&quot;./dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="1-3-Head-describe-shape-and-info"><a href="#1-3-Head-describe-shape-and-info" class="headerlink" title="1.3. Head, describe, shape and info"></a>1.3. Head, describe, shape and info</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">display(data.head())</span><br><span class="line"></span><br><span class="line">display(data.describe())</span><br><span class="line"></span><br><span class="line">display(data.shape)</span><br><span class="line"></span><br><span class="line">display(data.info())</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>customerID</th>      <th>gender</th>      <th>SeniorCitizen</th>      <th>Partner</th>      <th>Dependents</th>      <th>tenure</th>      <th>PhoneService</th>      <th>MultipleLines</th>      <th>InternetService</th>      <th>OnlineSecurity</th>      <th>...</th>      <th>DeviceProtection</th>      <th>TechSupport</th>      <th>StreamingTV</th>      <th>StreamingMovies</th>      <th>Contract</th>      <th>PaperlessBilling</th>      <th>PaymentMethod</th>      <th>MonthlyCharges</th>      <th>TotalCharges</th>      <th>Churn</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>7590-VHVEG</td>      <td>Female</td>      <td>0</td>      <td>Yes</td>      <td>No</td>      <td>1</td>      <td>No</td>      <td>No phone service</td>      <td>DSL</td>      <td>No</td>      <td>...</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>Month-to-month</td>      <td>Yes</td>      <td>Electronic check</td>      <td>29.85</td>      <td>29.85</td>      <td>No</td>    </tr>    <tr>      <th>1</th>      <td>5575-GNVDE</td>      <td>Male</td>      <td>0</td>      <td>No</td>      <td>No</td>      <td>34</td>      <td>Yes</td>      <td>No</td>      <td>DSL</td>      <td>Yes</td>      <td>...</td>      <td>Yes</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>One year</td>      <td>No</td>      <td>Mailed check</td>      <td>56.95</td>      <td>1889.5</td>      <td>No</td>    </tr>    <tr>      <th>2</th>      <td>3668-QPYBK</td>      <td>Male</td>      <td>0</td>      <td>No</td>      <td>No</td>      <td>2</td>      <td>Yes</td>      <td>No</td>      <td>DSL</td>      <td>Yes</td>      <td>...</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>Month-to-month</td>      <td>Yes</td>      <td>Mailed check</td>      <td>53.85</td>      <td>108.15</td>      <td>Yes</td>    </tr>    <tr>      <th>3</th>      <td>7795-CFOCW</td>      <td>Male</td>      <td>0</td>      <td>No</td>      <td>No</td>      <td>45</td>      <td>No</td>      <td>No phone service</td>      <td>DSL</td>      <td>Yes</td>      <td>...</td>      <td>Yes</td>      <td>Yes</td>      <td>No</td>      <td>No</td>      <td>One year</td>      <td>No</td>      <td>Bank transfer (automatic)</td>      <td>42.30</td>      <td>1840.75</td>      <td>No</td>    </tr>    <tr>      <th>4</th>      <td>9237-HQITU</td>      <td>Female</td>      <td>0</td>      <td>No</td>      <td>No</td>      <td>2</td>      <td>Yes</td>      <td>No</td>      <td>Fiber optic</td>      <td>No</td>      <td>...</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>No</td>      <td>Month-to-month</td>      <td>Yes</td>      <td>Electronic check</td>      <td>70.70</td>      <td>151.65</td>      <td>Yes</td>    </tr>  </tbody></table><p>5 rows × 21 columns</p></div><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>SeniorCitizen</th>      <th>tenure</th>      <th>MonthlyCharges</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>7043.000000</td>      <td>7043.000000</td>      <td>7043.000000</td>    </tr>    <tr>      <th>mean</th>      <td>0.162147</td>      <td>32.371149</td>      <td>64.761692</td>    </tr>    <tr>      <th>std</th>      <td>0.368612</td>      <td>24.559481</td>      <td>30.090047</td>    </tr>    <tr>      <th>min</th>      <td>0.000000</td>      <td>0.000000</td>      <td>18.250000</td>    </tr>    <tr>      <th>25%</th>      <td>0.000000</td>      <td>9.000000</td>      <td>35.500000</td>    </tr>    <tr>      <th>50%</th>      <td>0.000000</td>      <td>29.000000</td>      <td>70.350000</td>    </tr>    <tr>      <th>75%</th>      <td>0.000000</td>      <td>55.000000</td>      <td>89.850000</td>    </tr>    <tr>      <th>max</th>      <td>1.000000</td>      <td>72.000000</td>      <td>118.750000</td>    </tr>  </tbody></table></div><pre><code>(7043, 21)&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 7043 entries, 0 to 7042Data columns (total 21 columns): #   Column            Non-Null Count  Dtype  ---  ------            --------------  -----   0   customerID        7043 non-null   object  1   gender            7043 non-null   object  2   SeniorCitizen     7043 non-null   int64   3   Partner           7043 non-null   object  4   Dependents        7043 non-null   object  5   tenure            7043 non-null   int64   6   PhoneService      7043 non-null   object  7   MultipleLines     7043 non-null   object  8   InternetService   7043 non-null   object  9   OnlineSecurity    7043 non-null   object  10  OnlineBackup      7043 non-null   object  11  DeviceProtection  7043 non-null   object  12  TechSupport       7043 non-null   object  13  StreamingTV       7043 non-null   object  14  StreamingMovies   7043 non-null   object  15  Contract          7043 non-null   object  16  PaperlessBilling  7043 non-null   object  17  PaymentMethod     7043 non-null   object  18  MonthlyCharges    7043 non-null   float64 19  TotalCharges      7043 non-null   object  20  Churn             7043 non-null   object dtypes: float64(1), int64(2), object(18)memory usage: 1.1+ MBNone</code></pre><h2 id="1-4-Reassign-target-encode-variables-and-replace-missing-values"><a href="#1-4-Reassign-target-encode-variables-and-replace-missing-values" class="headerlink" title="1.4. Reassign target, encode variables and replace missing values"></a>1.4. Reassign target, encode variables and replace missing values</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reassign target 将是否替换为0，1</span></span><br><span class="line"></span><br><span class="line">data.Churn.replace(to_replace = <span class="built_in">dict</span>(Yes = <span class="number">1</span>, No = <span class="number">0</span>), inplace = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Encode as object 将指示位替换为对象类型</span></span><br><span class="line"></span><br><span class="line">col_name = [<span class="string">&#x27;SeniorCitizen&#x27;</span>, <span class="string">&#x27;Churn&#x27;</span>]</span><br><span class="line"></span><br><span class="line">data[col_name] = data[col_name].astype(<span class="built_in">object</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Encode as float 将钱数替换为float类型</span></span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;TotalCharges&#x27;</span>] = data[<span class="string">&#x27;TotalCharges&#x27;</span>].replace(<span class="string">&quot; &quot;</span>, <span class="number">0</span>).astype(<span class="string">&#x27;float64&#x27;</span>)</span><br></pre></td></tr></table></figure><h1 id="2-Exploratory-Data-Analysis-EDA"><a href="#2-Exploratory-Data-Analysis-EDA" class="headerlink" title="2. Exploratory Data Analysis (EDA)"></a>2. Exploratory Data Analysis (EDA)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">churn = data[(data[<span class="string">&#x27;Churn&#x27;</span>] != <span class="number">0</span>)]      <span class="comment"># 取流失的客户全部数据</span></span><br><span class="line"></span><br><span class="line">no_churn = data[(data[<span class="string">&#x27;Churn&#x27;</span>] == <span class="number">0</span>)]   <span class="comment"># 取留存的客户全部数据</span></span><br></pre></td></tr></table></figure><h2 id="2-1-Target-distribution-number-and"><a href="#2-1-Target-distribution-number-and" class="headerlink" title="2.1. Target distribution (number and %)"></a>2.1. Target distribution (number and %)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ax = sns.catplot(y=<span class="string">&quot;Churn&quot;</span>, kind=<span class="string">&quot;count&quot;</span>, data=data, height=<span class="number">2.6</span>, aspect=<span class="number">2.5</span>, palette =&#123;<span class="number">0</span> : <span class="string">&#x27;lightblue&#x27;</span>, <span class="number">1</span> : <span class="string">&#x27;gold&#x27;</span>&#125;, orient=<span class="string">&#x27;h&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fLpqKK"><img src="https://z3.ax1x.com/2021/08/20/fLpqKK.png" alt="fLpqKK.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ax = (data[<span class="string">&#x27;Churn&#x27;</span>].value_counts()*<span class="number">100.0</span> /<span class="built_in">len</span>(data))\</span><br><span class="line"></span><br><span class="line">.plot.pie(autopct=<span class="string">&#x27;%.1f%%&#x27;</span>, labels = [<span class="string">&#x27;No&#x27;</span>, <span class="string">&#x27;Yes&#x27;</span>],figsize =(<span class="number">5</span>,<span class="number">5</span>), colors=[<span class="string">&#x27;lightblue&#x27;</span>, <span class="string">&#x27;gold&#x27;</span>], fontsize = <span class="number">12</span>)                                                                           </span><br><span class="line"></span><br><span class="line">ax.yaxis.set_major_formatter(mtick.PercentFormatter())</span><br><span class="line"></span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Churn&#x27;</span>,fontsize = <span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">&#x27;% of Churn&#x27;</span>, fontsize = <span class="number">12</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 1.0, &#39;% of Churn&#39;)</code></pre><p><a href="https://imgtu.com/i/fLpLDO"><img src="https://z3.ax1x.com/2021/08/20/fLpLDO.png" alt="fLpLDO.png"></a></p><h2 id="2-2-Numeric-features-Seaborn"><a href="#2-2-Numeric-features-Seaborn" class="headerlink" title="2.2. Numeric features : Seaborn"></a>2.2. Numeric features : Seaborn</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_distribution_num</span>(<span class="params">data_select</span>) :</span> </span><br><span class="line"></span><br><span class="line">    sns.set_style(<span class="string">&quot;ticks&quot;</span>)</span><br><span class="line"></span><br><span class="line">    s = sns.FacetGrid(data, hue = <span class="string">&#x27;Churn&#x27;</span>,aspect = <span class="number">2.5</span>, palette =&#123;<span class="number">0</span> : <span class="string">&#x27;lightblue&#x27;</span>, <span class="number">1</span> : <span class="string">&#x27;gold&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">    s.<span class="built_in">map</span>(sns.kdeplot, data_select, shade = <span class="literal">False</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">    s.<span class="built_in">set</span>(xlim=(<span class="number">0</span>, data[data_select].<span class="built_in">max</span>()))</span><br><span class="line"></span><br><span class="line">    s.add_legend()</span><br><span class="line"></span><br><span class="line">    s.set_axis_labels(data_select, <span class="string">&#x27;proportion&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    s.fig.suptitle(data_select)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">plot_distribution_num(<span class="string">&#x27;tenure&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plot_distribution_num(<span class="string">&#x27;MonthlyCharges&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plot_distribution_num(<span class="string">&#x27;TotalCharges&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fLpvUH"><img src="https://z3.ax1x.com/2021/08/20/fLpvUH.png" alt="fLpvUH.png"></a></p><p><a href="https://imgtu.com/i/fLpjVe"><img src="https://z3.ax1x.com/2021/08/20/fLpjVe.png" alt="fLpjVe.png"></a></p><p><a href="https://imgtu.com/i/fLpObD"><img src="https://z3.ax1x.com/2021/08/20/fLpObD.png" alt="fLpObD.png"></a></p><h2 id="2-3-Numeric-features-Correlation"><a href="#2-3-Numeric-features-Correlation" class="headerlink" title="2.3. Numeric features : Correlation"></a>2.3. Numeric features : Correlation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">df_quant = data.select_dtypes(exclude=[<span class="built_in">object</span>])</span><br><span class="line"></span><br><span class="line">df_quant.head()</span><br><span class="line"></span><br><span class="line">corr_quant = df_quant.corr()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">ax = sns.heatmap(corr_quant, annot=<span class="literal">True</span>, cmap = <span class="string">&#x27;viridis&#x27;</span>, linewidths = <span class="number">.1</span>, linecolor = <span class="string">&#x27;grey&#x27;</span>, fmt=<span class="string">&quot;.2f&quot;</span>)</span><br><span class="line"></span><br><span class="line">ax.invert_yaxis()</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">&quot;Correlation&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fLpx5d"><img src="https://z3.ax1x.com/2021/08/20/fLpx5d.png" alt="fLpx5d.png"></a></p><h2 id="2-4-Object-features-Seaborn"><a href="#2-4-Object-features-Seaborn" class="headerlink" title="2.4. Object features : Seaborn"></a>2.4. Object features : Seaborn</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_distribution_cat</span>(<span class="params">feature1,feature2, df</span>):</span> </span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">18</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">121</span>)</span><br><span class="line"></span><br><span class="line">    s = sns.countplot(x = feature1, hue=<span class="string">&#x27;Churn&#x27;</span>, data = df, </span><br><span class="line"></span><br><span class="line">                      palette = &#123;<span class="number">0</span> : <span class="string">&#x27;lightblue&#x27;</span>, <span class="number">1</span> :<span class="string">&#x27;gold&#x27;</span>&#125;, alpha = <span class="number">0.8</span>, </span><br><span class="line"></span><br><span class="line">                      linewidth = <span class="number">0.4</span>, edgecolor=<span class="string">&#x27;grey&#x27;</span>) </span><br><span class="line"></span><br><span class="line">    s.set_title(feature1)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> s.patches:</span><br><span class="line"></span><br><span class="line">        s.annotate(<span class="string">&#x27;&#123;:.0f&#125;&#x27;</span>.<span class="built_in">format</span>(p.get_height()), (p.get_x()+<span class="number">0.15</span>, p.get_height()+<span class="number">30</span>))</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">122</span>)</span><br><span class="line"></span><br><span class="line">    s = sns.countplot(x = feature2, hue=<span class="string">&#x27;Churn&#x27;</span>, data = df, </span><br><span class="line"></span><br><span class="line">                      palette = &#123;<span class="number">0</span> : <span class="string">&#x27;lightblue&#x27;</span>, <span class="number">1</span> :<span class="string">&#x27;gold&#x27;</span>&#125;, alpha = <span class="number">0.8</span>, </span><br><span class="line"></span><br><span class="line">                      linewidth = <span class="number">0.4</span>, edgecolor=<span class="string">&#x27;grey&#x27;</span>) </span><br><span class="line"></span><br><span class="line">    s.set_title(feature2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> s.patches:</span><br><span class="line"></span><br><span class="line">        s.annotate(<span class="string">&#x27;&#123;:.0f&#125;&#x27;</span>.<span class="built_in">format</span>(p.get_height()), (p.get_x()+<span class="number">0.15</span>, p.get_height()+<span class="number">30</span>))</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">plot_distribution_cat(<span class="string">&#x27;SeniorCitizen&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">plot_distribution_cat(<span class="string">&#x27;Partner&#x27;</span>, <span class="string">&#x27;Dependents&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">plot_distribution_cat(<span class="string">&#x27;MultipleLines&#x27;</span>, <span class="string">&#x27;InternetService&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">plot_distribution_cat(<span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;TechSupport&#x27;</span>, data)</span><br><span class="line"></span><br><span class="line">plot_distribution_cat(<span class="string">&#x27;DeviceProtection&#x27;</span>, <span class="string">&#x27;StreamingTV&#x27;</span>,data)</span><br><span class="line"></span><br><span class="line">plot_distribution_cat(<span class="string">&#x27;StreamingMovies&#x27;</span>, <span class="string">&#x27;PaperlessBilling&#x27;</span>,data)</span><br><span class="line"></span><br><span class="line">plot_distribution_cat(<span class="string">&#x27;PaymentMethod&#x27;</span>, <span class="string">&#x27;Contract&#x27;</span>,data)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fL9SPA"><img src="https://z3.ax1x.com/2021/08/20/fL9SPA.png" alt="fL9SPA.png"></a></p><p><a href="https://imgtu.com/i/fL9p8I"><img src="https://z3.ax1x.com/2021/08/20/fL9p8I.png" alt="fL9p8I.png"></a></p><p><a href="https://imgtu.com/i/fL992t"><img src="https://z3.ax1x.com/2021/08/20/fL992t.png" alt="fL992t.png"></a></p><p><a href="https://imgtu.com/i/fL9CxP"><img src="https://z3.ax1x.com/2021/08/20/fL9CxP.png" alt="fL9CxP.png"></a></p><p><a href="https://imgtu.com/i/fL9Fr8"><img src="https://z3.ax1x.com/2021/08/20/fL9Fr8.png" alt="fL9Fr8.png"></a></p><p><a href="https://imgtu.com/i/fL9kqS"><img src="https://z3.ax1x.com/2021/08/20/fL9kqS.png" alt="fL9kqS.png"></a></p><p><a href="https://imgtu.com/i/fL9EVg"><img src="https://z3.ax1x.com/2021/08/20/fL9EVg.png" alt="fL9EVg.png"></a></p><h1 id="3-Feature-engineering-and-selection"><a href="#3-Feature-engineering-and-selection" class="headerlink" title="3. Feature engineering and selection"></a>3. Feature engineering and selection</h1><h2 id="3-1-New-features"><a href="#3-1-New-features" class="headerlink" title="3.1. New features"></a>3.1. New features</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">data.loc[:,<span class="string">&#x27;Engaged&#x27;</span>]=<span class="number">1</span> </span><br><span class="line"></span><br><span class="line">data.loc[(data[<span class="string">&#x27;Contract&#x27;</span>]==<span class="string">&#x27;Month-to-month&#x27;</span>),<span class="string">&#x27;Engaged&#x27;</span>]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data.loc[:,<span class="string">&#x27;YandNotE&#x27;</span>]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">data.loc[(data[<span class="string">&#x27;SeniorCitizen&#x27;</span>]==<span class="number">0</span>) &amp; (data[<span class="string">&#x27;Engaged&#x27;</span>]==<span class="number">0</span>),<span class="string">&#x27;YandNotE&#x27;</span>]=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data.loc[:,<span class="string">&#x27;ElectCheck&#x27;</span>]=<span class="number">0</span> </span><br><span class="line"></span><br><span class="line">data.loc[(data[<span class="string">&#x27;PaymentMethod&#x27;</span>]==<span class="string">&#x27;Electronic check&#x27;</span>) &amp; (data[<span class="string">&#x27;Engaged&#x27;</span>]==<span class="number">0</span>),<span class="string">&#x27;ElectCheck&#x27;</span>]=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data.loc[:,<span class="string">&#x27;fiberopt&#x27;</span>]=<span class="number">1</span> </span><br><span class="line"></span><br><span class="line">data.loc[(data[<span class="string">&#x27;InternetService&#x27;</span>]!=<span class="string">&#x27;Fiber optic&#x27;</span>),<span class="string">&#x27;fiberopt&#x27;</span>]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data.loc[:,<span class="string">&#x27;StreamNoInt&#x27;</span>]=<span class="number">1</span> </span><br><span class="line"></span><br><span class="line">data.loc[(data[<span class="string">&#x27;StreamingTV&#x27;</span>]!=<span class="string">&#x27;No internet service&#x27;</span>),<span class="string">&#x27;StreamNoInt&#x27;</span>]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data.loc[:,<span class="string">&#x27;NoProt&#x27;</span>]=<span class="number">1</span> </span><br><span class="line"></span><br><span class="line">data.loc[(data[<span class="string">&#x27;OnlineBackup&#x27;</span>]!=<span class="string">&#x27;No&#x27;</span>) | (data[<span class="string">&#x27;DeviceProtection&#x27;</span>]!=<span class="string">&#x27;No&#x27;</span>) | (data[<span class="string">&#x27;TechSupport&#x27;</span>]!=<span class="string">&#x27;No&#x27;</span>),<span class="string">&#x27;NoProt&#x27;</span>]=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;TotalServices&#x27;</span>] = (data[[<span class="string">&#x27;PhoneService&#x27;</span>, <span class="string">&#x27;InternetService&#x27;</span>, <span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;OnlineBackup&#x27;</span>, <span class="string">&#x27;DeviceProtection&#x27;</span>, <span class="string">&#x27;TechSupport&#x27;</span>, <span class="string">&#x27;StreamingTV&#x27;</span>, <span class="string">&#x27;StreamingMovies&#x27;</span>]]== <span class="string">&#x27;Yes&#x27;</span>).<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对留存月份进行分箱，返回所在箱</span></span><br><span class="line">data[<span class="string">&#x27;tenure&#x27;</span>] = pd.cut(data[<span class="string">&#x27;tenure&#x27;</span>], <span class="number">3</span>)</span><br></pre></td></tr></table></figure><h2 id="3-2-Drop-some-features"><a href="#3-2-Drop-some-features" class="headerlink" title="3.2. Drop some features"></a>3.2. Drop some features</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.columns</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;customerID&#39;, &#39;gender&#39;, &#39;SeniorCitizen&#39;, &#39;Partner&#39;, &#39;Dependents&#39;,       &#39;tenure&#39;, &#39;PhoneService&#39;, &#39;MultipleLines&#39;, &#39;InternetService&#39;,       &#39;OnlineSecurity&#39;, &#39;OnlineBackup&#39;, &#39;DeviceProtection&#39;, &#39;TechSupport&#39;,       &#39;StreamingTV&#39;, &#39;StreamingMovies&#39;, &#39;Contract&#39;, &#39;PaperlessBilling&#39;,       &#39;PaymentMethod&#39;, &#39;MonthlyCharges&#39;, &#39;TotalCharges&#39;, &#39;Churn&#39;, &#39;Engaged&#39;,       &#39;YandNotE&#39;, &#39;ElectCheck&#39;, &#39;fiberopt&#39;, &#39;StreamNoInt&#39;, &#39;NoProt&#39;,       &#39;TotalServices&#39;],      dtype=&#39;object&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data = data.drop(columns = [</span><br><span class="line"></span><br><span class="line">                            <span class="string">&#x27;Contract&#x27;</span>,</span><br><span class="line"></span><br><span class="line">                            <span class="string">&#x27;DeviceProtection&#x27;</span>, </span><br><span class="line"></span><br><span class="line">                            <span class="string">&#x27;Partner&#x27;</span></span><br><span class="line"></span><br><span class="line">                           ])</span><br></pre></td></tr></table></figure><h2 id="3-3-Features-encoding-and-scaling"><a href="#3-3-Features-encoding-and-scaling" class="headerlink" title="3.3. Features encoding and scaling"></a>3.3. Features encoding and scaling</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 客户ID</span></span><br><span class="line"></span><br><span class="line">Id_col     = [<span class="string">&#x27;customerID&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标签</span></span><br><span class="line"></span><br><span class="line">target_col = [<span class="string">&quot;Churn&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对象型数据列</span></span><br><span class="line"></span><br><span class="line">cat_cols   = data.nunique()[data.nunique() &lt; <span class="number">10</span>].keys().tolist()</span><br><span class="line"></span><br><span class="line">cat_cols   = [x <span class="keyword">for</span> x <span class="keyword">in</span> cat_cols <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> target_col]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数值型数据列</span></span><br><span class="line"></span><br><span class="line">num_cols   = [x <span class="keyword">for</span> x <span class="keyword">in</span> data.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> cat_cols + target_col + Id_col]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二值列</span></span><br><span class="line"></span><br><span class="line">bin_cols   = data.nunique()[data.nunique() == <span class="number">2</span>].keys().tolist()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多值列</span></span><br><span class="line"></span><br><span class="line">multi_cols = [i <span class="keyword">for</span> i <span class="keyword">in</span> cat_cols <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> bin_cols]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对二值列进行标签编码</span></span><br><span class="line"></span><br><span class="line">le = LabelEncoder()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> bin_cols :</span><br><span class="line"></span><br><span class="line">    data[i] = le.fit_transform(data[i])</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 对多值列进行独热编码</span></span><br><span class="line"></span><br><span class="line">data = pd.get_dummies(data = data,columns = multi_cols )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数值型数据标准化</span></span><br><span class="line"></span><br><span class="line">std = StandardScaler()</span><br><span class="line"></span><br><span class="line">scaled = std.fit_transform(data[num_cols])</span><br><span class="line"></span><br><span class="line">scaled = pd.DataFrame(scaled,columns=num_cols)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数值型元数据替换为标准化后的数值数据</span></span><br><span class="line"></span><br><span class="line">df_data_og = data.copy()</span><br><span class="line"></span><br><span class="line">data = data.drop(columns = num_cols,axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">data = data.merge(scaled,left_index=<span class="literal">True</span>,right_index=<span class="literal">True</span>,how = <span class="string">&quot;left&quot;</span>)</span><br><span class="line"></span><br><span class="line">data = data.drop([<span class="string">&#x27;customerID&#x27;</span>],axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="3-4-Correlation-Heatmap"><a href="#3-4-Correlation-Heatmap" class="headerlink" title="3.4. Correlation Heatmap"></a>3.4. Correlation Heatmap</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">correlation_plot</span>(<span class="params">data</span>):</span></span><br><span class="line"></span><br><span class="line">    data = data.corr()</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    ax = sns.heatmap(data, annot=<span class="literal">False</span>, cmap = <span class="string">&#x27;viridis&#x27;</span>, linewidths = <span class="number">.1</span>, linecolor = <span class="string">&#x27;grey&#x27;</span>, fmt=<span class="string">&quot;.2f&quot;</span>)</span><br><span class="line"></span><br><span class="line">    ax.invert_yaxis()</span><br><span class="line"></span><br><span class="line">    ax.set_title(<span class="string">&quot;Correlation&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">correlation_plot(data)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fL9VaQ"><img src="https://z3.ax1x.com/2021/08/20/fL9VaQ.png" alt="fL9VaQ.png"></a></p><h2 id="3-5-Remove-collinear-features"><a href="#3-5-Remove-collinear-features" class="headerlink" title="3.5. Remove collinear features"></a>3.5. Remove collinear features</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 相关特征进行删除的阈值</span></span><br><span class="line"></span><br><span class="line">threshold = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对相关性矩阵取绝对值</span></span><br><span class="line"></span><br><span class="line">corr_matrix = data.corr().<span class="built_in">abs</span>()</span><br><span class="line"></span><br><span class="line">display(corr_matrix.head().append(corr_matrix.tail()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 取相关性矩阵上三角 np.triu 此处方法先将数据全部置1然后取上三角，此时下三角全为0，将0-1转换为bool值，以选取True所在单元格的数据</span></span><br><span class="line"></span><br><span class="line">upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=<span class="number">1</span>).astype(np.<span class="built_in">bool</span>))</span><br><span class="line"></span><br><span class="line">display(upper.head().append(upper.tail()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 取阈值之上的特征并删除</span></span><br><span class="line"></span><br><span class="line">to_drop = [column <span class="keyword">for</span> column <span class="keyword">in</span> upper.columns <span class="keyword">if</span> <span class="built_in">any</span>(upper[column] &gt; threshold)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;There are %d columns to remove :&#x27;</span> % (<span class="built_in">len</span>(to_drop)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.drop(columns = to_drop)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">to_drop</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>gender</th>      <th>SeniorCitizen</th>      <th>Dependents</th>      <th>PhoneService</th>      <th>PaperlessBilling</th>      <th>Churn</th>      <th>Engaged</th>      <th>YandNotE</th>      <th>ElectCheck</th>      <th>fiberopt</th>      <th>...</th>      <th>TotalServices_0</th>      <th>TotalServices_1</th>      <th>TotalServices_2</th>      <th>TotalServices_3</th>      <th>TotalServices_4</th>      <th>TotalServices_5</th>      <th>TotalServices_6</th>      <th>TotalServices_7</th>      <th>MonthlyCharges</th>      <th>TotalCharges</th>    </tr>  </thead>  <tbody>    <tr>      <th>gender</th>      <td>1.000000</td>      <td>0.001874</td>      <td>0.010517</td>      <td>0.006488</td>      <td>0.011754</td>      <td>0.008612</td>      <td>0.003386</td>      <td>0.003776</td>      <td>0.006969</td>      <td>0.011286</td>      <td>...</td>      <td>0.012379</td>      <td>0.006565</td>      <td>0.001029</td>      <td>0.001161</td>      <td>0.005514</td>      <td>0.002264</td>      <td>0.017296</td>      <td>0.013176</td>      <td>0.014569</td>      <td>0.000080</td>    </tr>    <tr>      <th>SeniorCitizen</th>      <td>0.001874</td>      <td>1.000000</td>      <td>0.211185</td>      <td>0.008576</td>      <td>0.156530</td>      <td>0.150889</td>      <td>0.138360</td>      <td>0.386482</td>      <td>0.186468</td>      <td>0.255338</td>      <td>...</td>      <td>0.003738</td>      <td>0.122491</td>      <td>0.041459</td>      <td>0.046895</td>      <td>0.050380</td>      <td>0.029801</td>      <td>0.002747</td>      <td>0.014319</td>      <td>0.220173</td>      <td>0.103006</td>    </tr>    <tr>      <th>Dependents</th>      <td>0.010517</td>      <td>0.211185</td>      <td>1.000000</td>      <td>0.001762</td>      <td>0.111377</td>      <td>0.164221</td>      <td>0.231720</td>      <td>0.111982</td>      <td>0.169907</td>      <td>0.165818</td>      <td>...</td>      <td>0.023303</td>      <td>0.059161</td>      <td>0.084852</td>      <td>0.047922</td>      <td>0.013134</td>      <td>0.029117</td>      <td>0.029168</td>      <td>0.048430</td>      <td>0.113890</td>      <td>0.062078</td>    </tr>    <tr>      <th>PhoneService</th>      <td>0.006488</td>      <td>0.008576</td>      <td>0.001762</td>      <td>1.000000</td>      <td>0.016505</td>      <td>0.011942</td>      <td>0.000742</td>      <td>0.000083</td>      <td>0.004519</td>      <td>0.289999</td>      <td>...</td>      <td>0.327354</td>      <td>0.107222</td>      <td>0.065522</td>      <td>0.069257</td>      <td>0.009174</td>      <td>0.013544</td>      <td>0.047230</td>      <td>0.063979</td>      <td>0.247398</td>      <td>0.113214</td>    </tr>    <tr>      <th>PaperlessBilling</th>      <td>0.011754</td>      <td>0.156530</td>      <td>0.111377</td>      <td>0.016505</td>      <td>1.000000</td>      <td>0.191825</td>      <td>0.169096</td>      <td>0.070549</td>      <td>0.197873</td>      <td>0.326853</td>      <td>...</td>      <td>0.006482</td>      <td>0.251039</td>      <td>0.068116</td>      <td>0.068790</td>      <td>0.082407</td>      <td>0.070216</td>      <td>0.058396</td>      <td>0.011691</td>      <td>0.352150</td>      <td>0.158574</td>    </tr>    <tr>      <th>TotalServices_5</th>      <td>0.002264</td>      <td>0.029801</td>      <td>0.029117</td>      <td>0.013544</td>      <td>0.070216</td>      <td>0.037420</td>      <td>0.164026</td>      <td>0.141655</td>      <td>0.075395</td>      <td>0.115043</td>      <td>...</td>      <td>0.039097</td>      <td>0.250156</td>      <td>0.148032</td>      <td>0.151906</td>      <td>0.153700</td>      <td>1.000000</td>      <td>0.103519</td>      <td>0.071270</td>      <td>0.299248</td>      <td>0.315356</td>    </tr>    <tr>      <th>TotalServices_6</th>      <td>0.017296</td>      <td>0.002747</td>      <td>0.029168</td>      <td>0.047230</td>      <td>0.058396</td>      <td>0.089768</td>      <td>0.217169</td>      <td>0.176288</td>      <td>0.116575</td>      <td>0.064497</td>      <td>...</td>      <td>0.030421</td>      <td>0.194641</td>      <td>0.115181</td>      <td>0.118195</td>      <td>0.119591</td>      <td>0.103519</td>      <td>1.000000</td>      <td>0.055454</td>      <td>0.289082</td>      <td>0.391785</td>    </tr>    <tr>      <th>TotalServices_7</th>      <td>0.013176</td>      <td>0.014319</td>      <td>0.048430</td>      <td>0.063979</td>      <td>0.011691</td>      <td>0.091806</td>      <td>0.202449</td>      <td>0.162530</td>      <td>0.109766</td>      <td>0.041263</td>      <td>...</td>      <td>0.020944</td>      <td>0.134005</td>      <td>0.079299</td>      <td>0.081374</td>      <td>0.082335</td>      <td>0.071270</td>      <td>0.055454</td>      <td>1.000000</td>      <td>0.246353</td>      <td>0.378530</td>    </tr>    <tr>      <th>MonthlyCharges</th>      <td>0.014569</td>      <td>0.220173</td>      <td>0.113890</td>      <td>0.247398</td>      <td>0.352150</td>      <td>0.193356</td>      <td>0.060165</td>      <td>0.048075</td>      <td>0.202893</td>      <td>0.787066</td>      <td>...</td>      <td>0.141994</td>      <td>0.724004</td>      <td>0.010335</td>      <td>0.116311</td>      <td>0.249383</td>      <td>0.299248</td>      <td>0.289082</td>      <td>0.246353</td>      <td>1.000000</td>      <td>0.651174</td>    </tr>    <tr>      <th>TotalCharges</th>      <td>0.000080</td>      <td>0.103006</td>      <td>0.062078</td>      <td>0.113214</td>      <td>0.158574</td>      <td>0.198324</td>      <td>0.444255</td>      <td>0.413707</td>      <td>0.212875</td>      <td>0.361655</td>      <td>...</td>      <td>0.097310</td>      <td>0.492495</td>      <td>0.196423</td>      <td>0.059875</td>      <td>0.151065</td>      <td>0.315356</td>      <td>0.391785</td>      <td>0.378530</td>      <td>0.651174</td>      <td>1.000000</td>    </tr>  </tbody></table><p>10 rows × 50 columns</p></div><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>gender</th>      <th>SeniorCitizen</th>      <th>Dependents</th>      <th>PhoneService</th>      <th>PaperlessBilling</th>      <th>Churn</th>      <th>Engaged</th>      <th>YandNotE</th>      <th>ElectCheck</th>      <th>fiberopt</th>      <th>...</th>      <th>TotalServices_0</th>      <th>TotalServices_1</th>      <th>TotalServices_2</th>      <th>TotalServices_3</th>      <th>TotalServices_4</th>      <th>TotalServices_5</th>      <th>TotalServices_6</th>      <th>TotalServices_7</th>      <th>MonthlyCharges</th>      <th>TotalCharges</th>    </tr>  </thead>  <tbody>    <tr>      <th>gender</th>      <td>NaN</td>      <td>0.001874</td>      <td>0.010517</td>      <td>0.006488</td>      <td>0.011754</td>      <td>0.008612</td>      <td>0.003386</td>      <td>0.003776</td>      <td>0.006969</td>      <td>0.011286</td>      <td>...</td>      <td>0.012379</td>      <td>0.006565</td>      <td>0.001029</td>      <td>0.001161</td>      <td>0.005514</td>      <td>0.002264</td>      <td>0.017296</td>      <td>0.013176</td>      <td>0.014569</td>      <td>0.000080</td>    </tr>    <tr>      <th>SeniorCitizen</th>      <td>NaN</td>      <td>NaN</td>      <td>0.211185</td>      <td>0.008576</td>      <td>0.156530</td>      <td>0.150889</td>      <td>0.138360</td>      <td>0.386482</td>      <td>0.186468</td>      <td>0.255338</td>      <td>...</td>      <td>0.003738</td>      <td>0.122491</td>      <td>0.041459</td>      <td>0.046895</td>      <td>0.050380</td>      <td>0.029801</td>      <td>0.002747</td>      <td>0.014319</td>      <td>0.220173</td>      <td>0.103006</td>    </tr>    <tr>      <th>Dependents</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0.001762</td>      <td>0.111377</td>      <td>0.164221</td>      <td>0.231720</td>      <td>0.111982</td>      <td>0.169907</td>      <td>0.165818</td>      <td>...</td>      <td>0.023303</td>      <td>0.059161</td>      <td>0.084852</td>      <td>0.047922</td>      <td>0.013134</td>      <td>0.029117</td>      <td>0.029168</td>      <td>0.048430</td>      <td>0.113890</td>      <td>0.062078</td>    </tr>    <tr>      <th>PhoneService</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0.016505</td>      <td>0.011942</td>      <td>0.000742</td>      <td>0.000083</td>      <td>0.004519</td>      <td>0.289999</td>      <td>...</td>      <td>0.327354</td>      <td>0.107222</td>      <td>0.065522</td>      <td>0.069257</td>      <td>0.009174</td>      <td>0.013544</td>      <td>0.047230</td>      <td>0.063979</td>      <td>0.247398</td>      <td>0.113214</td>    </tr>    <tr>      <th>PaperlessBilling</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0.191825</td>      <td>0.169096</td>      <td>0.070549</td>      <td>0.197873</td>      <td>0.326853</td>      <td>...</td>      <td>0.006482</td>      <td>0.251039</td>      <td>0.068116</td>      <td>0.068790</td>      <td>0.082407</td>      <td>0.070216</td>      <td>0.058396</td>      <td>0.011691</td>      <td>0.352150</td>      <td>0.158574</td>    </tr>    <tr>      <th>TotalServices_5</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0.103519</td>      <td>0.071270</td>      <td>0.299248</td>      <td>0.315356</td>    </tr>    <tr>      <th>TotalServices_6</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0.055454</td>      <td>0.289082</td>      <td>0.391785</td>    </tr>    <tr>      <th>TotalServices_7</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0.246353</td>      <td>0.378530</td>    </tr>    <tr>      <th>MonthlyCharges</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0.651174</td>    </tr>    <tr>      <th>TotalCharges</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>  </tbody></table><p>10 rows × 50 columns</p></div><pre><code>There are 8 columns to remove :[&#39;MultipleLines_No phone service&#39;, &#39;InternetService_Fiber optic&#39;, &#39;InternetService_No&#39;, &#39;OnlineSecurity_No internet service&#39;, &#39;OnlineBackup_No internet service&#39;, &#39;TechSupport_No internet service&#39;, &#39;StreamingTV_No internet service&#39;, &#39;StreamingMovies_No internet service&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">correlation_plot(data)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fL9mPs"><img src="https://z3.ax1x.com/2021/08/20/fL9mPs.png" alt="fL9mPs.png"></a></p><h1 id="4-Prepare-dataset-and-stylized-report"><a href="#4-Prepare-dataset-and-stylized-report" class="headerlink" title="4. Prepare dataset and stylized report"></a>4. Prepare dataset and stylized report</h1><h2 id="4-1-Define-X-y"><a href="#4-1-Define-X-y" class="headerlink" title="4.1. Define (X,  y)"></a>4.1. Define (X,  y)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y = np.array(data.Churn.tolist())</span><br><span class="line"></span><br><span class="line">data = data.drop(<span class="string">&#x27;Churn&#x27;</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">features = data.columns</span><br><span class="line"></span><br><span class="line">X = np.array(data.values)</span><br></pre></td></tr></table></figure><h2 id="4-2-Train-test-split"><a href="#4-2-Train-test-split" class="headerlink" title="4.2. Train_test_split"></a>4.2. Train_test_split</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练数据分割训练集测试集</span></span><br><span class="line"></span><br><span class="line">random_state = <span class="number">51</span></span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = random_state)</span><br></pre></td></tr></table></figure><h2 id="4-3-Stylized-report-with-sns-confusion-matrix-roc-precision-recall-etc…"><a href="#4-3-Stylized-report-with-sns-confusion-matrix-roc-precision-recall-etc…" class="headerlink" title="4.3. Stylized report with sns (confusion matrix, roc, precision-recall, etc…)"></a>4.3. Stylized report with sns (confusion matrix, roc, precision-recall, etc…)</h2><p>为了衡量模型的性能，我们需要几个元素：</p><p>这部分必不可少</p><ul><li><strong>Confusion matrix</strong> : 也称为误差矩阵，使算法的性能可视化：</li></ul><pre><code>* true positive (TP) : 识别正确，识别样本为正例，实际为正例* true negative (TN) : 识别正确，识别样本为反例，实际为反例* false positive (FP) : 识别错误，识别样本为正例，实际为反例* false negative (FN) : 识别错误，识别样本为反例，实际为正例</code></pre><ul><li><strong>Metrics</strong> :</li></ul><pre><code>* Accuracy : (TP +TN) / (TP + TN + FP +FN)* Precision : TP / (TP + FP)* Recall : TP / (TP + FN)* F1 score : 2 x ((Precision x Recall) / (Precision + Recall))</code></pre><ul><li><strong>Roc Curve</strong> : ROC 曲线是通过在各种阈值设置下绘制真阳性率 (TPR) 与假阳性率 (FPR) 来创建的。</li></ul><ul><li><strong>Precision Recall Curve</strong> :  显示了不同阈值下精确率和召回率之间的权衡</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_performance</span>(<span class="params">model</span>):</span>    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 混淆矩阵</span></span><br><span class="line"></span><br><span class="line">    sns.<span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">    C2= confusion_matrix(y_test, y_pred, labels=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    sns.heatmap(C2,annot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ROC曲线</span></span><br><span class="line"></span><br><span class="line">    fpr, tpr, threshold = roc_curve(y_test, y_score)</span><br><span class="line"></span><br><span class="line">    roc_auc = auc(fpr, tpr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">&#x27;Receiver Operating Characteristic:&#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(roc_auc_score(y_test, y_score), <span class="number">3</span>)))  </span><br><span class="line"></span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;navy&#x27;</span>, lw=<span class="number">2</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;AUC = %0.2f&#x27;</span> % roc_auc)</span><br><span class="line"></span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">&#x27;r &#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Recall曲线</span></span><br><span class="line"></span><br><span class="line">    precision, recall, thresholds = precision_recall_curve(y_test, y_score)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    plt.plot(precision, recall)</span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">&#x27;Precision-Recall curve&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.ylabel(<span class="string">&#x27;precision&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;recall&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 特征重要性</span></span><br><span class="line"></span><br><span class="line">    importances = <span class="built_in">eval</span>(model).feature_importances_</span><br><span class="line"></span><br><span class="line">    weights = pd.Series(importances, index=features)</span><br><span class="line"></span><br><span class="line">    weights.sort_values()[-<span class="number">10</span>:].plot(kind = <span class="string">&#x27;barh&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="4-4-Define-cross-validation-metrics"><a href="#4-4-Define-cross-validation-metrics" class="headerlink" title="4.4. Define cross validation metrics"></a>4.4. Define cross validation metrics</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 交叉验证指标</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_val_metrics</span>(<span class="params">model</span>) :</span></span><br><span class="line"></span><br><span class="line">    scores = [<span class="string">&#x27;accuracy&#x27;</span>, <span class="string">&#x27;precision&#x27;</span>, <span class="string">&#x27;recall&#x27;</span>, <span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;roc_auc&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> sc <span class="keyword">in</span> scores:</span><br><span class="line"></span><br><span class="line">        scores = cross_val_score(model, X, y, cv = <span class="number">5</span>, scoring = sc)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[%s] : %0.5f (+/- %0.5f)&#x27;</span>%(sc, scores.mean(), scores.std()))</span><br></pre></td></tr></table></figure><h1 id="5-Light-GBM-Model"><a href="#5-Light-GBM-Model" class="headerlink" title="5. Light GBM Model"></a>5. Light GBM Model</h1><h2 id="5-1-LightGBM-Before-RandomizedSearchCV"><a href="#5-1-LightGBM-Before-RandomizedSearchCV" class="headerlink" title="5.1. LightGBM - Before RandomizedSearchCV"></a>5.1. LightGBM - Before RandomizedSearchCV</h2><p><strong>LightGBM</strong> 是一个梯度提升框架，它使用基于树的学习算法。 它旨在分布式和高效，具有以下优点：</p><ul><li><p>训练速度更快，效率更高。</p></li><li><p>较低的内存使用率。</p></li><li><p>更好的准确性。</p></li><li><p>支持并行和 GPU 学习。</p></li><li><p>能够处理大规模数据。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"></span><br><span class="line">lgbm_clf = lgbm.LGBMClassifier(n_estimators=<span class="number">1500</span>, random_state = <span class="number">51</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lgbm_clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y_pred = lgbm_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line">y_score = lgbm_clf.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_performance(<span class="string">&#x27;lgbm_clf&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fL9Z5j"><img src="https://z3.ax1x.com/2021/08/20/fL9Z5j.png" alt="fL9Z5j.png"></a></p><p><a href="https://imgtu.com/i/fL9nGn"><img src="https://z3.ax1x.com/2021/08/20/fL9nGn.png" alt="fL9nGn.png"></a></p><p><a href="https://imgtu.com/i/fL9u2q"><img src="https://z3.ax1x.com/2021/08/20/fL9u2q.png" alt="fL9u2q.png"></a></p><pre><code>Wall time: 2.72 s</code></pre><p><a href="https://imgtu.com/i/fLivOP"><img src="https://z3.ax1x.com/2021/08/20/fLivOP.png" alt="fLivOP.png"></a></p><h2 id="5-2-LightGBM-RandomizedSearchCV-to-optimise-hyperparameters-1000-fits"><a href="#5-2-LightGBM-RandomizedSearchCV-to-optimise-hyperparameters-1000-fits" class="headerlink" title="5.2. LightGBM - RandomizedSearchCV to optimise hyperparameters  (1000 fits)"></a>5.2. LightGBM - RandomizedSearchCV to optimise hyperparameters  (1000 fits)</h2><p>为了找到最佳超参数，我们将使用随机搜索 CV。<br>随机搜索是一种使用超参数的随机组合来为构建的模型寻找最佳解决方案的技术。<br>通常，RandomizedSearchCV 比计算所有可能组合的 GridSearchCV 更快、更准确。 使用随机网格，指定我们想要的组合数量。</p><ul><li><strong>LightGBM : Hyperparameters</strong> :</li></ul><pre><code>* learning_rate : 学习率* n_estimators : 树的数量* num_leaves : 整棵树的叶子数，默认值为31* min_child_samples : 一片叶子中数据的最少数量。 可以用来处理过拟合* min_child_weight : 一片叶子中的最小Hessian和* subsample : 随机选择部分数据而不重新采样* max_depth : 它描述了树的最大深度。 该参数用于处理模型过拟合。* colsample_bytree : 如果该值小于1.0，LightGBM 将在每次迭代中随机选择部分特征。 例如，如果将其设置为 0.8，LightGBM 将在训练每棵树之前选择 80% 的特征* reg_alpha : 正则化* reg_lambda : 正则化* early_stopping_rounds : 早停机制，此参数可以加快分析速度。 如果一个验证数据的一个指标在上个 early_stopping_round 轮次中没有改进，模型将停止训练。 这将减少过多的迭代次数。</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">fit_params = &#123;<span class="string">&quot;early_stopping_rounds&quot;</span> : <span class="number">50</span>, </span><br><span class="line"></span><br><span class="line">             <span class="string">&quot;eval_metric&quot;</span> : <span class="string">&#x27;binary&#x27;</span>, </span><br><span class="line"></span><br><span class="line">             <span class="string">&quot;eval_set&quot;</span> : [(X_test,y_test)],</span><br><span class="line"></span><br><span class="line">             <span class="string">&#x27;eval_names&#x27;</span>: [<span class="string">&#x27;valid&#x27;</span>],</span><br><span class="line"></span><br><span class="line">             <span class="string">&#x27;verbose&#x27;</span>: <span class="number">0</span>,</span><br><span class="line"></span><br><span class="line">             <span class="string">&#x27;categorical_feature&#x27;</span>: <span class="string">&#x27;auto&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">param_test = &#123;<span class="string">&#x27;learning_rate&#x27;</span> : [<span class="number">0.01</span>, <span class="number">0.02</span>, <span class="number">0.03</span>, <span class="number">0.04</span>, <span class="number">0.05</span>, <span class="number">0.08</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>],</span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;n_estimators&#x27;</span> : [<span class="number">100</span>, <span class="number">200</span>, <span class="number">300</span>, <span class="number">400</span>, <span class="number">500</span>, <span class="number">600</span>, <span class="number">800</span>, <span class="number">1000</span>, <span class="number">1500</span>, <span class="number">2000</span>, <span class="number">3000</span>, <span class="number">5000</span>],</span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;num_leaves&#x27;</span>: sp_randint(<span class="number">6</span>, <span class="number">50</span>), </span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;min_child_samples&#x27;</span>: sp_randint(<span class="number">100</span>, <span class="number">500</span>), </span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;min_child_weight&#x27;</span>: [<span class="number">1e-5</span>, <span class="number">1e-3</span>, <span class="number">1e-2</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">1e1</span>, <span class="number">1e2</span>, <span class="number">1e3</span>, <span class="number">1e4</span>],</span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;subsample&#x27;</span>: sp_uniform(loc=<span class="number">0.2</span>, scale=<span class="number">0.8</span>), </span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;max_depth&#x27;</span>: [-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;colsample_bytree&#x27;</span>: sp_uniform(loc=<span class="number">0.4</span>, scale=<span class="number">0.6</span>),</span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;reg_alpha&#x27;</span>: [<span class="number">0</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>],</span><br><span class="line"></span><br><span class="line">              <span class="string">&#x27;reg_lambda&#x27;</span>: [<span class="number">0</span>, <span class="number">1e-1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#number of combinations</span></span><br><span class="line"></span><br><span class="line">n_iter = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#intialize lgbm and lunch the search</span></span><br><span class="line"></span><br><span class="line">lgbm_clf = lgbm.LGBMClassifier(random_state=random_state, silent=<span class="literal">True</span>, metric=<span class="string">&#x27;None&#x27;</span>, n_jobs=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">grid_search = RandomizedSearchCV(</span><br><span class="line"></span><br><span class="line">    estimator=lgbm_clf, param_distributions=param_test, </span><br><span class="line"></span><br><span class="line">    n_iter=n_iter,</span><br><span class="line"></span><br><span class="line">    scoring=<span class="string">&#x27;accuracy&#x27;</span>,</span><br><span class="line"></span><br><span class="line">    cv=<span class="number">5</span>,</span><br><span class="line"></span><br><span class="line">    refit=<span class="literal">True</span>,</span><br><span class="line"></span><br><span class="line">    random_state=random_state,</span><br><span class="line"></span><br><span class="line">    verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">grid_search.fit(X_train, y_train, **fit_params)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Best params: &#123;&#125; &#x27;</span>.<span class="built_in">format</span>(grid_search.best_params_))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">opt_parameters =  grid_search.best_params_</span><br></pre></td></tr></table></figure><pre><code>Fitting 5 folds for each of 200 candidates, totalling 1000 fitsBest params: &#123;&#39;colsample_bytree&#39;: 0.9970322000118677, &#39;learning_rate&#39;: 0.08, &#39;max_depth&#39;: 3, &#39;min_child_samples&#39;: 476, &#39;min_child_weight&#39;: 100.0, &#39;n_estimators&#39;: 500, &#39;num_leaves&#39;: 35, &#39;reg_alpha&#39;: 7, &#39;reg_lambda&#39;: 1, &#39;subsample&#39;: 0.6034489935154275&#125; </code></pre><h2 id="5-3-LightGBM-After-RandomizedSearchCV"><a href="#5-3-LightGBM-After-RandomizedSearchCV" class="headerlink" title="5.3. LightGBM - After RandomizedSearchCV"></a>5.3. LightGBM - After RandomizedSearchCV</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"></span><br><span class="line">lgbm_clf = lgbm.LGBMClassifier(**opt_parameters)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lgbm_clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">y_pred = lgbm_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line">y_score = lgbm_clf.predict_proba(X_test)[:,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_performance(<span class="string">&#x27;lgbm_clf&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fLiqWd"><img src="https://z3.ax1x.com/2021/08/20/fLiqWd.png" alt="fLiqWd.png"></a></p><p><a href="https://imgtu.com/i/fLijyt"><img src="https://z3.ax1x.com/2021/08/20/fLijyt.png" alt="fLijyt.png"></a></p><p><a href="https://imgtu.com/i/fLiOSA"><img src="https://z3.ax1x.com/2021/08/20/fLiOSA.png" alt="fLiOSA.png"></a></p><pre><code>Wall time: 1.41 s</code></pre><p><a href="https://imgtu.com/i/fLiXQI"><img src="https://z3.ax1x.com/2021/08/20/fLiXQI.png" alt="fLiXQI.png"></a></p><h2 id="5-4-LightGBM-–-Cross-validation-5-folds"><a href="#5-4-LightGBM-–-Cross-validation-5-folds" class="headerlink" title="5.4. LightGBM – Cross validation (5 folds)"></a>5.4. LightGBM – Cross validation (5 folds)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cross_val_metrics(lgbm_clf)</span><br></pre></td></tr></table></figure><pre><code>[accuracy] : 0.80591 (+/- 0.00951)[precision] : 0.66978 (+/- 0.02319)[recall] : 0.53023 (+/- 0.01859)[f1] : 0.59181 (+/- 0.01951)[roc_auc] : 0.84634 (+/- 0.00961)</code></pre><hr><p>本文提及的数据集下载地址：<br>链接：<a href="https://pan.baidu.com/s/1ZVlY4KeAy6cvu8Aotb3CpQ">https://pan.baidu.com/s/1ZVlY4KeAy6cvu8Aotb3CpQ</a><br>提取码：1111</p><hr>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Telcom-Customer-Churn&quot;&gt;&lt;a href=&quot;#Telcom-Customer-Churn&quot; class=&quot;headerlink&quot; title=&quot;Telcom Customer Churn&quot;&gt;&lt;/a&gt;&lt;strong&gt;Telcom Customer Churn&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;每行代表一个客户每列是一个特征，原始数据包含 7043 行 21 列. “Churn” 是标签.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;customerID&lt;/strong&gt; : 客户 ID&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;gender&lt;/strong&gt; : 客户性别&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;SeniorCitizen&lt;/strong&gt; : 用户是否退休 (1, 0)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Partner&lt;/strong&gt; : 客户是否有合作伙伴 (Yes, No)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dependents&lt;/strong&gt; : 客户是否有家属 (Yes, No)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;tenure&lt;/strong&gt; : 客户留存月数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PhoneService&lt;/strong&gt; : 客户是否有电话服务 (Yes, No)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;MultipleLines&lt;/strong&gt; : 客户是否有多条线路 (Yes, No, No phone service)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;InternetService&lt;/strong&gt; : 客户网络服务提供商 (DSL, Fiber optic, No)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OnlineSecurity&lt;/strong&gt; : 客户是否有在线安全 (Yes, No, No internet service)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OnlineBackup&lt;/strong&gt; : 客户是否有在线备份 (Yes, No, No internet service)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;DeviceProtection&lt;/strong&gt; : 客户是否有设备保护 (Yes, No, No internet service)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;TechSupport&lt;/strong&gt; : 客户是否有技术支持 (Yes, No, No internet service)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;StreamingTV&lt;/strong&gt; : 客户是否有流媒体电视 (Yes, No, No internet service)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;StreamingMovies&lt;/strong&gt; : 客户是否有流媒体电影 (Yes, No, No internet service)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Contract&lt;/strong&gt; : 客户合同期限 (Month-to-month, One year, Two year)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PaperlessBilling&lt;/strong&gt; : 客户是否有无纸化计费 (Yes, No)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PaymentMethod&lt;/strong&gt; : 客户付款方式 (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;MonthlyCharges&lt;/strong&gt; : 客户月付金额&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;TotalCharges&lt;/strong&gt; : 客户付款总金额&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Churn&lt;/strong&gt; : 客户是否流失 (Yes or No)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="Kaggle" scheme="http://woody0819.github.io/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>Home Credit Default Risk</title>
    <link href="http://woody0819.github.io/2021/08/20/Home%20Credit%20Default%20Risk/"/>
    <id>http://woody0819.github.io/2021/08/20/Home%20Credit%20Default%20Risk/</id>
    <published>2021-08-19T17:00:41.932Z</published>
    <updated>2021-08-19T17:23:26.630Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">app_train = pd.read_csv(<span class="string">&#x27;./dataset/application_train.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Training data shape: &#x27;</span>, app_train.shape)</span><br><span class="line"></span><br><span class="line">app_train.head()</span><br></pre></td></tr></table></figure><pre><code>Training data shape:  (307511, 122)</code></pre><span id="more"></span><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>SK_ID_CURR</th>      <th>TARGET</th>      <th>NAME_CONTRACT_TYPE</th>      <th>CODE_GENDER</th>      <th>FLAG_OWN_CAR</th>      <th>FLAG_OWN_REALTY</th>      <th>CNT_CHILDREN</th>      <th>AMT_INCOME_TOTAL</th>      <th>AMT_CREDIT</th>      <th>AMT_ANNUITY</th>      <th>...</th>      <th>FLAG_DOCUMENT_18</th>      <th>FLAG_DOCUMENT_19</th>      <th>FLAG_DOCUMENT_20</th>      <th>FLAG_DOCUMENT_21</th>      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>      <th>AMT_REQ_CREDIT_BUREAU_MON</th>      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>100002</td>      <td>1</td>      <td>Cash loans</td>      <td>M</td>      <td>N</td>      <td>Y</td>      <td>0</td>      <td>202500.0</td>      <td>406597.5</td>      <td>24700.5</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>1.0</td>    </tr>    <tr>      <th>1</th>      <td>100003</td>      <td>0</td>      <td>Cash loans</td>      <td>F</td>      <td>N</td>      <td>N</td>      <td>0</td>      <td>270000.0</td>      <td>1293502.5</td>      <td>35698.5</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <th>2</th>      <td>100004</td>      <td>0</td>      <td>Revolving loans</td>      <td>M</td>      <td>Y</td>      <td>Y</td>      <td>0</td>      <td>67500.0</td>      <td>135000.0</td>      <td>6750.0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <th>3</th>      <td>100006</td>      <td>0</td>      <td>Cash loans</td>      <td>F</td>      <td>N</td>      <td>Y</td>      <td>0</td>      <td>135000.0</td>      <td>312682.5</td>      <td>29686.5</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>4</th>      <td>100007</td>      <td>0</td>      <td>Cash loans</td>      <td>M</td>      <td>N</td>      <td>Y</td>      <td>0</td>      <td>121500.0</td>      <td>513000.0</td>      <td>21865.5</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>  </tbody></table><p>5 rows × 122 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">app_test = pd.read_csv(<span class="string">&#x27;./dataset/application_test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Testing data shape: &#x27;</span>, app_test.shape)</span><br><span class="line"></span><br><span class="line">app_test.head()</span><br></pre></td></tr></table></figure><pre><code>Testing data shape:  (48744, 121)</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>SK_ID_CURR</th>      <th>NAME_CONTRACT_TYPE</th>      <th>CODE_GENDER</th>      <th>FLAG_OWN_CAR</th>      <th>FLAG_OWN_REALTY</th>      <th>CNT_CHILDREN</th>      <th>AMT_INCOME_TOTAL</th>      <th>AMT_CREDIT</th>      <th>AMT_ANNUITY</th>      <th>AMT_GOODS_PRICE</th>      <th>...</th>      <th>FLAG_DOCUMENT_18</th>      <th>FLAG_DOCUMENT_19</th>      <th>FLAG_DOCUMENT_20</th>      <th>FLAG_DOCUMENT_21</th>      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>      <th>AMT_REQ_CREDIT_BUREAU_MON</th>      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>100001</td>      <td>Cash loans</td>      <td>F</td>      <td>N</td>      <td>Y</td>      <td>0</td>      <td>135000.0</td>      <td>568800.0</td>      <td>20560.5</td>      <td>450000.0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1</th>      <td>100005</td>      <td>Cash loans</td>      <td>M</td>      <td>N</td>      <td>Y</td>      <td>0</td>      <td>99000.0</td>      <td>222768.0</td>      <td>17370.0</td>      <td>180000.0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>3.0</td>    </tr>    <tr>      <th>2</th>      <td>100013</td>      <td>Cash loans</td>      <td>M</td>      <td>Y</td>      <td>Y</td>      <td>0</td>      <td>202500.0</td>      <td>663264.0</td>      <td>69777.0</td>      <td>630000.0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>1.0</td>      <td>4.0</td>    </tr>    <tr>      <th>3</th>      <td>100028</td>      <td>Cash loans</td>      <td>F</td>      <td>N</td>      <td>Y</td>      <td>2</td>      <td>315000.0</td>      <td>1575000.0</td>      <td>49018.5</td>      <td>1575000.0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>3.0</td>    </tr>    <tr>      <th>4</th>      <td>100038</td>      <td>Cash loans</td>      <td>M</td>      <td>Y</td>      <td>N</td>      <td>1</td>      <td>180000.0</td>      <td>625500.0</td>      <td>32067.0</td>      <td>625500.0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>  </tbody></table><p>5 rows × 121 columns</p></div><h2 id="Exploratory-Data-Analysis-EDA-数据探索性分析"><a href="#Exploratory-Data-Analysis-EDA-数据探索性分析" class="headerlink" title="Exploratory Data Analysis(EDA):数据探索性分析"></a>Exploratory Data Analysis(EDA):数据探索性分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看类别分布状况</span></span><br><span class="line"></span><br><span class="line">app_train[<span class="string">&#x27;TARGET&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>0    2826861     24825Name: TARGET, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">app_train[<span class="string">&#x27;TARGET&#x27;</span>].astype(<span class="built_in">int</span>).plot.hist()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x210807715f8&gt;</code></pre><p><a href="https://imgtu.com/i/fqvXfx"><img src="https://z3.ax1x.com/2021/08/19/fqvXfx.png" alt="fqvXfx.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查缺失值</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">missing_values_table</span>(<span class="params">df</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每列特征的缺失值数目</span></span><br><span class="line"></span><br><span class="line">        mis_val = df.isnull().<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每列特征缺失值的百分比</span></span><br><span class="line"></span><br><span class="line">        mis_val_percent = <span class="number">100</span> * df.isnull().<span class="built_in">sum</span>() / <span class="built_in">len</span>(df)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拼接上述两列，axis=1左右连接，axis=0上下连接</span></span><br><span class="line"></span><br><span class="line">        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 重置列名</span></span><br><span class="line"></span><br><span class="line">        mis_val_table_ren_columns = mis_val_table.rename(</span><br><span class="line"></span><br><span class="line">        columns = &#123;<span class="number">0</span> : <span class="string">&#x27;Missing Values&#x27;</span>, <span class="number">1</span> : <span class="string">&#x27;% of Total Values&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 按特征缺失率排序，ascending=True按升序排列，Fasle降序排列，round()保留几位小数</span></span><br><span class="line"></span><br><span class="line">        mis_val_table_ren_columns = mis_val_table_ren_columns[</span><br><span class="line"></span><br><span class="line">            mis_val_table_ren_columns.iloc[:,<span class="number">1</span>] != <span class="number">0</span>].sort_values(</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;% of Total Values&#x27;</span>, ascending=<span class="literal">False</span>).<span class="built_in">round</span>(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出总结信息</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;Your selected dataframe has &quot;</span> + <span class="built_in">str</span>(df.shape[<span class="number">1</span>]) + <span class="string">&quot; columns.\n&quot;</span>      </span><br><span class="line"></span><br><span class="line">            <span class="string">&quot;There are &quot;</span> + <span class="built_in">str</span>(mis_val_table_ren_columns.shape[<span class="number">0</span>]) +</span><br><span class="line"></span><br><span class="line">              <span class="string">&quot; columns that have missing values.&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回缺失信息</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> mis_val_table_ren_columns</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练集数据缺失情况，对于缺失值可采取填补措施，对于缺失率很高的列可删除，在此处暂时保留</span></span><br><span class="line"></span><br><span class="line">missing_values = missing_values_table(app_train)</span><br><span class="line"></span><br><span class="line">missing_values.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><pre><code>Your selected dataframe has 122 columns.There are 67 columns that have missing values.</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Missing Values</th>      <th>% of Total Values</th>    </tr>  </thead>  <tbody>    <tr>      <th>COMMONAREA_MEDI</th>      <td>214865</td>      <td>69.9</td>    </tr>    <tr>      <th>COMMONAREA_AVG</th>      <td>214865</td>      <td>69.9</td>    </tr>    <tr>      <th>COMMONAREA_MODE</th>      <td>214865</td>      <td>69.9</td>    </tr>    <tr>      <th>NONLIVINGAPARTMENTS_MEDI</th>      <td>213514</td>      <td>69.4</td>    </tr>    <tr>      <th>NONLIVINGAPARTMENTS_MODE</th>      <td>213514</td>      <td>69.4</td>    </tr>    <tr>      <th>NONLIVINGAPARTMENTS_AVG</th>      <td>213514</td>      <td>69.4</td>    </tr>    <tr>      <th>FONDKAPREMONT_MODE</th>      <td>210295</td>      <td>68.4</td>    </tr>    <tr>      <th>LIVINGAPARTMENTS_MODE</th>      <td>210199</td>      <td>68.4</td>    </tr>    <tr>      <th>LIVINGAPARTMENTS_MEDI</th>      <td>210199</td>      <td>68.4</td>    </tr>    <tr>      <th>LIVINGAPARTMENTS_AVG</th>      <td>210199</td>      <td>68.4</td>    </tr>    <tr>      <th>FLOORSMIN_MODE</th>      <td>208642</td>      <td>67.8</td>    </tr>    <tr>      <th>FLOORSMIN_MEDI</th>      <td>208642</td>      <td>67.8</td>    </tr>    <tr>      <th>FLOORSMIN_AVG</th>      <td>208642</td>      <td>67.8</td>    </tr>    <tr>      <th>YEARS_BUILD_MODE</th>      <td>204488</td>      <td>66.5</td>    </tr>    <tr>      <th>YEARS_BUILD_MEDI</th>      <td>204488</td>      <td>66.5</td>    </tr>    <tr>      <th>YEARS_BUILD_AVG</th>      <td>204488</td>      <td>66.5</td>    </tr>    <tr>      <th>OWN_CAR_AGE</th>      <td>202929</td>      <td>66.0</td>    </tr>    <tr>      <th>LANDAREA_AVG</th>      <td>182590</td>      <td>59.4</td>    </tr>    <tr>      <th>LANDAREA_MEDI</th>      <td>182590</td>      <td>59.4</td>    </tr>    <tr>      <th>LANDAREA_MODE</th>      <td>182590</td>      <td>59.4</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看各类型数据的列数</span></span><br><span class="line"></span><br><span class="line">app_train.dtypes.value_counts()</span><br></pre></td></tr></table></figure><pre><code>float64    65int64      41object     16dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看对象类型中唯一值的数目</span></span><br><span class="line"></span><br><span class="line">app_train.select_dtypes(<span class="string">&#x27;object&#x27;</span>).apply(pd.Series.nunique, axis = <span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>NAME_CONTRACT_TYPE             2CODE_GENDER                    3FLAG_OWN_CAR                   2FLAG_OWN_REALTY                2NAME_TYPE_SUITE                7NAME_INCOME_TYPE               8NAME_EDUCATION_TYPE            5NAME_FAMILY_STATUS             6NAME_HOUSING_TYPE              6OCCUPATION_TYPE               18WEEKDAY_APPR_PROCESS_START     7ORGANIZATION_TYPE             58FONDKAPREMONT_MODE             4HOUSETYPE_MODE                 3WALLSMATERIAL_MODE             7EMERGENCYSTATE_MODE            2dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将对象类型进行编码，建议采用One-hot encoding避免标签编码带来的数值大小问题对预测结果产生影响</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处对于只有两个类别变量的特征采用标签编码，对于有两个及以上类别变量的特征采用独热编码</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 独热编码后数据维度会明显上升，可能需要降维算法删除相关度较高的特征和对结果几乎没有影响的垃圾特征</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用scikit-learn LabelEncoder()进行标签编码</span></span><br><span class="line"></span><br><span class="line">le = LabelEncoder()</span><br><span class="line"></span><br><span class="line">le_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> app_train:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> app_train[col].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">list</span>(app_train[col].unique())) &lt;= <span class="number">2</span>:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在训练集上训练编码器</span></span><br><span class="line"></span><br><span class="line">            le.fit(app_train[col])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 并在训练集和测试集上分别编码转换</span></span><br><span class="line"></span><br><span class="line">            app_train[col] = le.transform(app_train[col])</span><br><span class="line"></span><br><span class="line">            app_test[col] = le.transform(app_test[col])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计数有多少个特征被转换</span></span><br><span class="line"></span><br><span class="line">            le_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d columns were label encoded.&#x27;</span> % le_count)</span><br></pre></td></tr></table></figure><pre><code>3 columns were label encoded.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用pandas get_dummies实现独热编码</span></span><br><span class="line"></span><br><span class="line">app_train = pd.get_dummies(app_train)</span><br><span class="line"></span><br><span class="line">app_test = pd.get_dummies(app_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Training Features shape: &#x27;</span>, app_train.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Testing Features shape: &#x27;</span>, app_test.shape)</span><br></pre></td></tr></table></figure><pre><code>Training Features shape:  (307511, 243)Testing Features shape:  (48744, 239)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过shape可以观察到训练集测试集的特征数量不同，因此需要删除在训练集中而不在测试集中的特征列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过pandas将训练集和测试集对齐</span></span><br><span class="line"></span><br><span class="line">train_labels = app_train[<span class="string">&#x27;TARGET&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># axis=1按columns对齐，inner内连接只保留匹配的项，outer保留双方所有的数据，没有的列补NAN</span></span><br><span class="line"></span><br><span class="line">app_train, app_test = app_train.align(app_test, join = <span class="string">&#x27;inner&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将第一步取出的label重新加入处理后的训练集</span></span><br><span class="line"></span><br><span class="line">app_train[<span class="string">&#x27;TARGET&#x27;</span>] = train_labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Training Features shape: &#x27;</span>, app_train.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Testing Features shape: &#x27;</span>, app_test.shape)</span><br></pre></td></tr></table></figure><pre><code>Training Features shape:  (307511, 240)Testing Features shape:  (48744, 239)</code></pre><ul><li><p>异常值处理</p><ul><li><p>本项目中大部分特征均为金额，不存在异常情况因此该部分仅作为示例，不作为实际处理</p></li><li><p>本项目中异常值主要关注日期信息</p></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">numerical_fea = <span class="built_in">list</span>(app_train.select_dtypes(exclude=[<span class="string">&#x27;object&#x27;</span>]).columns)</span><br><span class="line"></span><br><span class="line">numerical_fea</span><br></pre></td></tr></table></figure><pre><code>[&#39;SK_ID_CURR&#39;, &#39;NAME_CONTRACT_TYPE&#39;, &#39;FLAG_OWN_CAR&#39;, &#39;FLAG_OWN_REALTY&#39;, &#39;CNT_CHILDREN&#39;, &#39;AMT_INCOME_TOTAL&#39;, &#39;AMT_CREDIT&#39;, &#39;AMT_ANNUITY&#39;, &#39;AMT_GOODS_PRICE&#39;, &#39;REGION_POPULATION_RELATIVE&#39;, &#39;DAYS_BIRTH&#39;, &#39;DAYS_EMPLOYED&#39;, &#39;DAYS_REGISTRATION&#39;, &#39;DAYS_ID_PUBLISH&#39;, &#39;OWN_CAR_AGE&#39;, &#39;FLAG_MOBIL&#39;, &#39;FLAG_EMP_PHONE&#39;, &#39;FLAG_WORK_PHONE&#39;, &#39;FLAG_CONT_MOBILE&#39;, &#39;FLAG_PHONE&#39;, &#39;FLAG_EMAIL&#39;, &#39;CNT_FAM_MEMBERS&#39;, &#39;REGION_RATING_CLIENT&#39;, &#39;REGION_RATING_CLIENT_W_CITY&#39;, &#39;HOUR_APPR_PROCESS_START&#39;, &#39;REG_REGION_NOT_LIVE_REGION&#39;, &#39;REG_REGION_NOT_WORK_REGION&#39;, &#39;LIVE_REGION_NOT_WORK_REGION&#39;, &#39;REG_CITY_NOT_LIVE_CITY&#39;, &#39;REG_CITY_NOT_WORK_CITY&#39;, &#39;LIVE_CITY_NOT_WORK_CITY&#39;, &#39;EXT_SOURCE_1&#39;, &#39;EXT_SOURCE_2&#39;, &#39;EXT_SOURCE_3&#39;, &#39;APARTMENTS_AVG&#39;, &#39;BASEMENTAREA_AVG&#39;, &#39;YEARS_BEGINEXPLUATATION_AVG&#39;, &#39;YEARS_BUILD_AVG&#39;, &#39;COMMONAREA_AVG&#39;, &#39;ELEVATORS_AVG&#39;, &#39;ENTRANCES_AVG&#39;, &#39;FLOORSMAX_AVG&#39;, &#39;FLOORSMIN_AVG&#39;, &#39;LANDAREA_AVG&#39;, &#39;LIVINGAPARTMENTS_AVG&#39;, &#39;LIVINGAREA_AVG&#39;, &#39;NONLIVINGAPARTMENTS_AVG&#39;, &#39;NONLIVINGAREA_AVG&#39;, &#39;APARTMENTS_MODE&#39;, &#39;BASEMENTAREA_MODE&#39;, &#39;YEARS_BEGINEXPLUATATION_MODE&#39;, &#39;YEARS_BUILD_MODE&#39;, &#39;COMMONAREA_MODE&#39;, &#39;ELEVATORS_MODE&#39;, &#39;ENTRANCES_MODE&#39;, &#39;FLOORSMAX_MODE&#39;, &#39;FLOORSMIN_MODE&#39;, &#39;LANDAREA_MODE&#39;, &#39;LIVINGAPARTMENTS_MODE&#39;, &#39;LIVINGAREA_MODE&#39;, &#39;NONLIVINGAPARTMENTS_MODE&#39;, &#39;NONLIVINGAREA_MODE&#39;, &#39;APARTMENTS_MEDI&#39;, &#39;BASEMENTAREA_MEDI&#39;, &#39;YEARS_BEGINEXPLUATATION_MEDI&#39;, &#39;YEARS_BUILD_MEDI&#39;, &#39;COMMONAREA_MEDI&#39;, &#39;ELEVATORS_MEDI&#39;, &#39;ENTRANCES_MEDI&#39;, &#39;FLOORSMAX_MEDI&#39;, &#39;FLOORSMIN_MEDI&#39;, &#39;LANDAREA_MEDI&#39;, &#39;LIVINGAPARTMENTS_MEDI&#39;, &#39;LIVINGAREA_MEDI&#39;, &#39;NONLIVINGAPARTMENTS_MEDI&#39;, &#39;NONLIVINGAREA_MEDI&#39;, &#39;TOTALAREA_MODE&#39;, &#39;OBS_30_CNT_SOCIAL_CIRCLE&#39;, &#39;DEF_30_CNT_SOCIAL_CIRCLE&#39;, &#39;OBS_60_CNT_SOCIAL_CIRCLE&#39;, &#39;DEF_60_CNT_SOCIAL_CIRCLE&#39;, &#39;DAYS_LAST_PHONE_CHANGE&#39;, &#39;FLAG_DOCUMENT_2&#39;, &#39;FLAG_DOCUMENT_3&#39;, &#39;FLAG_DOCUMENT_4&#39;, &#39;FLAG_DOCUMENT_5&#39;, &#39;FLAG_DOCUMENT_6&#39;, &#39;FLAG_DOCUMENT_7&#39;, &#39;FLAG_DOCUMENT_8&#39;, &#39;FLAG_DOCUMENT_9&#39;, &#39;FLAG_DOCUMENT_10&#39;, &#39;FLAG_DOCUMENT_11&#39;, &#39;FLAG_DOCUMENT_12&#39;, &#39;FLAG_DOCUMENT_13&#39;, &#39;FLAG_DOCUMENT_14&#39;, &#39;FLAG_DOCUMENT_15&#39;, &#39;FLAG_DOCUMENT_16&#39;, &#39;FLAG_DOCUMENT_17&#39;, &#39;FLAG_DOCUMENT_18&#39;, &#39;FLAG_DOCUMENT_19&#39;, &#39;FLAG_DOCUMENT_20&#39;, &#39;FLAG_DOCUMENT_21&#39;, &#39;AMT_REQ_CREDIT_BUREAU_HOUR&#39;, &#39;AMT_REQ_CREDIT_BUREAU_DAY&#39;, &#39;AMT_REQ_CREDIT_BUREAU_WEEK&#39;, &#39;AMT_REQ_CREDIT_BUREAU_MON&#39;, &#39;AMT_REQ_CREDIT_BUREAU_QRT&#39;, &#39;AMT_REQ_CREDIT_BUREAU_YEAR&#39;, &#39;CODE_GENDER_F&#39;, &#39;CODE_GENDER_M&#39;, &#39;NAME_TYPE_SUITE_Children&#39;, &#39;NAME_TYPE_SUITE_Family&#39;, &#39;NAME_TYPE_SUITE_Group of people&#39;, &#39;NAME_TYPE_SUITE_Other_A&#39;, &#39;NAME_TYPE_SUITE_Other_B&#39;, &#39;NAME_TYPE_SUITE_Spouse, partner&#39;, &#39;NAME_TYPE_SUITE_Unaccompanied&#39;, &#39;NAME_INCOME_TYPE_Businessman&#39;, &#39;NAME_INCOME_TYPE_Commercial associate&#39;, &#39;NAME_INCOME_TYPE_Pensioner&#39;, &#39;NAME_INCOME_TYPE_State servant&#39;, &#39;NAME_INCOME_TYPE_Student&#39;, &#39;NAME_INCOME_TYPE_Unemployed&#39;, &#39;NAME_INCOME_TYPE_Working&#39;, &#39;NAME_EDUCATION_TYPE_Academic degree&#39;, &#39;NAME_EDUCATION_TYPE_Higher education&#39;, &#39;NAME_EDUCATION_TYPE_Incomplete higher&#39;, &#39;NAME_EDUCATION_TYPE_Lower secondary&#39;, &#39;NAME_EDUCATION_TYPE_Secondary / secondary special&#39;, &#39;NAME_FAMILY_STATUS_Civil marriage&#39;, &#39;NAME_FAMILY_STATUS_Married&#39;, &#39;NAME_FAMILY_STATUS_Separated&#39;, &#39;NAME_FAMILY_STATUS_Single / not married&#39;, &#39;NAME_FAMILY_STATUS_Widow&#39;, &#39;NAME_HOUSING_TYPE_Co-op apartment&#39;, &#39;NAME_HOUSING_TYPE_House / apartment&#39;, &#39;NAME_HOUSING_TYPE_Municipal apartment&#39;, &#39;NAME_HOUSING_TYPE_Office apartment&#39;, &#39;NAME_HOUSING_TYPE_Rented apartment&#39;, &#39;NAME_HOUSING_TYPE_With parents&#39;, &#39;OCCUPATION_TYPE_Accountants&#39;, &#39;OCCUPATION_TYPE_Cleaning staff&#39;, &#39;OCCUPATION_TYPE_Cooking staff&#39;, &#39;OCCUPATION_TYPE_Core staff&#39;, &#39;OCCUPATION_TYPE_Drivers&#39;, &#39;OCCUPATION_TYPE_HR staff&#39;, &#39;OCCUPATION_TYPE_High skill tech staff&#39;, &#39;OCCUPATION_TYPE_IT staff&#39;, &#39;OCCUPATION_TYPE_Laborers&#39;, &#39;OCCUPATION_TYPE_Low-skill Laborers&#39;, &#39;OCCUPATION_TYPE_Managers&#39;, &#39;OCCUPATION_TYPE_Medicine staff&#39;, &#39;OCCUPATION_TYPE_Private service staff&#39;, &#39;OCCUPATION_TYPE_Realty agents&#39;, &#39;OCCUPATION_TYPE_Sales staff&#39;, &#39;OCCUPATION_TYPE_Secretaries&#39;, &#39;OCCUPATION_TYPE_Security staff&#39;, &#39;OCCUPATION_TYPE_Waiters/barmen staff&#39;, &#39;WEEKDAY_APPR_PROCESS_START_FRIDAY&#39;, &#39;WEEKDAY_APPR_PROCESS_START_MONDAY&#39;, &#39;WEEKDAY_APPR_PROCESS_START_SATURDAY&#39;, &#39;WEEKDAY_APPR_PROCESS_START_SUNDAY&#39;, &#39;WEEKDAY_APPR_PROCESS_START_THURSDAY&#39;, &#39;WEEKDAY_APPR_PROCESS_START_TUESDAY&#39;, &#39;WEEKDAY_APPR_PROCESS_START_WEDNESDAY&#39;, &#39;ORGANIZATION_TYPE_Advertising&#39;, &#39;ORGANIZATION_TYPE_Agriculture&#39;, &#39;ORGANIZATION_TYPE_Bank&#39;, &#39;ORGANIZATION_TYPE_Business Entity Type 1&#39;, &#39;ORGANIZATION_TYPE_Business Entity Type 2&#39;, &#39;ORGANIZATION_TYPE_Business Entity Type 3&#39;, &#39;ORGANIZATION_TYPE_Cleaning&#39;, &#39;ORGANIZATION_TYPE_Construction&#39;, &#39;ORGANIZATION_TYPE_Culture&#39;, &#39;ORGANIZATION_TYPE_Electricity&#39;, &#39;ORGANIZATION_TYPE_Emergency&#39;, &#39;ORGANIZATION_TYPE_Government&#39;, &#39;ORGANIZATION_TYPE_Hotel&#39;, &#39;ORGANIZATION_TYPE_Housing&#39;, &#39;ORGANIZATION_TYPE_Industry: type 1&#39;, &#39;ORGANIZATION_TYPE_Industry: type 10&#39;, &#39;ORGANIZATION_TYPE_Industry: type 11&#39;, &#39;ORGANIZATION_TYPE_Industry: type 12&#39;, &#39;ORGANIZATION_TYPE_Industry: type 13&#39;, &#39;ORGANIZATION_TYPE_Industry: type 2&#39;, &#39;ORGANIZATION_TYPE_Industry: type 3&#39;, &#39;ORGANIZATION_TYPE_Industry: type 4&#39;, &#39;ORGANIZATION_TYPE_Industry: type 5&#39;, &#39;ORGANIZATION_TYPE_Industry: type 6&#39;, &#39;ORGANIZATION_TYPE_Industry: type 7&#39;, &#39;ORGANIZATION_TYPE_Industry: type 8&#39;, &#39;ORGANIZATION_TYPE_Industry: type 9&#39;, &#39;ORGANIZATION_TYPE_Insurance&#39;, &#39;ORGANIZATION_TYPE_Kindergarten&#39;, &#39;ORGANIZATION_TYPE_Legal Services&#39;, &#39;ORGANIZATION_TYPE_Medicine&#39;, &#39;ORGANIZATION_TYPE_Military&#39;, &#39;ORGANIZATION_TYPE_Mobile&#39;, &#39;ORGANIZATION_TYPE_Other&#39;, &#39;ORGANIZATION_TYPE_Police&#39;, &#39;ORGANIZATION_TYPE_Postal&#39;, &#39;ORGANIZATION_TYPE_Realtor&#39;, &#39;ORGANIZATION_TYPE_Religion&#39;, &#39;ORGANIZATION_TYPE_Restaurant&#39;, &#39;ORGANIZATION_TYPE_School&#39;, &#39;ORGANIZATION_TYPE_Security&#39;, &#39;ORGANIZATION_TYPE_Security Ministries&#39;, &#39;ORGANIZATION_TYPE_Self-employed&#39;, &#39;ORGANIZATION_TYPE_Services&#39;, &#39;ORGANIZATION_TYPE_Telecom&#39;, &#39;ORGANIZATION_TYPE_Trade: type 1&#39;, &#39;ORGANIZATION_TYPE_Trade: type 2&#39;, &#39;ORGANIZATION_TYPE_Trade: type 3&#39;, &#39;ORGANIZATION_TYPE_Trade: type 4&#39;, &#39;ORGANIZATION_TYPE_Trade: type 5&#39;, &#39;ORGANIZATION_TYPE_Trade: type 6&#39;, &#39;ORGANIZATION_TYPE_Trade: type 7&#39;, &#39;ORGANIZATION_TYPE_Transport: type 1&#39;, &#39;ORGANIZATION_TYPE_Transport: type 2&#39;, &#39;ORGANIZATION_TYPE_Transport: type 3&#39;, &#39;ORGANIZATION_TYPE_Transport: type 4&#39;, &#39;ORGANIZATION_TYPE_University&#39;, &#39;ORGANIZATION_TYPE_XNA&#39;, &#39;FONDKAPREMONT_MODE_not specified&#39;, &#39;FONDKAPREMONT_MODE_org spec account&#39;, &#39;FONDKAPREMONT_MODE_reg oper account&#39;, &#39;FONDKAPREMONT_MODE_reg oper spec account&#39;, &#39;HOUSETYPE_MODE_block of flats&#39;, &#39;HOUSETYPE_MODE_specific housing&#39;, &#39;HOUSETYPE_MODE_terraced house&#39;, &#39;WALLSMATERIAL_MODE_Block&#39;, &#39;WALLSMATERIAL_MODE_Mixed&#39;, &#39;WALLSMATERIAL_MODE_Monolithic&#39;, &#39;WALLSMATERIAL_MODE_Others&#39;, &#39;WALLSMATERIAL_MODE_Panel&#39;, &#39;WALLSMATERIAL_MODE_Stone, brick&#39;, &#39;WALLSMATERIAL_MODE_Wooden&#39;, &#39;EMERGENCYSTATE_MODE_No&#39;, &#39;EMERGENCYSTATE_MODE_Yes&#39;, &#39;TARGET&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3segama异常值检测函数，添加异常值指示列</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_outliers_by_3segama</span>(<span class="params">data,fea</span>):</span></span><br><span class="line"></span><br><span class="line">    data_std = np.std(data[fea])</span><br><span class="line"></span><br><span class="line">    data_mean = np.mean(data[fea])</span><br><span class="line"></span><br><span class="line">    outliers_cut_off = data_std * <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    lower_rule = data_mean - outliers_cut_off</span><br><span class="line"></span><br><span class="line">    upper_rule = data_mean + outliers_cut_off</span><br><span class="line"></span><br><span class="line">    data[fea+<span class="string">&#x27;_outliers&#x27;</span>] = data[fea].apply(<span class="keyword">lambda</span> x:<span class="built_in">str</span>(<span class="string">&#x27;异常值&#x27;</span>) <span class="keyword">if</span> x &gt; upper_rule <span class="keyword">or</span> x &lt; lower_rule <span class="keyword">else</span> <span class="string">&#x27;正常值&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 异常值详情</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fea <span class="keyword">in</span> numerical_fea:</span><br><span class="line"></span><br><span class="line">    outlier_train = find_outliers_by_3segama(app_train,fea)</span><br><span class="line"></span><br><span class="line">outlier_train</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>SK_ID_CURR</th>      <th>NAME_CONTRACT_TYPE</th>      <th>FLAG_OWN_CAR</th>      <th>FLAG_OWN_REALTY</th>      <th>CNT_CHILDREN</th>      <th>AMT_INCOME_TOTAL</th>      <th>AMT_CREDIT</th>      <th>AMT_ANNUITY</th>      <th>AMT_GOODS_PRICE</th>      <th>REGION_POPULATION_RELATIVE</th>      <th>...</th>      <th>WALLSMATERIAL_MODE_Block_outliers</th>      <th>WALLSMATERIAL_MODE_Mixed_outliers</th>      <th>WALLSMATERIAL_MODE_Monolithic_outliers</th>      <th>WALLSMATERIAL_MODE_Others_outliers</th>      <th>WALLSMATERIAL_MODE_Panel_outliers</th>      <th>WALLSMATERIAL_MODE_Stone, brick_outliers</th>      <th>WALLSMATERIAL_MODE_Wooden_outliers</th>      <th>EMERGENCYSTATE_MODE_No_outliers</th>      <th>EMERGENCYSTATE_MODE_Yes_outliers</th>      <th>TARGET_outliers</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>100002</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>202500.0</td>      <td>406597.5</td>      <td>24700.5</td>      <td>351000.0</td>      <td>0.018801</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>异常值</td>    </tr>    <tr>      <th>1</th>      <td>100003</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>270000.0</td>      <td>1293502.5</td>      <td>35698.5</td>      <td>1129500.0</td>      <td>0.003541</td>      <td>...</td>      <td>异常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>    </tr>    <tr>      <th>2</th>      <td>100004</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>67500.0</td>      <td>135000.0</td>      <td>6750.0</td>      <td>135000.0</td>      <td>0.010032</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>    </tr>    <tr>      <th>3</th>      <td>100006</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>135000.0</td>      <td>312682.5</td>      <td>29686.5</td>      <td>297000.0</td>      <td>0.008019</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>    </tr>    <tr>      <th>4</th>      <td>100007</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>121500.0</td>      <td>513000.0</td>      <td>21865.5</td>      <td>513000.0</td>      <td>0.028663</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>307506</th>      <td>456251</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>157500.0</td>      <td>254700.0</td>      <td>27558.0</td>      <td>225000.0</td>      <td>0.032561</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>    </tr>    <tr>      <th>307507</th>      <td>456252</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>72000.0</td>      <td>269550.0</td>      <td>12001.5</td>      <td>225000.0</td>      <td>0.025164</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>    </tr>    <tr>      <th>307508</th>      <td>456253</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>153000.0</td>      <td>677664.0</td>      <td>29979.0</td>      <td>585000.0</td>      <td>0.005002</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>    </tr>    <tr>      <th>307509</th>      <td>456254</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>171000.0</td>      <td>370107.0</td>      <td>20205.0</td>      <td>319500.0</td>      <td>0.005313</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>异常值</td>    </tr>    <tr>      <th>307510</th>      <td>456255</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>157500.0</td>      <td>675000.0</td>      <td>49117.5</td>      <td>675000.0</td>      <td>0.046220</td>      <td>...</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>      <td>正常值</td>    </tr>  </tbody></table><p>307511 rows × 480 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正常值与异常值各自占比情况</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fea <span class="keyword">in</span> numerical_fea:</span><br><span class="line"></span><br><span class="line">    radio = outlier_train[fea+<span class="string">&#x27;_outliers&#x27;</span>].value_counts(<span class="string">&#x27;异常值&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(radio)</span><br></pre></td></tr></table></figure><pre><code>正常值    1.0Name: SK_ID_CURR_outliers, dtype: float64正常值    0.904787异常值    0.095213Name: NAME_CONTRACT_TYPE_outliers, dtype: float64正常值    1.0Name: FLAG_OWN_CAR_outliers, dtype: float64正常值    1.0Name: FLAG_OWN_REALTY_outliers, dtype: float64正常值    0.986108异常值    0.013892Name: CNT_CHILDREN_outliers, dtype: float64正常值    0.998524异常值    0.001476Name: AMT_INCOME_TOTAL_outliers, dtype: float64正常值    0.989415异常值    0.010585Name: AMT_CREDIT_outliers, dtype: float64正常值    0.990378异常值    0.009622Name: AMT_ANNUITY_outliers, dtype: float64正常值    0.98643异常值    0.01357Name: AMT_GOODS_PRICE_outliers, dtype: float64正常值    0.972645异常值    0.027355Name: REGION_POPULATION_RELATIVE_outliers, dtype: float64正常值    1.0Name: DAYS_BIRTH_outliers, dtype: float64正常值    1.0Name: DAYS_EMPLOYED_outliers, dtype: float64正常值    0.997564异常值    0.002436Name: DAYS_REGISTRATION_outliers, dtype: float64正常值    1.0Name: DAYS_ID_PUBLISH_outliers, dtype: float64正常值    0.989044异常值    0.010956Name: OWN_CAR_AGE_outliers, dtype: float64正常值    0.999997异常值    0.000003Name: FLAG_MOBIL_outliers, dtype: float64正常值    1.0Name: FLAG_EMP_PHONE_outliers, dtype: float64正常值    1.0Name: FLAG_WORK_PHONE_outliers, dtype: float64正常值    0.998133异常值    0.001867Name: FLAG_CONT_MOBILE_outliers, dtype: float64正常值    1.0Name: FLAG_PHONE_outliers, dtype: float64正常值    0.94328异常值    0.05672Name: FLAG_EMAIL_outliers, dtype: float64正常值    0.98697异常值    0.01303Name: CNT_FAM_MEMBERS_outliers, dtype: float64正常值    1.0Name: REGION_RATING_CLIENT_outliers, dtype: float64正常值    1.0Name: REGION_RATING_CLIENT_W_CITY_outliers, dtype: float64正常值    0.997977异常值    0.002023Name: HOUR_APPR_PROCESS_START_outliers, dtype: float64正常值    0.984856异常值    0.015144Name: REG_REGION_NOT_LIVE_REGION_outliers, dtype: float64正常值    0.949231异常值    0.050769Name: REG_REGION_NOT_WORK_REGION_outliers, dtype: float64正常值    0.959341异常值    0.040659Name: LIVE_REGION_NOT_WORK_REGION_outliers, dtype: float64正常值    0.921827异常值    0.078173Name: REG_CITY_NOT_LIVE_CITY_outliers, dtype: float64正常值    1.0Name: REG_CITY_NOT_WORK_CITY_outliers, dtype: float64正常值    1.0Name: LIVE_CITY_NOT_WORK_CITY_outliers, dtype: float64正常值    1.0Name: EXT_SOURCE_1_outliers, dtype: float64正常值    1.0Name: EXT_SOURCE_2_outliers, dtype: float64正常值    1.0Name: EXT_SOURCE_3_outliers, dtype: float64正常值    0.990303异常值    0.009697Name: APARTMENTS_AVG_outliers, dtype: float64正常值    0.993584异常值    0.006416Name: BASEMENTAREA_AVG_outliers, dtype: float64正常值    0.997743异常值    0.002257Name: YEARS_BEGINEXPLUATATION_AVG_outliers, dtype: float64正常值    0.99612异常值    0.00388Name: YEARS_BUILD_AVG_outliers, dtype: float64正常值    0.994455异常值    0.005545Name: COMMONAREA_AVG_outliers, dtype: float64正常值    0.992065异常值    0.007935Name: ELEVATORS_AVG_outliers, dtype: float64正常值    0.9928异常值    0.0072Name: ENTRANCES_AVG_outliers, dtype: float64正常值    0.991509异常值    0.008491Name: FLOORSMAX_AVG_outliers, dtype: float64正常值    0.998078异常值    0.001922Name: FLOORSMIN_AVG_outliers, dtype: float64正常值    0.993207异常值    0.006793Name: LANDAREA_AVG_outliers, dtype: float64正常值    0.994322异常值    0.005678Name: LIVINGAPARTMENTS_AVG_outliers, dtype: float64正常值    0.989623异常值    0.010377Name: LIVINGAREA_AVG_outliers, dtype: float64正常值    0.997652异常值    0.002348Name: NONLIVINGAPARTMENTS_AVG_outliers, dtype: float64正常值    0.992156异常值    0.007844Name: NONLIVINGAREA_AVG_outliers, dtype: float64正常值    0.990212异常值    0.009788Name: APARTMENTS_MODE_outliers, dtype: float64正常值    0.993291异常值    0.006709Name: BASEMENTAREA_MODE_outliers, dtype: float64正常值    0.997789异常值    0.002211Name: YEARS_BEGINEXPLUATATION_MODE_outliers, dtype: float64正常值    0.996072异常值    0.003928Name: YEARS_BUILD_MODE_outliers, dtype: float64正常值    0.994495异常值    0.005505Name: COMMONAREA_MODE_outliers, dtype: float64正常值    0.98909异常值    0.01091Name: ELEVATORS_MODE_outliers, dtype: float64正常值    0.991454异常值    0.008546Name: ENTRANCES_MODE_outliers, dtype: float64正常值    0.991421异常值    0.008579Name: FLOORSMAX_MODE_outliers, dtype: float64正常值    0.998439异常值    0.001561Name: FLOORSMIN_MODE_outliers, dtype: float64正常值    0.993041异常值    0.006959Name: LANDAREA_MODE_outliers, dtype: float64正常值    0.994124异常值    0.005876Name: LIVINGAPARTMENTS_MODE_outliers, dtype: float64正常值    0.989126异常值    0.010874Name: LIVINGAREA_MODE_outliers, dtype: float64正常值    0.997795异常值    0.002205Name: NONLIVINGAPARTMENTS_MODE_outliers, dtype: float64正常值    0.991994异常值    0.008006Name: NONLIVINGAREA_MODE_outliers, dtype: float64正常值    0.99013异常值    0.00987Name: APARTMENTS_MEDI_outliers, dtype: float64正常值    0.993525异常值    0.006475Name: BASEMENTAREA_MEDI_outliers, dtype: float64正常值    0.99788异常值    0.00212Name: YEARS_BEGINEXPLUATATION_MEDI_outliers, dtype: float64正常值    0.996078异常值    0.003922Name: YEARS_BUILD_MEDI_outliers, dtype: float64正常值    0.994397异常值    0.005603Name: COMMONAREA_MEDI_outliers, dtype: float64正常值    0.992101异常值    0.007899Name: ELEVATORS_MEDI_outliers, dtype: float64正常值    0.992761异常值    0.007239Name: ENTRANCES_MEDI_outliers, dtype: float64正常值    0.991109异常值    0.008891Name: FLOORSMAX_MEDI_outliers, dtype: float64正常值    0.998202异常值    0.001798Name: FLOORSMIN_MEDI_outliers, dtype: float64正常值    0.993064异常值    0.006936Name: LANDAREA_MEDI_outliers, dtype: float64正常值    0.994247异常值    0.005753Name: LIVINGAPARTMENTS_MEDI_outliers, dtype: float64正常值    0.989513异常值    0.010487Name: LIVINGAREA_MEDI_outliers, dtype: float64正常值    0.997659异常值    0.002341Name: NONLIVINGAPARTMENTS_MEDI_outliers, dtype: float64正常值    0.992091异常值    0.007909Name: NONLIVINGAREA_MEDI_outliers, dtype: float64正常值    0.989194异常值    0.010806Name: TOTALAREA_MODE_outliers, dtype: float64正常值    0.979965异常值    0.020035Name: OBS_30_CNT_SOCIAL_CIRCLE_outliers, dtype: float64正常值    0.977763异常值    0.022237Name: DEF_30_CNT_SOCIAL_CIRCLE_outliers, dtype: float64正常值    0.980537异常值    0.019463Name: OBS_60_CNT_SOCIAL_CIRCLE_outliers, dtype: float64正常值    0.987226异常值    0.012774Name: DEF_60_CNT_SOCIAL_CIRCLE_outliers, dtype: float64正常值    0.997919异常值    0.002081Name: DAYS_LAST_PHONE_CHANGE_outliers, dtype: float64正常值    0.999958异常值    0.000042Name: FLAG_DOCUMENT_2_outliers, dtype: float64正常值    1.0Name: FLAG_DOCUMENT_3_outliers, dtype: float64正常值    0.999919异常值    0.000081Name: FLAG_DOCUMENT_4_outliers, dtype: float64正常值    0.984885异常值    0.015115Name: FLAG_DOCUMENT_5_outliers, dtype: float64正常值    0.911945异常值    0.088055Name: FLAG_DOCUMENT_6_outliers, dtype: float64正常值    0.999808异常值    0.000192Name: FLAG_DOCUMENT_7_outliers, dtype: float64正常值    0.918624异常值    0.081376Name: FLAG_DOCUMENT_8_outliers, dtype: float64正常值    0.996104异常值    0.003896Name: FLAG_DOCUMENT_9_outliers, dtype: float64正常值    0.999977异常值    0.000023Name: FLAG_DOCUMENT_10_outliers, dtype: float64正常值    0.996088异常值    0.003912Name: FLAG_DOCUMENT_11_outliers, dtype: float64正常值    0.999993异常值    0.000007Name: FLAG_DOCUMENT_12_outliers, dtype: float64正常值    0.996475异常值    0.003525Name: FLAG_DOCUMENT_13_outliers, dtype: float64正常值    0.997064异常值    0.002936Name: FLAG_DOCUMENT_14_outliers, dtype: float64正常值    0.99879异常值    0.00121Name: FLAG_DOCUMENT_15_outliers, dtype: float64正常值    0.990072异常值    0.009928Name: FLAG_DOCUMENT_16_outliers, dtype: float64正常值    0.999733异常值    0.000267Name: FLAG_DOCUMENT_17_outliers, dtype: float64正常值    0.99187异常值    0.00813Name: FLAG_DOCUMENT_18_outliers, dtype: float64正常值    0.999405异常值    0.000595Name: FLAG_DOCUMENT_19_outliers, dtype: float64正常值    0.999493异常值    0.000507Name: FLAG_DOCUMENT_20_outliers, dtype: float64正常值    0.999665异常值    0.000335Name: FLAG_DOCUMENT_21_outliers, dtype: float64正常值    0.994712异常值    0.005288Name: AMT_REQ_CREDIT_BUREAU_HOUR_outliers, dtype: float64正常值    0.995158异常值    0.004842Name: AMT_REQ_CREDIT_BUREAU_DAY_outliers, dtype: float64正常值    0.972242异常值    0.027758Name: AMT_REQ_CREDIT_BUREAU_WEEK_outliers, dtype: float64正常值    0.98948异常值    0.01052Name: AMT_REQ_CREDIT_BUREAU_MON_outliers, dtype: float64正常值    0.992517异常值    0.007483Name: AMT_REQ_CREDIT_BUREAU_QRT_outliers, dtype: float64正常值    0.989061异常值    0.010939Name: AMT_REQ_CREDIT_BUREAU_YEAR_outliers, dtype: float64正常值    1.0Name: CODE_GENDER_F_outliers, dtype: float64正常值    1.0Name: CODE_GENDER_M_outliers, dtype: float64正常值    0.989376异常值    0.010624Name: NAME_TYPE_SUITE_Children_outliers, dtype: float64正常值    1.0Name: NAME_TYPE_SUITE_Family_outliers, dtype: float64正常值    0.999119异常值    0.000881Name: NAME_TYPE_SUITE_Group of people_outliers, dtype: float64正常值    0.997184异常值    0.002816Name: NAME_TYPE_SUITE_Other_A_outliers, dtype: float64正常值    0.994244异常值    0.005756Name: NAME_TYPE_SUITE_Other_B_outliers, dtype: float64正常值    0.963026异常值    0.036974Name: NAME_TYPE_SUITE_Spouse, partner_outliers, dtype: float64正常值    1.0Name: NAME_TYPE_SUITE_Unaccompanied_outliers, dtype: float64正常值    0.999967异常值    0.000033Name: NAME_INCOME_TYPE_Businessman_outliers, dtype: float64正常值    1.0Name: NAME_INCOME_TYPE_Commercial associate_outliers, dtype: float64正常值    1.0Name: NAME_INCOME_TYPE_Pensioner_outliers, dtype: float64正常值    0.929424异常值    0.070576Name: NAME_INCOME_TYPE_State servant_outliers, dtype: float64正常值    0.999941异常值    0.000059Name: NAME_INCOME_TYPE_Student_outliers, dtype: float64正常值    0.999928异常值    0.000072Name: NAME_INCOME_TYPE_Unemployed_outliers, dtype: float64正常值    1.0Name: NAME_INCOME_TYPE_Working_outliers, dtype: float64正常值    0.999467异常值    0.000533Name: NAME_EDUCATION_TYPE_Academic degree_outliers, dtype: float64正常值    1.0Name: NAME_EDUCATION_TYPE_Higher education_outliers, dtype: float64正常值    0.96658异常值    0.03342Name: NAME_EDUCATION_TYPE_Incomplete higher_outliers, dtype: float64正常值    0.987591异常值    0.012409Name: NAME_EDUCATION_TYPE_Lower secondary_outliers, dtype: float64正常值    1.0Name: NAME_EDUCATION_TYPE_Secondary / secondary special_outliers, dtype: float64正常值    0.903174异常值    0.096826Name: NAME_FAMILY_STATUS_Civil marriage_outliers, dtype: float64正常值    1.0Name: NAME_FAMILY_STATUS_Married_outliers, dtype: float64正常值    0.93571异常值    0.06429Name: NAME_FAMILY_STATUS_Separated_outliers, dtype: float64正常值    1.0Name: NAME_FAMILY_STATUS_Single / not married_outliers, dtype: float64正常值    0.947683异常值    0.052317Name: NAME_FAMILY_STATUS_Widow_outliers, dtype: float64正常值    0.996351异常值    0.003649Name: NAME_HOUSING_TYPE_Co-op apartment_outliers, dtype: float64正常值    1.0Name: NAME_HOUSING_TYPE_House / apartment_outliers, dtype: float64正常值    0.963634异常值    0.036366Name: NAME_HOUSING_TYPE_Municipal apartment_outliers, dtype: float64正常值    0.99149异常值    0.00851Name: NAME_HOUSING_TYPE_Office apartment_outliers, dtype: float64正常值    0.984127异常值    0.015873Name: NAME_HOUSING_TYPE_Rented apartment_outliers, dtype: float64正常值    0.951742异常值    0.048258Name: NAME_HOUSING_TYPE_With parents_outliers, dtype: float64正常值    0.968089异常值    0.031911Name: OCCUPATION_TYPE_Accountants_outliers, dtype: float64正常值    0.984869异常值    0.015131Name: OCCUPATION_TYPE_Cleaning staff_outliers, dtype: float64正常值    0.980664异常值    0.019336Name: OCCUPATION_TYPE_Cooking staff_outliers, dtype: float64正常值    0.910345异常值    0.089655Name: OCCUPATION_TYPE_Core staff_outliers, dtype: float64正常值    0.939505异常值    0.060495Name: OCCUPATION_TYPE_Drivers_outliers, dtype: float64正常值    0.998169异常值    0.001831Name: OCCUPATION_TYPE_HR staff_outliers, dtype: float64正常值    0.962993异常值    0.037007Name: OCCUPATION_TYPE_High skill tech staff_outliers, dtype: float64正常值    0.998289异常值    0.001711Name: OCCUPATION_TYPE_IT staff_outliers, dtype: float64正常值    1.0Name: OCCUPATION_TYPE_Laborers_outliers, dtype: float64正常值    0.993194异常值    0.006806Name: OCCUPATION_TYPE_Low-skill Laborers_outliers, dtype: float64正常值    0.930503异常值    0.069497Name: OCCUPATION_TYPE_Managers_outliers, dtype: float64正常值    0.972238异常值    0.027762Name: OCCUPATION_TYPE_Medicine staff_outliers, dtype: float64正常值    0.991376异常值    0.008624Name: OCCUPATION_TYPE_Private service staff_outliers, dtype: float64正常值    0.997558异常值    0.002442Name: OCCUPATION_TYPE_Realty agents_outliers, dtype: float64正常值    1.0Name: OCCUPATION_TYPE_Sales staff_outliers, dtype: float64正常值    0.995756异常值    0.004244Name: OCCUPATION_TYPE_Secretaries_outliers, dtype: float64正常值    0.978144异常值    0.021856Name: OCCUPATION_TYPE_Security staff_outliers, dtype: float64正常值    0.995616异常值    0.004384Name: OCCUPATION_TYPE_Waiters/barmen staff_outliers, dtype: float64正常值    1.0Name: WEEKDAY_APPR_PROCESS_START_FRIDAY_outliers, dtype: float64正常值    1.0Name: WEEKDAY_APPR_PROCESS_START_MONDAY_outliers, dtype: float64正常值    1.0Name: WEEKDAY_APPR_PROCESS_START_SATURDAY_outliers, dtype: float64正常值    0.947381异常值    0.052619Name: WEEKDAY_APPR_PROCESS_START_SUNDAY_outliers, dtype: float64正常值    1.0Name: WEEKDAY_APPR_PROCESS_START_THURSDAY_outliers, dtype: float64正常值    1.0Name: WEEKDAY_APPR_PROCESS_START_TUESDAY_outliers, dtype: float64正常值    1.0Name: WEEKDAY_APPR_PROCESS_START_WEDNESDAY_outliers, dtype: float64正常值    0.998605异常值    0.001395Name: ORGANIZATION_TYPE_Advertising_outliers, dtype: float64正常值    0.99202异常值    0.00798Name: ORGANIZATION_TYPE_Agriculture_outliers, dtype: float64正常值    0.991847异常值    0.008153Name: ORGANIZATION_TYPE_Bank_outliers, dtype: float64正常值    0.980541异常值    0.019459Name: ORGANIZATION_TYPE_Business Entity Type 1_outliers, dtype: float64正常值    0.965683异常值    0.034317Name: ORGANIZATION_TYPE_Business Entity Type 2_outliers, dtype: float64正常值    1.0Name: ORGANIZATION_TYPE_Business Entity Type 3_outliers, dtype: float64正常值    0.999155异常值    0.000845Name: ORGANIZATION_TYPE_Cleaning_outliers, dtype: float64正常值    0.978144异常值    0.021856Name: ORGANIZATION_TYPE_Construction_outliers, dtype: float64正常值    0.998768异常值    0.001232Name: ORGANIZATION_TYPE_Culture_outliers, dtype: float64正常值    0.996911异常值    0.003089Name: ORGANIZATION_TYPE_Electricity_outliers, dtype: float64正常值    0.998179异常值    0.001821Name: ORGANIZATION_TYPE_Emergency_outliers, dtype: float64正常值    0.966167异常值    0.033833Name: ORGANIZATION_TYPE_Government_outliers, dtype: float64正常值    0.996859异常值    0.003141Name: ORGANIZATION_TYPE_Hotel_outliers, dtype: float64正常值    0.990381异常值    0.009619Name: ORGANIZATION_TYPE_Housing_outliers, dtype: float64正常值    0.996621异常值    0.003379Name: ORGANIZATION_TYPE_Industry: type 1_outliers, dtype: float64正常值    0.999646异常值    0.000354Name: ORGANIZATION_TYPE_Industry: type 10_outliers, dtype: float64正常值    0.991207异常值    0.008793Name: ORGANIZATION_TYPE_Industry: type 11_outliers, dtype: float64正常值    0.9988异常值    0.0012Name: ORGANIZATION_TYPE_Industry: type 12_outliers, dtype: float64正常值    0.999782异常值    0.000218Name: ORGANIZATION_TYPE_Industry: type 13_outliers, dtype: float64正常值    0.998511异常值    0.001489Name: ORGANIZATION_TYPE_Industry: type 2_outliers, dtype: float64正常值    0.98934异常值    0.01066Name: ORGANIZATION_TYPE_Industry: type 3_outliers, dtype: float64正常值    0.997148异常值    0.002852Name: ORGANIZATION_TYPE_Industry: type 4_outliers, dtype: float64正常值    0.998052异常值    0.001948Name: ORGANIZATION_TYPE_Industry: type 5_outliers, dtype: float64正常值    0.999636异常值    0.000364Name: ORGANIZATION_TYPE_Industry: type 6_outliers, dtype: float64正常值    0.99575异常值    0.00425Name: ORGANIZATION_TYPE_Industry: type 7_outliers, dtype: float64正常值    0.999922异常值    0.000078Name: ORGANIZATION_TYPE_Industry: type 8_outliers, dtype: float64正常值    0.989048异常值    0.010952Name: ORGANIZATION_TYPE_Industry: type 9_outliers, dtype: float64正常值    0.998059异常值    0.001941Name: ORGANIZATION_TYPE_Insurance_outliers, dtype: float64正常值    0.977627异常值    0.022373Name: ORGANIZATION_TYPE_Kindergarten_outliers, dtype: float64正常值    0.999008异常值    0.000992Name: ORGANIZATION_TYPE_Legal Services_outliers, dtype: float64正常值    0.963601异常值    0.036399Name: ORGANIZATION_TYPE_Medicine_outliers, dtype: float64正常值    0.991434异常值    0.008566Name: ORGANIZATION_TYPE_Military_outliers, dtype: float64正常值    0.998969异常值    0.001031Name: ORGANIZATION_TYPE_Mobile_outliers, dtype: float64正常值    0.945748异常值    0.054252Name: ORGANIZATION_TYPE_Other_outliers, dtype: float64正常值    0.992387异常值    0.007613Name: ORGANIZATION_TYPE_Police_outliers, dtype: float64正常值    0.992986异常值    0.007014Name: ORGANIZATION_TYPE_Postal_outliers, dtype: float64正常值    0.998712异常值    0.001288Name: ORGANIZATION_TYPE_Realtor_outliers, dtype: float64正常值    0.999724异常值    0.000276Name: ORGANIZATION_TYPE_Religion_outliers, dtype: float64正常值    0.994111异常值    0.005889Name: ORGANIZATION_TYPE_Restaurant_outliers, dtype: float64正常值    0.971081异常值    0.028919Name: ORGANIZATION_TYPE_School_outliers, dtype: float64正常值    0.989441异常值    0.010559Name: ORGANIZATION_TYPE_Security_outliers, dtype: float64正常值    0.993581异常值    0.006419Name: ORGANIZATION_TYPE_Security Ministries_outliers, dtype: float64正常值    1.0Name: ORGANIZATION_TYPE_Self-employed_outliers, dtype: float64正常值    0.994878异常值    0.005122Name: ORGANIZATION_TYPE_Services_outliers, dtype: float64正常值    0.998124异常值    0.001876Name: ORGANIZATION_TYPE_Telecom_outliers, dtype: float64正常值    0.998868异常值    0.001132Name: ORGANIZATION_TYPE_Trade: type 1_outliers, dtype: float64正常值    0.993821异常值    0.006179Name: ORGANIZATION_TYPE_Trade: type 2_outliers, dtype: float64正常值    0.988644异常值    0.011356Name: ORGANIZATION_TYPE_Trade: type 3_outliers, dtype: float64正常值    0.999792异常值    0.000208Name: ORGANIZATION_TYPE_Trade: type 4_outliers, dtype: float64正常值    0.999841异常值    0.000159Name: ORGANIZATION_TYPE_Trade: type 5_outliers, dtype: float64正常值    0.997948异常值    0.002052Name: ORGANIZATION_TYPE_Trade: type 6_outliers, dtype: float64正常值    0.974534异常值    0.025466Name: ORGANIZATION_TYPE_Trade: type 7_outliers, dtype: float64正常值    0.999346异常值    0.000654Name: ORGANIZATION_TYPE_Transport: type 1_outliers, dtype: float64正常值    0.992833异常值    0.007167Name: ORGANIZATION_TYPE_Transport: type 2_outliers, dtype: float64正常值    0.99614异常值    0.00386Name: ORGANIZATION_TYPE_Transport: type 3_outliers, dtype: float64正常值    0.982446异常值    0.017554Name: ORGANIZATION_TYPE_Transport: type 4_outliers, dtype: float64正常值    0.995685异常值    0.004315Name: ORGANIZATION_TYPE_University_outliers, dtype: float64正常值    1.0Name: ORGANIZATION_TYPE_XNA_outliers, dtype: float64正常值    0.981506异常值    0.018494Name: FONDKAPREMONT_MODE_not specified_outliers, dtype: float64正常值    0.981727异常值    0.018273Name: FONDKAPREMONT_MODE_org spec account_outliers, dtype: float64正常值    1.0Name: FONDKAPREMONT_MODE_reg oper account_outliers, dtype: float64正常值    0.960717异常值    0.039283Name: FONDKAPREMONT_MODE_reg oper spec account_outliers, dtype: float64正常值    1.0Name: HOUSETYPE_MODE_block of flats_outliers, dtype: float64正常值    0.995125异常值    0.004875Name: HOUSETYPE_MODE_specific housing_outliers, dtype: float64正常值    0.996059异常值    0.003941Name: HOUSETYPE_MODE_terraced house_outliers, dtype: float64正常值    0.96991异常值    0.03009Name: WALLSMATERIAL_MODE_Block_outliers, dtype: float64正常值    0.992534异常值    0.007466Name: WALLSMATERIAL_MODE_Mixed_outliers, dtype: float64正常值    0.994215异常值    0.005785Name: WALLSMATERIAL_MODE_Monolithic_outliers, dtype: float64正常值    0.994716异常值    0.005284Name: WALLSMATERIAL_MODE_Others_outliers, dtype: float64正常值    1.0Name: WALLSMATERIAL_MODE_Panel_outliers, dtype: float64正常值    1.0Name: WALLSMATERIAL_MODE_Stone, brick_outliers, dtype: float64正常值    0.982563异常值    0.017437Name: WALLSMATERIAL_MODE_Wooden_outliers, dtype: float64正常值    1.0Name: EMERGENCYSTATE_MODE_No_outliers, dtype: float64正常值    0.99243异常值    0.00757Name: EMERGENCYSTATE_MODE_Yes_outliers, dtype: float64正常值    0.919271异常值    0.080729Name: TARGET_outliers, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查异常值，利用描述统计describe查看特征的均值极大值极小值等结合常识和业务判断是否存在异常</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看用户年龄分布，此处该特征为负数，反映的是申请贷款前用户存活天数故除以-365得到年龄</span></span><br><span class="line"></span><br><span class="line">(app_train[<span class="string">&#x27;DAYS_BIRTH&#x27;</span>] / -<span class="number">365</span>).describe()</span><br></pre></td></tr></table></figure><pre><code>count    307511.000000mean         43.936973std          11.956133min          20.51780825%          34.00821950%          43.15068575%          53.923288max          69.120548Name: DAYS_BIRTH, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看工作年限，此处结果最小值为-1000年明显异常</span></span><br><span class="line"></span><br><span class="line">(app_train[<span class="string">&#x27;DAYS_EMPLOYED&#x27;</span>] / -<span class="number">365</span>).describe()</span><br></pre></td></tr></table></figure><pre><code>count    307511.000000mean       -174.835742std         387.056895min       -1000.66575325%           0.79178150%           3.32328875%           7.561644max          49.073973Name: DAYS_EMPLOYED, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 经查看天数在数据集中均表示为负数，365243可能为替代缺失值的数字</span></span><br><span class="line"></span><br><span class="line">app_train[<span class="string">&#x27;DAYS_EMPLOYED&#x27;</span>].plot.hist(title = <span class="string">&#x27;Days Employment Histogram&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Days Employment&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 0, &#39;Days Employment&#39;)</code></pre><p><a href="https://imgtu.com/i/fqvOt1"><img src="https://z3.ax1x.com/2021/08/19/fqvOt1.png" alt="fqvOt1.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看异常数据的违约率是否比其他的数据高，可以看到异常值违约率更低</span></span><br><span class="line"></span><br><span class="line">anom = app_train[app_train[<span class="string">&#x27;DAYS_EMPLOYED&#x27;</span>] == <span class="number">365243</span>]</span><br><span class="line"></span><br><span class="line">non_anom = app_train[app_train[<span class="string">&#x27;DAYS_EMPLOYED&#x27;</span>] != <span class="number">365243</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The non-anomalies default on %0.2f%% of loans&#x27;</span> % (<span class="number">100</span> * non_anom[<span class="string">&#x27;TARGET&#x27;</span>].mean()))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The anomalies default on %0.2f%% of loans&#x27;</span> % (<span class="number">100</span> * anom[<span class="string">&#x27;TARGET&#x27;</span>].mean()))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;There are %d anomalous days of employment&#x27;</span> % <span class="built_in">len</span>(anom))</span><br></pre></td></tr></table></figure><pre><code>The non-anomalies default on 8.66% of loansThe anomalies default on 5.40% of loansThere are 55374 anomalous days of employment</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建新列表示该数据是否异常</span></span><br><span class="line"></span><br><span class="line">app_train[<span class="string">&#x27;DAYS_EMPLOYED_ANOM&#x27;</span>] = app_train[<span class="string">&quot;DAYS_EMPLOYED&quot;</span>] == <span class="number">365243</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用缺失值替换空值标志</span></span><br><span class="line"></span><br><span class="line">app_train[<span class="string">&#x27;DAYS_EMPLOYED&#x27;</span>].replace(&#123;<span class="number">365243</span>: np.nan&#125;, inplace = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app_train[<span class="string">&#x27;DAYS_EMPLOYED&#x27;</span>].plot.hist(title = <span class="string">&#x27;Days Employment Histogram&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Days Employment&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 0, &#39;Days Employment&#39;)</code></pre><p><a href="https://imgtu.com/i/fqvLkR"><img src="https://z3.ax1x.com/2021/08/19/fqvLkR.png" alt="fqvLkR.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对测试集做相同操作</span></span><br><span class="line"></span><br><span class="line">app_test[<span class="string">&#x27;DAYS_EMPLOYED_ANOM&#x27;</span>] = app_test[<span class="string">&quot;DAYS_EMPLOYED&quot;</span>] == <span class="number">365243</span></span><br><span class="line"></span><br><span class="line">app_test[<span class="string">&quot;DAYS_EMPLOYED&quot;</span>].replace(&#123;<span class="number">365243</span>: np.nan&#125;, inplace = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;There are %d anomalies in the test data out of %d entries&#x27;</span> % (app_test[<span class="string">&quot;DAYS_EMPLOYED_ANOM&quot;</span>].<span class="built_in">sum</span>(), <span class="built_in">len</span>(app_test)))</span><br></pre></td></tr></table></figure><pre><code>There are 9274 anomalies in the test data out of 48744 entries</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看特征与标签的相关性，并排序</span></span><br><span class="line"></span><br><span class="line">correlations = app_train.corr()[<span class="string">&#x27;TARGET&#x27;</span>].sort_values()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Most Positive Correlations:\n&#x27;</span>, correlations.tail(<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nMost Negative Correlations:\n&#x27;</span>, correlations.head(<span class="number">15</span>))</span><br></pre></td></tr></table></figure><pre><code>Most Positive Correlations: OCCUPATION_TYPE_Laborers                             0.043019FLAG_DOCUMENT_3                                      0.044346REG_CITY_NOT_LIVE_CITY                               0.044395FLAG_EMP_PHONE                                       0.045982NAME_EDUCATION_TYPE_Secondary / secondary special    0.049824REG_CITY_NOT_WORK_CITY                               0.050994DAYS_ID_PUBLISH                                      0.051457CODE_GENDER_M                                        0.054713DAYS_LAST_PHONE_CHANGE                               0.055218NAME_INCOME_TYPE_Working                             0.057481REGION_RATING_CLIENT                                 0.058899REGION_RATING_CLIENT_W_CITY                          0.060893DAYS_EMPLOYED                                        0.074958DAYS_BIRTH                                           0.078239TARGET                                               1.000000Name: TARGET, dtype: float64Most Negative Correlations: EXT_SOURCE_3                           -0.178919EXT_SOURCE_2                           -0.160472EXT_SOURCE_1                           -0.155317NAME_EDUCATION_TYPE_Higher education   -0.056593CODE_GENDER_F                          -0.054704NAME_INCOME_TYPE_Pensioner             -0.046209DAYS_EMPLOYED_ANOM                     -0.045987ORGANIZATION_TYPE_XNA                  -0.045987FLOORSMAX_AVG                          -0.044003FLOORSMAX_MEDI                         -0.043768FLOORSMAX_MODE                         -0.043226EMERGENCYSTATE_MODE_No                 -0.042201HOUSETYPE_MODE_block of flats          -0.040594AMT_GOODS_PRICE                        -0.039645REGION_POPULATION_RELATIVE             -0.037227Name: TARGET, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 年龄特征天数在源数据中是负的，年龄越大应越不容易违约，在此处对该数据上了绝对值重新计算相关性</span></span><br><span class="line"></span><br><span class="line">app_train[<span class="string">&#x27;DAYS_BIRTH&#x27;</span>] = <span class="built_in">abs</span>(app_train[<span class="string">&#x27;DAYS_BIRTH&#x27;</span>])</span><br><span class="line"></span><br><span class="line">app_train[<span class="string">&#x27;DAYS_BIRTH&#x27;</span>].corr(app_train[<span class="string">&#x27;TARGET&#x27;</span>])</span><br></pre></td></tr></table></figure><pre><code>-0.07823930830982712</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置图形样式</span></span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">&#x27;fivethirtyeight&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对客户年龄分布进行作图</span></span><br><span class="line"></span><br><span class="line">plt.hist(app_train[<span class="string">&#x27;DAYS_BIRTH&#x27;</span>] / <span class="number">365</span>, edgecolor = <span class="string">&#x27;k&#x27;</span>, bins = <span class="number">25</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Age of Client&#x27;</span>); plt.xlabel(<span class="string">&#x27;Age (years)&#x27;</span>); plt.ylabel(<span class="string">&#x27;Count&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0, 0.5, &#39;Count&#39;)</code></pre><p><a href="https://imgtu.com/i/fqvx1K"><img src="https://z3.ax1x.com/2021/08/19/fqvx1K.png" alt="fqvx1K.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 未违约用户年龄的KDE图</span></span><br><span class="line"></span><br><span class="line">sns.kdeplot(data = app_train.loc[app_train[<span class="string">&#x27;TARGET&#x27;</span>] == <span class="number">0</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>] / <span class="number">365</span>, label = <span class="string">&#x27;target == 0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 违约用户年龄的KDE图</span></span><br><span class="line"></span><br><span class="line">sns.kdeplot(data = app_train.loc[app_train[<span class="string">&#x27;TARGET&#x27;</span>] == <span class="number">1</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>] / <span class="number">365</span>, label = <span class="string">&#x27;target == 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 坐标轴</span></span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Age (years)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Distribution of Ages&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()    <span class="comment"># 重要，没有显示标签语句，原图设置了标签但不显示</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x158876e93c8&gt;</code></pre><p><a href="https://imgtu.com/i/fqvvp6"><img src="https://z3.ax1x.com/2021/08/19/fqvvp6.png" alt="fqvvp6.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对年龄进行分箱</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将年龄数据取出</span></span><br><span class="line"></span><br><span class="line">age_data = app_train[[<span class="string">&#x27;TARGET&#x27;</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">age_data[<span class="string">&#x27;YEARS_BIRTH&#x27;</span>] = age_data[<span class="string">&#x27;DAYS_BIRTH&#x27;</span>] / <span class="number">365</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将年龄数据分箱，利用np.linspace在20-70之间生成11个数来划分区间</span></span><br><span class="line"></span><br><span class="line">age_data[<span class="string">&#x27;YEARS_BINNED&#x27;</span>] = pd.cut(age_data[<span class="string">&#x27;YEARS_BIRTH&#x27;</span>], bins = np.linspace(<span class="number">20</span>, <span class="number">70</span>, num = <span class="number">11</span>))</span><br><span class="line"></span><br><span class="line">age_data.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>TARGET</th>      <th>DAYS_BIRTH</th>      <th>YEARS_BIRTH</th>      <th>YEARS_BINNED</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>9461</td>      <td>25.920548</td>      <td>(25.0, 30.0]</td>    </tr>    <tr>      <th>1</th>      <td>0</td>      <td>16765</td>      <td>45.931507</td>      <td>(45.0, 50.0]</td>    </tr>    <tr>      <th>2</th>      <td>0</td>      <td>19046</td>      <td>52.180822</td>      <td>(50.0, 55.0]</td>    </tr>    <tr>      <th>3</th>      <td>0</td>      <td>19005</td>      <td>52.068493</td>      <td>(50.0, 55.0]</td>    </tr>    <tr>      <th>4</th>      <td>0</td>      <td>19932</td>      <td>54.608219</td>      <td>(50.0, 55.0]</td>    </tr>    <tr>      <th>5</th>      <td>0</td>      <td>16941</td>      <td>46.413699</td>      <td>(45.0, 50.0]</td>    </tr>    <tr>      <th>6</th>      <td>0</td>      <td>13778</td>      <td>37.747945</td>      <td>(35.0, 40.0]</td>    </tr>    <tr>      <th>7</th>      <td>0</td>      <td>18850</td>      <td>51.643836</td>      <td>(50.0, 55.0]</td>    </tr>    <tr>      <th>8</th>      <td>0</td>      <td>20099</td>      <td>55.065753</td>      <td>(55.0, 60.0]</td>    </tr>    <tr>      <th>9</th>      <td>0</td>      <td>14469</td>      <td>39.641096</td>      <td>(35.0, 40.0]</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据分箱进行分组并求均值</span></span><br><span class="line"></span><br><span class="line">age_groups  = age_data.groupby(<span class="string">&#x27;YEARS_BINNED&#x27;</span>).mean()</span><br><span class="line"></span><br><span class="line">age_groups</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>TARGET</th>      <th>DAYS_BIRTH</th>      <th>YEARS_BIRTH</th>    </tr>    <tr>      <th>YEARS_BINNED</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>(20.0, 25.0]</th>      <td>0.123036</td>      <td>8532.795625</td>      <td>23.377522</td>    </tr>    <tr>      <th>(25.0, 30.0]</th>      <td>0.111436</td>      <td>10155.219250</td>      <td>27.822518</td>    </tr>    <tr>      <th>(30.0, 35.0]</th>      <td>0.102814</td>      <td>11854.848377</td>      <td>32.479037</td>    </tr>    <tr>      <th>(35.0, 40.0]</th>      <td>0.089414</td>      <td>13707.908253</td>      <td>37.555913</td>    </tr>    <tr>      <th>(40.0, 45.0]</th>      <td>0.078491</td>      <td>15497.661233</td>      <td>42.459346</td>    </tr>    <tr>      <th>(45.0, 50.0]</th>      <td>0.074171</td>      <td>17323.900441</td>      <td>47.462741</td>    </tr>    <tr>      <th>(50.0, 55.0]</th>      <td>0.066968</td>      <td>19196.494791</td>      <td>52.593136</td>    </tr>    <tr>      <th>(55.0, 60.0]</th>      <td>0.055314</td>      <td>20984.262742</td>      <td>57.491131</td>    </tr>    <tr>      <th>(60.0, 65.0]</th>      <td>0.052737</td>      <td>22780.547460</td>      <td>62.412459</td>    </tr>    <tr>      <th>(65.0, 70.0]</th>      <td>0.037270</td>      <td>24292.614340</td>      <td>66.555108</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将年龄分箱和平均违约率作条形图</span></span><br><span class="line"></span><br><span class="line">plt.bar(age_groups.index.astype(<span class="built_in">str</span>), <span class="number">100</span> * age_groups[<span class="string">&#x27;TARGET&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 坐标轴</span></span><br><span class="line"></span><br><span class="line">plt.xticks(rotation = <span class="number">75</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Age Group (years)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Failure to Repay (%)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Failure to Repay by Age Group&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 1.0, &#39;Failure to Repay by Age Group&#39;)</code></pre><p><a href="https://imgtu.com/i/fqvz6O"><img src="https://z3.ax1x.com/2021/08/19/fqvz6O.png" alt="fqvz6O.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查三个与目标负相关最强的变量彼此之间和与目标等属性间的相关性</span></span><br><span class="line"></span><br><span class="line">ext_data = app_train[[<span class="string">&#x27;TARGET&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_1&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_2&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_3&#x27;</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">ext_data_corrs = ext_data.corr()</span><br><span class="line"></span><br><span class="line">ext_data_corrs</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>TARGET</th>      <th>EXT_SOURCE_1</th>      <th>EXT_SOURCE_2</th>      <th>EXT_SOURCE_3</th>      <th>DAYS_BIRTH</th>    </tr>  </thead>  <tbody>    <tr>      <th>TARGET</th>      <td>1.000000</td>      <td>-0.155317</td>      <td>-0.160472</td>      <td>-0.178919</td>      <td>-0.078239</td>    </tr>    <tr>      <th>EXT_SOURCE_1</th>      <td>-0.155317</td>      <td>1.000000</td>      <td>0.213982</td>      <td>0.186846</td>      <td>0.600610</td>    </tr>    <tr>      <th>EXT_SOURCE_2</th>      <td>-0.160472</td>      <td>0.213982</td>      <td>1.000000</td>      <td>0.109167</td>      <td>0.091996</td>    </tr>    <tr>      <th>EXT_SOURCE_3</th>      <td>-0.178919</td>      <td>0.186846</td>      <td>0.109167</td>      <td>1.000000</td>      <td>0.205478</td>    </tr>    <tr>      <th>DAYS_BIRTH</th>      <td>-0.078239</td>      <td>0.600610</td>      <td>0.091996</td>      <td>0.205478</td>      <td>1.000000</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对相关性作热度图 annot=True格子上显示数字 vmin\vmax确定颜色范围</span></span><br><span class="line"></span><br><span class="line">sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = -<span class="number">0.25</span>, annot = <span class="literal">True</span>, vmax = <span class="number">0.6</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Correlation Heatmap&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 1.0, &#39;Correlation Heatmap&#39;)</code></pre><p><a href="https://imgtu.com/i/fqxSXD"><img src="https://z3.ax1x.com/2021/08/19/fqxSXD.png" alt="fqxSXD.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">10</span>, <span class="number">12</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历三个变量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, source <span class="keyword">in</span> <span class="built_in">enumerate</span>([<span class="string">&#x27;EXT_SOURCE_1&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_2&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_3&#x27;</span>]):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># subplot三个整数是子图行数、列数和索引值</span></span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">3</span>, <span class="number">1</span>, i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 未违约客户KDE图</span></span><br><span class="line"></span><br><span class="line">    sns.kdeplot(app_train.loc[app_train[<span class="string">&#x27;TARGET&#x27;</span>] == <span class="number">0</span>, source], label = <span class="string">&#x27;target == 0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 违约客户KDE图</span></span><br><span class="line"></span><br><span class="line">    sns.kdeplot(app_train.loc[app_train[<span class="string">&#x27;TARGET&#x27;</span>] == <span class="number">1</span>, source], label = <span class="string">&#x27;target == 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 坐标轴</span></span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">&#x27;Distribution of %s by Target Value&#x27;</span> % source)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;%s&#x27;</span> % source); plt.ylabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">plt.tight_layout(h_pad = <span class="number">2.5</span>)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fqx9ne"><img src="https://z3.ax1x.com/2021/08/19/fqx9ne.png" alt="fqx9ne.png"></a></p><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>两种简单的特征构建方式</p><ul><li>多项式特征</li><li>领域知识特征  </li></ul><p>构造的特征是否有用不能轻易断定，只有试了之后看效果才能知道。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多项式特征通过scikit-learn polynomialfeatures构建</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为构建多项式特征构建新的df</span></span><br><span class="line"></span><br><span class="line">poly_features = app_train[[<span class="string">&#x27;EXT_SOURCE_1&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_2&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_3&#x27;</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>, <span class="string">&#x27;TARGET&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">poly_features_test = app_test[[<span class="string">&#x27;EXT_SOURCE_1&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_2&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_3&#x27;</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缺失值填充策略中位数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"></span><br><span class="line">imputer = SimpleImputer(strategy = <span class="string">&#x27;median&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">poly_target = poly_features[<span class="string">&#x27;TARGET&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">poly_features = poly_features.drop(columns = [<span class="string">&#x27;TARGET&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行缺失值填充，注意以训练集为基准测试集作相同变化</span></span><br><span class="line"></span><br><span class="line">poly_features = imputer.fit_transform(poly_features)</span><br><span class="line"></span><br><span class="line">poly_features_test = imputer.transform(poly_features_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures                             </span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建多项式特征，定义度数</span></span><br><span class="line"></span><br><span class="line">poly_transformer = PolynomialFeatures(degree = <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练多项式特征</span></span><br><span class="line"></span><br><span class="line">poly_transformer.fit(poly_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成特征</span></span><br><span class="line"></span><br><span class="line">poly_features = poly_transformer.transform(poly_features)</span><br><span class="line"></span><br><span class="line">poly_features_test = poly_transformer.transform(poly_features_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Polynomial Features shape: &#x27;</span>, poly_features.shape)</span><br></pre></td></tr></table></figure><pre><code>Polynomial Features shape:  (307511, 35)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建特征很多使用get_feature_names为新特征命名,并预览前15个</span></span><br><span class="line"></span><br><span class="line">poly_transformer.get_feature_names(input_features = [<span class="string">&#x27;EXT_SOURCE_1&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_2&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_3&#x27;</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>])[:<span class="number">15</span>]</span><br></pre></td></tr></table></figure><pre><code>[&#39;1&#39;, &#39;EXT_SOURCE_1&#39;, &#39;EXT_SOURCE_2&#39;, &#39;EXT_SOURCE_3&#39;, &#39;DAYS_BIRTH&#39;, &#39;EXT_SOURCE_1^2&#39;, &#39;EXT_SOURCE_1 EXT_SOURCE_2&#39;, &#39;EXT_SOURCE_1 EXT_SOURCE_3&#39;, &#39;EXT_SOURCE_1 DAYS_BIRTH&#39;, &#39;EXT_SOURCE_2^2&#39;, &#39;EXT_SOURCE_2 EXT_SOURCE_3&#39;, &#39;EXT_SOURCE_2 DAYS_BIRTH&#39;, &#39;EXT_SOURCE_3^2&#39;, &#39;EXT_SOURCE_3 DAYS_BIRTH&#39;, &#39;DAYS_BIRTH^2&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查新特征与目标的相关度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为新特征建立df </span></span><br><span class="line"></span><br><span class="line">poly_features = pd.DataFrame(poly_features, </span><br><span class="line"></span><br><span class="line">                             columns = poly_transformer.get_feature_names([<span class="string">&#x27;EXT_SOURCE_1&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_2&#x27;</span>, </span><br><span class="line"></span><br><span class="line">                                                                           <span class="string">&#x27;EXT_SOURCE_3&#x27;</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入target列特征</span></span><br><span class="line"></span><br><span class="line">poly_features[<span class="string">&#x27;TARGET&#x27;</span>] = poly_target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看与target的相关性并排序</span></span><br><span class="line"></span><br><span class="line">poly_corrs = poly_features.corr()[<span class="string">&#x27;TARGET&#x27;</span>].sort_values()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看前十和后五项</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(poly_corrs.head(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(poly_corrs.tail(<span class="number">5</span>))</span><br></pre></td></tr></table></figure><pre><code>EXT_SOURCE_2 EXT_SOURCE_3                -0.193939EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3   -0.189605EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH     -0.181283EXT_SOURCE_2^2 EXT_SOURCE_3              -0.176428EXT_SOURCE_2 EXT_SOURCE_3^2              -0.172282EXT_SOURCE_1 EXT_SOURCE_2                -0.166625EXT_SOURCE_1 EXT_SOURCE_3                -0.164065EXT_SOURCE_2                             -0.160295EXT_SOURCE_2 DAYS_BIRTH                  -0.156873EXT_SOURCE_1 EXT_SOURCE_2^2              -0.156867Name: TARGET, dtype: float64DAYS_BIRTH     -0.078239DAYS_BIRTH^2   -0.076672DAYS_BIRTH^3   -0.074273TARGET          1.0000001                    NaNName: TARGET, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为测试特征新建df</span></span><br><span class="line"></span><br><span class="line">poly_features_test = pd.DataFrame(poly_features_test, </span><br><span class="line"></span><br><span class="line">                                  columns = poly_transformer.get_feature_names([<span class="string">&#x27;EXT_SOURCE_1&#x27;</span>, <span class="string">&#x27;EXT_SOURCE_2&#x27;</span>, </span><br><span class="line"></span><br><span class="line">                                                                                <span class="string">&#x27;EXT_SOURCE_3&#x27;</span>, <span class="string">&#x27;DAYS_BIRTH&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将多项式特征与训练特征合并，以sk_id_curr为引，how=left保留所有左表信息，将右表拼上来不能对其的部分用NAN填充</span></span><br><span class="line"></span><br><span class="line">poly_features[<span class="string">&#x27;SK_ID_CURR&#x27;</span>] = app_train[<span class="string">&#x27;SK_ID_CURR&#x27;</span>]</span><br><span class="line"></span><br><span class="line">app_train_poly = app_train.merge(poly_features, on = <span class="string">&#x27;SK_ID_CURR&#x27;</span>, how = <span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 同样操作也作用于测试集</span></span><br><span class="line"></span><br><span class="line">poly_features_test[<span class="string">&#x27;SK_ID_CURR&#x27;</span>] = app_test[<span class="string">&#x27;SK_ID_CURR&#x27;</span>]</span><br><span class="line"></span><br><span class="line">app_test_poly = app_test.merge(poly_features_test, on = <span class="string">&#x27;SK_ID_CURR&#x27;</span>, how = <span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练集和数据集的特征对齐</span></span><br><span class="line"></span><br><span class="line">app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = <span class="string">&#x27;inner&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看训练集测试集特征尺寸</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Training data with polynomial features shape: &#x27;</span>, app_train_poly.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Testing data with polynomial features shape:  &#x27;</span>, app_test_poly.shape)</span><br></pre></td></tr></table></figure><pre><code>Training data with polynomial features shape:  (307511, 275)Testing data with polynomial features shape:   (48744, 275)</code></pre><ul><li>领域知识特征<ul><li>CREDIT_INCOME_PERCENT: 信用金额相对于客户收入的百分比</li><li>ANNUITY_INCOME_PERCENT: 贷款年金相对于客户收入的百分比</li><li>CREDIT_TERM: 支付期限以月为单位(因为年金是每月到期的金额</li><li>DAYS_EMPLOYED_PERCENT: 雇佣天数占客户年龄的百分比</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">app_train_domain = app_train.copy()</span><br><span class="line"></span><br><span class="line">app_test_domain = app_test.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造训练集相关特征</span></span><br><span class="line"></span><br><span class="line">app_train_domain[<span class="string">&#x27;CREDIT_INCOME_PERCENT&#x27;</span>] = app_train_domain[<span class="string">&#x27;AMT_CREDIT&#x27;</span>] / app_train_domain[<span class="string">&#x27;AMT_INCOME_TOTAL&#x27;</span>]</span><br><span class="line"></span><br><span class="line">app_train_domain[<span class="string">&#x27;ANNUITY_INCOME_PERCENT&#x27;</span>] = app_train_domain[<span class="string">&#x27;AMT_ANNUITY&#x27;</span>] / app_train_domain[<span class="string">&#x27;AMT_INCOME_TOTAL&#x27;</span>]</span><br><span class="line"></span><br><span class="line">app_train_domain[<span class="string">&#x27;CREDIT_TERM&#x27;</span>] = app_train_domain[<span class="string">&#x27;AMT_ANNUITY&#x27;</span>] / app_train_domain[<span class="string">&#x27;AMT_CREDIT&#x27;</span>]</span><br><span class="line"></span><br><span class="line">app_train_domain[<span class="string">&#x27;DAYS_EMPLOYED_PERCENT&#x27;</span>] = app_train_domain[<span class="string">&#x27;DAYS_EMPLOYED&#x27;</span>] / app_train_domain[<span class="string">&#x27;DAYS_BIRTH&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试集上采取相同操作</span></span><br><span class="line"></span><br><span class="line">app_test_domain[<span class="string">&#x27;CREDIT_INCOME_PERCENT&#x27;</span>] = app_test_domain[<span class="string">&#x27;AMT_CREDIT&#x27;</span>] / app_test_domain[<span class="string">&#x27;AMT_INCOME_TOTAL&#x27;</span>]</span><br><span class="line"></span><br><span class="line">app_test_domain[<span class="string">&#x27;ANNUITY_INCOME_PERCENT&#x27;</span>] = app_test_domain[<span class="string">&#x27;AMT_ANNUITY&#x27;</span>] / app_test_domain[<span class="string">&#x27;AMT_INCOME_TOTAL&#x27;</span>]</span><br><span class="line"></span><br><span class="line">app_test_domain[<span class="string">&#x27;CREDIT_TERM&#x27;</span>] = app_test_domain[<span class="string">&#x27;AMT_ANNUITY&#x27;</span>] / app_test_domain[<span class="string">&#x27;AMT_CREDIT&#x27;</span>]</span><br><span class="line"></span><br><span class="line">app_test_domain[<span class="string">&#x27;DAYS_EMPLOYED_PERCENT&#x27;</span>] = app_test_domain[<span class="string">&#x27;DAYS_EMPLOYED&#x27;</span>] / app_test_domain[<span class="string">&#x27;DAYS_BIRTH&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化新特征</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>, <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历新特征</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, feature <span class="keyword">in</span> <span class="built_in">enumerate</span>([<span class="string">&#x27;CREDIT_INCOME_PERCENT&#x27;</span>, <span class="string">&#x27;ANNUITY_INCOME_PERCENT&#x27;</span>, <span class="string">&#x27;CREDIT_TERM&#x27;</span>, <span class="string">&#x27;DAYS_EMPLOYED_PERCENT&#x27;</span>]):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建子图，4行1列编号为i+1</span></span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">4</span>, <span class="number">1</span>, i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 未违约kde图</span></span><br><span class="line"></span><br><span class="line">    sns.kdeplot(app_train_domain.loc[app_train_domain[<span class="string">&#x27;TARGET&#x27;</span>] == <span class="number">0</span>, feature], label = <span class="string">&#x27;target == 0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 违约kde图</span></span><br><span class="line"></span><br><span class="line">    sns.kdeplot(app_train_domain.loc[app_train_domain[<span class="string">&#x27;TARGET&#x27;</span>] == <span class="number">1</span>, feature], label = <span class="string">&#x27;target == 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 标签及坐标轴</span></span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">&#x27;Distribution of %s by Target Value&#x27;</span> % feature)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;%s&#x27;</span> % feature)</span><br><span class="line"></span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.legend()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">plt.tight_layout(h_pad = <span class="number">2.5</span>)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fqxFAA"><img src="https://z3.ax1x.com/2021/08/19/fqxFAA.png" alt="fqxFAA.png"></a></p><h2 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h2><p>首先对数据进行预处理：</p><ul><li><p>对象数据编码(encoding)</p></li><li><p>填充缺失值(imputation)</p></li><li><p>归一化特征范围(feature scaling)</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查训练集中是否包含target,包含的话删掉</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;TARGET&#x27;</span> <span class="keyword">in</span> app_train:</span><br><span class="line"></span><br><span class="line">    train = app_train.drop(columns = [<span class="string">&#x27;TARGET&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">    train = app_train.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征名</span></span><br><span class="line"></span><br><span class="line">features = <span class="built_in">list</span>(train.columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制测试集</span></span><br><span class="line"></span><br><span class="line">test = app_test.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对缺失值采取中位数填充策略</span></span><br><span class="line"></span><br><span class="line">imputer = SimpleImputer(strategy = <span class="string">&#x27;median&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化特征至0-1区间</span></span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler(feature_range = (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过训练集训练填充参数</span></span><br><span class="line"></span><br><span class="line">imputer.fit(train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充训练集和测试集</span></span><br><span class="line"></span><br><span class="line">train = imputer.transform(train)</span><br><span class="line"></span><br><span class="line">test = imputer.transform(app_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过训练集训练归一化参数，并且归一化训练集和测试集</span></span><br><span class="line"></span><br><span class="line">scaler.fit(train)</span><br><span class="line"></span><br><span class="line">train = scaler.transform(train)</span><br><span class="line"></span><br><span class="line">test = scaler.transform(test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看训练集和测试集的尺寸</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Training data shape: &#x27;</span>, train.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Testing data shape: &#x27;</span>, test.shape)</span><br></pre></td></tr></table></figure><pre><code>Training data shape:  (307511, 240)Testing data shape:  (48744, 240)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基线模型使用Scikit-Learn的logistic_regression</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line"></span><br><span class="line">log_reg = LogisticRegression(C = <span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line">log_reg.fit(train, train_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 做预测，注意predict返回的是一个预测值，而predict_proba返回的是各个类别的概率，行概率和为1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 二分类则得到([px1,px2],(dtype)) 分别表示预测为0的概率和预测为1的概率</span></span><br><span class="line"></span><br><span class="line">log_reg_pred = log_reg.predict_proba(test)</span><br><span class="line"></span><br><span class="line">log_reg_pred</span><br></pre></td></tr></table></figure><pre><code>array([[0.92148542, 0.07851458],       [0.8620737 , 0.1379263 ],       [0.91780633, 0.08219367],       ...,       [0.92277534, 0.07722466],       [0.91761109, 0.08238891],       [0.89786466, 0.10213534]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看每列概率对应的类别，可以看出与以上描述一致，第一个为0的概率第二个为1的概率</span></span><br><span class="line"></span><br><span class="line">log_reg.classes_</span><br></pre></td></tr></table></figure><pre><code>array([0, 1], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于我们需要的是违约的概率即选择第二列结果</span></span><br><span class="line"></span><br><span class="line">log_reg_pred = log_reg.predict_proba(test)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">log_reg_pred</span><br></pre></td></tr></table></figure><pre><code>array([0.07851458, 0.1379263 , 0.08219367, ..., 0.07722466, 0.08238891,       0.10213534])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Submission dataframe</span></span><br><span class="line"></span><br><span class="line">submit = app_test[[<span class="string">&#x27;SK_ID_CURR&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">submit[<span class="string">&#x27;TARGET&#x27;</span>] = log_reg_pred</span><br><span class="line"></span><br><span class="line">submit.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>SK_ID_CURR</th>      <th>TARGET</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>100001</td>      <td>0.078515</td>    </tr>    <tr>      <th>1</th>      <td>100005</td>      <td>0.137926</td>    </tr>    <tr>      <th>2</th>      <td>100013</td>      <td>0.082194</td>    </tr>    <tr>      <th>3</th>      <td>100028</td>      <td>0.080921</td>    </tr>    <tr>      <th>4</th>      <td>100038</td>      <td>0.132618</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将结果保存为csv</span></span><br><span class="line"></span><br><span class="line">submit.to_csv(<span class="string">&#x27;./1_result/log_reg_baseline.csv&#x27;</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h2 id="随机森林模型"><a href="#随机森林模型" class="headerlink" title="随机森林模型"></a>随机森林模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立随机森林模型，n_estimators为树的数量，n_jobs设定工作的core数量，-1为所有core工作</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># verbose为日志显示为0时不输出日志信息，为1时输出带进度条的日志信息，为2时无进度条得日志信息</span></span><br><span class="line"></span><br><span class="line">random_forest = RandomForestClassifier(n_estimators = <span class="number">100</span>, random_state = <span class="number">50</span>, verbose = <span class="number">1</span>, n_jobs = -<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在训练集上训练随机森林</span></span><br><span class="line"></span><br><span class="line">random_forest.fit(train, train_labels)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征重要性</span></span><br><span class="line"></span><br><span class="line">feature_importance_values = random_forest.feature_importances_</span><br><span class="line"></span><br><span class="line">feature_importances = pd.DataFrame(&#123;<span class="string">&#x27;feature&#x27;</span>: features, <span class="string">&#x27;importance&#x27;</span>: feature_importance_values&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上做预测，选择违约的概率</span></span><br><span class="line"></span><br><span class="line">predictions = random_forest.predict_proba(test)[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.4s[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提交准备</span></span><br><span class="line"></span><br><span class="line">submit = app_test[[<span class="string">&#x27;SK_ID_CURR&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">submit[<span class="string">&#x27;TARGET&#x27;</span>] = predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">submit.to_csv(<span class="string">&#x27;./1_result/random_forest_baseline.csv&#x27;</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证特征工程创建的特征是否有用，多项式特征</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征名</span></span><br><span class="line"></span><br><span class="line">poly_features_names = <span class="built_in">list</span>(app_train_poly.columns)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 中位数填补缺失值</span></span><br><span class="line"></span><br><span class="line">imputer = SimpleImputer(strategy = <span class="string">&#x27;median&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">poly_features = imputer.fit_transform(app_train_poly)</span><br><span class="line"></span><br><span class="line">poly_features_test = imputer.transform(app_test_poly)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化多项式特征</span></span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler(feature_range = (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">poly_features = scaler.fit_transform(poly_features)</span><br><span class="line"></span><br><span class="line">poly_features_test = scaler.transform(poly_features_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line"></span><br><span class="line">random_forest_poly = RandomForestClassifier(n_estimators = <span class="number">100</span>, random_state = <span class="number">50</span>, verbose = <span class="number">1</span>, n_jobs = -<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line">random_forest_poly.fit(poly_features, train_labels)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 做预测</span></span><br><span class="line"></span><br><span class="line">predictions = random_forest_poly.predict_proba(poly_features_test)[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   43.9s[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.4s finished</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提交准备</span></span><br><span class="line"></span><br><span class="line">submit = app_test[[<span class="string">&#x27;SK_ID_CURR&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">submit[<span class="string">&#x27;TARGET&#x27;</span>] = predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">submit.to_csv(<span class="string">&#x27;./1_result/random_forest_baseline_engineered.csv&#x27;</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试领域知识特征是否有用</span></span><br><span class="line"></span><br><span class="line">app_train_domain = app_train_domain.drop(columns = <span class="string">&#x27;TARGET&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">domain_features_names = <span class="built_in">list</span>(app_train_domain.columns)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 中位数填补缺失值</span></span><br><span class="line"></span><br><span class="line">imputer = SimpleImputer(strategy = <span class="string">&#x27;median&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">domain_features = imputer.fit_transform(app_train_domain)</span><br><span class="line"></span><br><span class="line">domain_features_test = imputer.transform(app_test_domain)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化领域特征</span></span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler(feature_range = (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">domain_features = scaler.fit_transform(domain_features)</span><br><span class="line"></span><br><span class="line">domain_features_test = scaler.transform(domain_features_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line"></span><br><span class="line">random_forest_domain = RandomForestClassifier(n_estimators = <span class="number">100</span>, random_state = <span class="number">50</span>, verbose = <span class="number">1</span>, n_jobs = -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line">random_forest_domain.fit(domain_features, train_labels)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取特征重要性</span></span><br><span class="line"></span><br><span class="line">feature_importance_values_domain = random_forest_domain.feature_importances_</span><br><span class="line"></span><br><span class="line">feature_importances_domain = pd.DataFrame(&#123;<span class="string">&#x27;feature&#x27;</span>: domain_features_names, <span class="string">&#x27;importance&#x27;</span>: feature_importance_values_domain&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 做预测</span></span><br><span class="line"></span><br><span class="line">predictions = random_forest_domain.predict_proba(domain_features_test)[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   36.1s[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提交准备</span></span><br><span class="line"></span><br><span class="line">submit = app_test[[<span class="string">&#x27;SK_ID_CURR&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">submit[<span class="string">&#x27;TARGET&#x27;</span>] = predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">submit.to_csv(<span class="string">&#x27;./1_result/random_forest_baseline_domain.csv&#x27;</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_feature_importances</span>(<span class="params">df</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Plot importances returned by a model. This can work with any measure of</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    feature importance provided that higher importance is better. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        df (dataframe): 特征重要性. 包含`features`列和 `importance&#x27;列</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        用图展示15个最重要的特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据特征重要性排序，降序</span></span><br><span class="line"></span><br><span class="line">    df = df.sort_values(<span class="string">&#x27;importance&#x27;</span>, ascending = <span class="literal">False</span>).reset_index()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 归一化特征重要性</span></span><br><span class="line"></span><br><span class="line">    df[<span class="string">&#x27;importance_normalized&#x27;</span>] = df[<span class="string">&#x27;importance&#x27;</span>] / df[<span class="string">&#x27;importance&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 条形图</span></span><br><span class="line"></span><br><span class="line">    plt.figure(figsize = (<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    ax = plt.subplot()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将最重要的索引置顶</span></span><br><span class="line"></span><br><span class="line">    ax.barh(<span class="built_in">list</span>(<span class="built_in">reversed</span>(<span class="built_in">list</span>(df.index[:<span class="number">15</span>]))), </span><br><span class="line"></span><br><span class="line">            df[<span class="string">&#x27;importance_normalized&#x27;</span>].head(<span class="number">15</span>), </span><br><span class="line"></span><br><span class="line">            align = <span class="string">&#x27;center&#x27;</span>, edgecolor = <span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置标签</span></span><br><span class="line"></span><br><span class="line">    ax.set_yticks(<span class="built_in">list</span>(<span class="built_in">reversed</span>(<span class="built_in">list</span>(df.index[:<span class="number">15</span>]))))</span><br><span class="line"></span><br><span class="line">    ax.set_yticklabels(df[<span class="string">&#x27;feature&#x27;</span>].head(<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot labeling</span></span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Normalized Importance&#x27;</span>); plt.title(<span class="string">&#x27;Feature Importances&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示默认特征的重要性</span></span><br><span class="line"></span><br><span class="line">feature_importances_sorted = plot_feature_importances(feature_importances)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fqxC0H"><img src="https://z3.ax1x.com/2021/08/19/fqxC0H.png" alt="fqxC0H.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示领域特征重要性</span></span><br><span class="line"></span><br><span class="line">feature_importances_domain_sorted = plot_feature_importances(feature_importances_domain)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fqxP7d"><img src="https://z3.ax1x.com/2021/08/19/fqxP7d.png" alt="fqxP7d.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span>(<span class="params">features, test_features, encoding = <span class="string">&#x27;ohe&#x27;</span>, n_folds = <span class="number">5</span></span>):</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;lightgbm交叉验证</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    --------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        features (pd.DataFrame): </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            训练集特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        test_features (pd.DataFrame): </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            测试集特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        encoding (str, default = &#x27;ohe&#x27;): </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            独热编码，le为标签编码</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            n_folds (int, default = 5): 交叉验证折数默认为5</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    --------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        submission (pd.DataFrame): </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            由`SK_ID_CURR` 和 `TARGET`组成的DF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        feature_importances (pd.DataFrame): </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            特征重要性</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        valid_metrics (pd.DataFrame): </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            dataframe with training and validation metrics (ROC AUC) for each fold and overall.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取 ids</span></span><br><span class="line"></span><br><span class="line">    train_ids = features[<span class="string">&#x27;SK_ID_CURR&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    test_ids = test_features[<span class="string">&#x27;SK_ID_CURR&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取训练集标签</span></span><br><span class="line"></span><br><span class="line">    labels = features[<span class="string">&#x27;TARGET&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 只保留特征</span></span><br><span class="line"></span><br><span class="line">    features = features.drop(columns = [<span class="string">&#x27;SK_ID_CURR&#x27;</span>, <span class="string">&#x27;TARGET&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    test_features = test_features.drop(columns = [<span class="string">&#x27;SK_ID_CURR&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 独热编码</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> encoding == <span class="string">&#x27;ohe&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        features = pd.get_dummies(features)</span><br><span class="line"></span><br><span class="line">        test_features = pd.get_dummies(test_features)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 按列对齐DF</span></span><br><span class="line"></span><br><span class="line">        features, test_features = features.align(test_features, join = <span class="string">&#x27;inner&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 无分类索引记录</span></span><br><span class="line"></span><br><span class="line">        cat_indices = <span class="string">&#x27;auto&#x27;</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 整数标签编码</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">elif</span> encoding == <span class="string">&#x27;le&#x27;</span>:</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建标签编码</span></span><br><span class="line"></span><br><span class="line">        label_encoder = LabelEncoder()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 用于存储分类索引的列表</span></span><br><span class="line"></span><br><span class="line">        cat_indices = []</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历每列</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, col <span class="keyword">in</span> <span class="built_in">enumerate</span>(features):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> features[col].dtype == <span class="string">&#x27;object&#x27;</span>:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 将分类特性映射到整数</span></span><br><span class="line"></span><br><span class="line">                features[col] = label_encoder.fit_transform(np.array(features[col].astype(<span class="built_in">str</span>)).reshape((-<span class="number">1</span>,)))</span><br><span class="line"></span><br><span class="line">                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(<span class="built_in">str</span>)).reshape((-<span class="number">1</span>,)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 记录分类索引</span></span><br><span class="line"></span><br><span class="line">                cat_indices.append(i)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 若标签编码无效则捕获错误</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Encoding must be either &#x27;ohe&#x27; or &#x27;le&#x27;&quot;</span>)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Training Data Shape: &#x27;</span>, features.shape)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Testing Data Shape: &#x27;</span>, test_features.shape)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取特征名称</span></span><br><span class="line"></span><br><span class="line">    feature_names = <span class="built_in">list</span>(features.columns)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将DF转化为np数组</span></span><br><span class="line"></span><br><span class="line">    features = np.array(features)</span><br><span class="line"></span><br><span class="line">    test_features = np.array(test_features)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建交叉验证对象</span></span><br><span class="line"></span><br><span class="line">    k_fold = KFold(n_splits = n_folds, shuffle = <span class="literal">True</span>, random_state = <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立空数组用于记录特征重要性</span></span><br><span class="line"></span><br><span class="line">    feature_importance_values = np.zeros(<span class="built_in">len</span>(feature_names))</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立空数组用于保存预测值</span></span><br><span class="line"></span><br><span class="line">    test_predictions = np.zeros(test_features.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Empty array for out of fold validation predictions</span></span><br><span class="line"></span><br><span class="line">    out_of_fold = np.zeros(features.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于记录验证和训练分数的列表</span></span><br><span class="line"></span><br><span class="line">    valid_scores = []</span><br><span class="line"></span><br><span class="line">    train_scores = []</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每折</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> train_indices, valid_indices <span class="keyword">in</span> k_fold.split(features):</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每折的训练数据</span></span><br><span class="line"></span><br><span class="line">        train_features, train_labels = features[train_indices], labels[train_indices]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每折的验证数据</span></span><br><span class="line"></span><br><span class="line">        valid_features, valid_labels = features[valid_indices], labels[valid_indices]</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建模型</span></span><br><span class="line"></span><br><span class="line">        model = lgb.LGBMClassifier(n_estimators=<span class="number">10000</span>, objective = <span class="string">&#x27;binary&#x27;</span>, </span><br><span class="line"></span><br><span class="line">                                   class_weight = <span class="string">&#x27;balanced&#x27;</span>, learning_rate = <span class="number">0.05</span>, </span><br><span class="line"></span><br><span class="line">                                   reg_alpha = <span class="number">0.1</span>, reg_lambda = <span class="number">0.1</span>, </span><br><span class="line"></span><br><span class="line">                                   subsample = <span class="number">0.8</span>, n_jobs = -<span class="number">1</span>, random_state = <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line">        model.fit(train_features, train_labels, eval_metric = <span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line"></span><br><span class="line">                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],</span><br><span class="line"></span><br><span class="line">                  eval_names = [<span class="string">&#x27;valid&#x27;</span>, <span class="string">&#x27;train&#x27;</span>], categorical_feature = cat_indices,</span><br><span class="line"></span><br><span class="line">                  early_stopping_rounds = <span class="number">100</span>, verbose = <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录最好的代数</span></span><br><span class="line"></span><br><span class="line">        best_iteration = model.best_iteration_</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录特征重要性</span></span><br><span class="line"></span><br><span class="line">        feature_importance_values += model.feature_importances_ / k_fold.n_splits</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 做预测</span></span><br><span class="line"></span><br><span class="line">        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, <span class="number">1</span>] / k_fold.n_splits</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录折外预测结果</span></span><br><span class="line"></span><br><span class="line">        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录最好的得分</span></span><br><span class="line"></span><br><span class="line">        valid_score = model.best_score_[<span class="string">&#x27;valid&#x27;</span>][<span class="string">&#x27;auc&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        train_score = model.best_score_[<span class="string">&#x27;train&#x27;</span>][<span class="string">&#x27;auc&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        valid_scores.append(valid_score)</span><br><span class="line"></span><br><span class="line">        train_scores.append(train_score)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 清理内存</span></span><br><span class="line"></span><br><span class="line">        gc.enable()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">del</span> model, train_features, valid_features</span><br><span class="line"></span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提交准备</span></span><br><span class="line"></span><br><span class="line">    submission = pd.DataFrame(&#123;<span class="string">&#x27;SK_ID_CURR&#x27;</span>: test_ids, <span class="string">&#x27;TARGET&#x27;</span>: test_predictions&#125;)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 特征重要性</span></span><br><span class="line"></span><br><span class="line">    feature_importances = pd.DataFrame(&#123;<span class="string">&#x27;feature&#x27;</span>: feature_names, <span class="string">&#x27;importance&#x27;</span>: feature_importance_values&#125;)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 交叉验证整体得分</span></span><br><span class="line"></span><br><span class="line">    valid_auc = roc_auc_score(labels, out_of_fold)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将得分加入矩阵</span></span><br><span class="line"></span><br><span class="line">    valid_scores.append(valid_auc)</span><br><span class="line"></span><br><span class="line">    train_scores.append(np.mean(train_scores))</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建验证分数的DF</span></span><br><span class="line"></span><br><span class="line">    fold_names = <span class="built_in">list</span>(<span class="built_in">range</span>(n_folds))</span><br><span class="line"></span><br><span class="line">    fold_names.append(<span class="string">&#x27;overall&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    metrics = pd.DataFrame(&#123;<span class="string">&#x27;fold&#x27;</span>: fold_names,</span><br><span class="line"></span><br><span class="line">                            <span class="string">&#x27;train&#x27;</span>: train_scores,</span><br><span class="line"></span><br><span class="line">                            <span class="string">&#x27;valid&#x27;</span>: valid_scores&#125;) </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> submission, feature_importances, metrics</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">submission, fi, metrics = model(app_train, app_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Baseline metrics&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(metrics)</span><br></pre></td></tr></table></figure><pre><code>Training Data Shape:  (307511, 239)Testing Data Shape:  (48744, 239)Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.798723    train&#39;s binary_logloss: 0.547797    valid&#39;s auc: 0.755039    valid&#39;s binary_logloss: 0.563266[400]    train&#39;s auc: 0.82838    train&#39;s binary_logloss: 0.518334    valid&#39;s auc: 0.755107    valid&#39;s binary_logloss: 0.545575Early stopping, best iteration is:[315]    train&#39;s auc: 0.816657    train&#39;s binary_logloss: 0.530116    valid&#39;s auc: 0.755215    valid&#39;s binary_logloss: 0.552627Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.798409    train&#39;s binary_logloss: 0.548179    valid&#39;s auc: 0.758332    valid&#39;s binary_logloss: 0.563587[400]    train&#39;s auc: 0.828244    train&#39;s binary_logloss: 0.518308    valid&#39;s auc: 0.758563    valid&#39;s binary_logloss: 0.545588Early stopping, best iteration is:[317]    train&#39;s auc: 0.8169    train&#39;s binary_logloss: 0.529878    valid&#39;s auc: 0.758754    valid&#39;s binary_logloss: 0.552413Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.797648    train&#39;s binary_logloss: 0.549331    valid&#39;s auc: 0.763246    valid&#39;s binary_logloss: 0.564236Early stopping, best iteration is:[264]    train&#39;s auc: 0.808111    train&#39;s binary_logloss: 0.539063    valid&#39;s auc: 0.76363    valid&#39;s binary_logloss: 0.557905Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.798855    train&#39;s binary_logloss: 0.547952    valid&#39;s auc: 0.757131    valid&#39;s binary_logloss: 0.562234Early stopping, best iteration is:[280]    train&#39;s auc: 0.811887    train&#39;s binary_logloss: 0.535139    valid&#39;s auc: 0.757583    valid&#39;s binary_logloss: 0.554287Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.797918    train&#39;s binary_logloss: 0.548584    valid&#39;s auc: 0.758065    valid&#39;s binary_logloss: 0.564721Early stopping, best iteration is:[287]    train&#39;s auc: 0.811617    train&#39;s binary_logloss: 0.535146    valid&#39;s auc: 0.758344    valid&#39;s binary_logloss: 0.556636Baseline metrics      fold     train     valid0        0  0.816657  0.7552151        1  0.816900  0.7587542        2  0.808111  0.7636303        3  0.811887  0.7575834        4  0.811617  0.7583445  overall  0.813034  0.758705</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fi_sorted = plot_feature_importances(fi)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fqxktI"><img src="https://z3.ax1x.com/2021/08/19/fqxktI.png" alt="fqxktI.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">submission.to_csv(<span class="string">&#x27;./1_result/baseline_lgb.csv&#x27;</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">app_train_domain[<span class="string">&#x27;TARGET&#x27;</span>] = train_labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试领域知识特征</span></span><br><span class="line"></span><br><span class="line">submission_domain, fi_domain, metrics_domain = model(app_train_domain, app_test_domain)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Baseline with domain knowledge features metrics&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(metrics_domain)</span><br></pre></td></tr></table></figure><pre><code>Training Data Shape:  (307511, 243)Testing Data Shape:  (48744, 243)Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.804779    train&#39;s binary_logloss: 0.541283    valid&#39;s auc: 0.762511    valid&#39;s binary_logloss: 0.557227Early stopping, best iteration is:[268]    train&#39;s auc: 0.815523    train&#39;s binary_logloss: 0.530413    valid&#39;s auc: 0.763069    valid&#39;s binary_logloss: 0.550276Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.804016    train&#39;s binary_logloss: 0.542318    valid&#39;s auc: 0.765768    valid&#39;s binary_logloss: 0.557819Early stopping, best iteration is:[218]    train&#39;s auc: 0.807075    train&#39;s binary_logloss: 0.539112    valid&#39;s auc: 0.766062    valid&#39;s binary_logloss: 0.555952Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.8038    train&#39;s binary_logloss: 0.542856    valid&#39;s auc: 0.7703    valid&#39;s binary_logloss: 0.557925[400]    train&#39;s auc: 0.834559    train&#39;s binary_logloss: 0.511454    valid&#39;s auc: 0.770511    valid&#39;s binary_logloss: 0.538558Early stopping, best iteration is:[383]    train&#39;s auc: 0.832138    train&#39;s binary_logloss: 0.514008    valid&#39;s auc: 0.77073    valid&#39;s binary_logloss: 0.54009Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.804603    train&#39;s binary_logloss: 0.541718    valid&#39;s auc: 0.765497    valid&#39;s binary_logloss: 0.556274Early stopping, best iteration is:[238]    train&#39;s auc: 0.8111    train&#39;s binary_logloss: 0.535149    valid&#39;s auc: 0.765884    valid&#39;s binary_logloss: 0.552351Training until validation scores don&#39;t improve for 100 rounds[200]    train&#39;s auc: 0.804782    train&#39;s binary_logloss: 0.541397    valid&#39;s auc: 0.765076    valid&#39;s binary_logloss: 0.558641Early stopping, best iteration is:[290]    train&#39;s auc: 0.819404    train&#39;s binary_logloss: 0.526653    valid&#39;s auc: 0.765249    valid&#39;s binary_logloss: 0.549657Baseline with domain knowledge features metrics      fold     train     valid0        0  0.815523  0.7630691        1  0.807075  0.7660622        2  0.832138  0.7707303        3  0.811100  0.7658844        4  0.819404  0.7652495  overall  0.817048  0.766186</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fi_sorted = plot_feature_importances(fi_domain)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/fqxV9P"><img src="https://z3.ax1x.com/2021/08/19/fqxV9P.png" alt="fqxV9P.png"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">submission_domain.to_csv(<span class="string">&#x27;./1_result/baseline_lgb_domain_features.csv&#x27;</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><hr><p>本文提及的数据集下载地址：<br>链接：<a href="https://pan.baidu.com/s/1Dlxp_C8H7Rjf0OKorSRQ0A">https://pan.baidu.com/s/1Dlxp_C8H7Rjf0OKorSRQ0A</a><br>提取码：1111</p><hr>]]></content>
    
    
    <summary type="html">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; os&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; seaborn &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; sns&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; sklearn.preprocessing &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; LabelEncoder&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; warnings&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;warnings.filterwarnings(&lt;span class=&quot;string&quot;&gt;&amp;#x27;ignore&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h2 id=&quot;数据读取&quot;&gt;&lt;a href=&quot;#数据读取&quot; class=&quot;headerlink&quot; title=&quot;数据读取&quot;&gt;&lt;/a&gt;数据读取&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;app_train = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&amp;#x27;./dataset/application_train.csv&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&amp;#x27;Training data shape: &amp;#x27;&lt;/span&gt;, app_train.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;app_train.head()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;pre&gt;&lt;code&gt;Training data shape:  (307511, 122)
&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="Kaggle" scheme="http://woody0819.github.io/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>数据分析一般过程</title>
    <link href="http://woody0819.github.io/2021/08/18/DA%20general%20process/"/>
    <id>http://woody0819.github.io/2021/08/18/DA%20general%20process/</id>
    <published>2021-08-18T07:28:10.977Z</published>
    <updated>2021-08-19T17:13:05.474Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-探索性数据分析-EDA"><a href="#1-探索性数据分析-EDA" class="headerlink" title="1. 探索性数据分析(EDA)"></a>1. 探索性数据分析(EDA)</h1><h2 id="1-数据总体了解"><a href="#1-数据总体了解" class="headerlink" title="(1) 数据总体了解"></a>(1) 数据总体了解</h2><ul><li>读取数据集并了解数据集大小，原始特征维度；</li><li>通过info熟悉数据类型；</li><li>粗略查看数据集中各特征基本统计量；</li></ul><h2 id="2-缺失值和唯一值"><a href="#2-缺失值和唯一值" class="headerlink" title="(2) 缺失值和唯一值"></a>(2) 缺失值和唯一值</h2><ul><li>查看数据缺失值情况</li><li>查看唯一值特征情况</li></ul><h2 id="3-深入数据-查看数据类型"><a href="#3-深入数据-查看数据类型" class="headerlink" title="(3) 深入数据-查看数据类型"></a>(3) 深入数据-查看数据类型</h2><ul><li><p>类别型数据</p></li><li><p>数值型数据</p><ul><li><p>离散数值型数据</p></li><li><p>连续数值型数据</p></li></ul></li></ul><h2 id="4-数据间相关关系"><a href="#4-数据间相关关系" class="headerlink" title="(4) 数据间相关关系"></a>(4) 数据间相关关系</h2><ul><li>特征和特征之间关系</li><li>特征和目标变量之间关系</li></ul><h2 id="5-用pandas-profiling生成数据报告"><a href="#5-用pandas-profiling生成数据报告" class="headerlink" title="(5) 用pandas_profiling生成数据报告"></a>(5) 用pandas_profiling生成数据报告</h2><span id="more"></span><h1 id="2-特征工程与特征选择"><a href="#2-特征工程与特征选择" class="headerlink" title="2. 特征工程与特征选择"></a>2. 特征工程与特征选择</h1><h2 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="(1) 数据预处理"></a>(1) 数据预处理</h2><ul><li>缺失值的填充</li><li>时间格式处理</li><li>对象类型特征转换到数值</li></ul><h2 id="2-异常值处理："><a href="#2-异常值处理：" class="headerlink" title="(2) 异常值处理："></a>(2) 异常值处理：</h2><ul><li>基于3segama原则<ul><li>均方差在统计学中，如果一个数据分布近似正态，那么大约 68% 的数据值会在均值的一个标准差范围内，大约 95% 会在两个标准差范围内，大约 99.7% 会在三个标准差范围内。</li></ul></li><li>基于箱型图<ul><li>总结一句话：四分位数会将数据分为三个点和四个区间，IQR = Q3 -Q1，下触须=Q1 − 1.5x IQR，上触须=Q3 + 1.5x IQR；</li></ul></li></ul><h2 id="3-数据分箱"><a href="#3-数据分箱" class="headerlink" title="(3) 数据分箱"></a>(3) 数据分箱</h2><ul><li>固定宽度分箱</li><li>分位数分箱<ul><li>离散数值型数据分箱</li><li>连续数值型数据分箱</li></ul></li><li>卡方分箱</li></ul><h2 id="4-特征交互"><a href="#4-特征交互" class="headerlink" title="(4) 特征交互"></a>(4) 特征交互</h2><ul><li>特征和特征之间组合</li><li>特征和特征之间衍生</li><li>其他特征衍生的尝试</li></ul><h2 id="5-特征编码"><a href="#5-特征编码" class="headerlink" title="(5) 特征编码"></a>(5) 特征编码</h2><ul><li>one-hot编码</li><li>label-encode编码</li></ul><h2 id="6-特征选择"><a href="#6-特征选择" class="headerlink" title="(6) 特征选择"></a>(6) 特征选择</h2><ul><li>1 Filter</li><li>2 Wrapper （RFE）</li><li>3 Embedded</li></ul><h1 id="3-建模与调参"><a href="#3-建模与调参" class="headerlink" title="3. 建模与调参"></a>3. 建模与调参</h1><h5 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h5><ul><li>优点<ul><li>训练速度较快，分类的时候，计算量仅仅只和特征的数目相关；</li><li>简单易理解，模型的可解释性非常好，从特征的权重可以看到不同的特征对最后结果的影响；</li><li>适合二分类问题，不需要缩放输入特征；</li><li>内存资源占用小，只需要存储各个维度的特征值；</li></ul></li><li>缺点<ul><li>逻辑回归需要预先处理缺失值和异常值；</li><li>不能用Logistic回归去解决非线性问题，因为Logistic的决策面是线性的；</li><li>对多重共线性数据较为敏感，且很难处理数据不平衡的问题；</li><li>准确率并不是很高，因为形式非常简单，很难去拟合数据的真实分布；</li></ul></li></ul><h5 id="决策树模型"><a href="#决策树模型" class="headerlink" title="决策树模型"></a>决策树模型</h5><ul><li>优点<ul><li>简单直观，生成的决策树可以可视化展示</li><li><strong>数据不需要预处理，不需要归一化，不需要处理缺失数据</strong></li><li>既可以处理离散值，也可以处理连续值</li></ul></li><li>缺点<ul><li>决策树算法非常容易过拟合，导致泛化能力不强（可进行适当的剪枝）</li><li>采用的是贪心算法，容易得到局部最优解</li></ul></li></ul><h5 id="集成模型集成方法（ensemble-method）"><a href="#集成模型集成方法（ensemble-method）" class="headerlink" title="集成模型集成方法（ensemble method）"></a>集成模型集成方法（ensemble method）</h5><p>通过组合多个学习器来完成学习任务，通过集成方法，可以将多个弱学习器组合成一个强分类器，因此集成学习的泛化能力一般比单一分类器要好。</p><p>集成方法主要包括Bagging和Boosting，Bagging和Boosting都是将已有的分类或回归算法通过一定方式组合起来，形成一个更加强大的分类。两种方法都是把若干个分类器整合为一个分类器的方法，只是整合的方式不一样，最终得到不一样的效果。常见的基于Baggin思想的集成模型有：随机森林、基于Boosting思想的集成模型有：Adaboost、GBDT、XgBoost、LightGBM、CatBoost等。</p><p><strong>Baggin和Boosting的区别总结如下：</strong></p><ul><li><strong>样本选择上：</strong> Bagging方法的训练集是从原始集中有放回的选取，所以从原始集中选出的各轮训练集之间是独立的；而Boosting方法需要每一轮的训练集不变，只是训练集中每个样本在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。</li><li><strong>样例权重上：</strong> Bagging方法使用均匀取样，所以每个样本的权重相等；而Boosting方法根据错误率不断调整样本的权值，错误率越大则权重越大。</li><li><strong>预测函数上：</strong> Bagging方法中所有预测函数的权重相等；而Boosting方法中每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。</li><li><strong>并行计算上：</strong> Bagging方法中各个预测函数可以并行生成；而Boosting方法各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</li></ul><h5 id="4-4-4-模型评估方法"><a href="#4-4-4-模型评估方法" class="headerlink" title="4.4.4 模型评估方法"></a>4.4.4 模型评估方法</h5><p>对于模型来说，其在训练集上面的误差我们称之为<strong>训练误差</strong>或者<strong>经验误差</strong>，而在测试集上的误差称之为<strong>测试误差</strong>。</p><p>对于我们来说，我们更关心的是模型对于新样本的学习能力，即我们希望通过对已有样本的学习，尽可能的将所有潜在样本的普遍规律学到手，而如果模型对训练样本学的太好，则有可能把训练样本自身所具有的一些特点当做所有潜在样本的普遍特点，这时候我们就会出现<strong>过拟合</strong>的问题。</p><p>因此我们通常将已有的数据集划分为训练集和测试集两部分，其中训练集用来训练模型，而测试集则是用来评估模型对于新样本的判别能力。</p><p><strong>对于数据集的划分，我们通常要保证满足以下两个条件：</strong></p><ul><li>训练集和测试集的分布要与样本真实分布一致，即训练集和测试集都要保证是从样本真实分布中独立同分布采样而得；</li><li>训练集和测试集要互斥；</li></ul><p><strong>对于数据集的划分有三种方法：留出法，交叉验证法和自助法：</strong></p><ul><li><p><strong>①留出法</strong></p><p>留出法是直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T。需要注意的是在划分的时候要尽可能保证数据分布的一致性，即避免因数据划分过程引入额外的偏差而对最终结果产生影响。为了保证数据分布的一致性，通常我们采用<strong>分层采样</strong>的方式来对数据进行采样。</p><p><strong>Tips：</strong> 通常，会将数据集D中大约2/3~4/5的样本作为训练集，其余的作为测试集。</p></li><li><p><strong>②交叉验证法</strong></p><p><strong>k折交叉验证</strong>通常将数据集D分为k份，其中k-1份作为训练集，剩余的一份作为测试集，这样就可以获得k组训练/测试集，可以进行k次训练与测试，最终返回的是k个测试结果的均值。交叉验证中数据集的划分依然是依据<strong>分层采样</strong>的方式来进行。</p><p>对于交叉验证法，其k值的选取往往决定了评估结果的稳定性和保真性，<strong>通常k值选取10。</strong></p><p>当k=1的时候，我们称之为<strong>留一法</strong>。</p></li><li><p><strong>③自助法</strong></p><p>我们每次从数据集D中取一个样本作为训练集中的元素，然后把该样本放回，重复该行为m次，这样我们就可以得到大小为m的训练集，在这里面有的样本重复出现，有的样本则没有出现过，我们把那些没有出现过的样本作为测试集；</p><p>进行这样采样的原因是因为在D中约有36.8%的数据没有在训练集中出现过。留出法与交叉验证法都是使用<strong>分层采样</strong>的方式进行数据采样与划分，而自助法则是使用<strong>有放回重复采样</strong>的方式进行数据采样；</p></li></ul><p><strong>数据集划分总结</strong></p><ul><li>对于数据量充足的时候，通常采用<strong>留出法</strong>或者<strong>k折交叉验证法</strong>来进行训练/测试集的划分；</li><li>对于数据集小且难以有效划分训练/测试集时使用<strong>自助法</strong>；</li><li>对于数据集小且可有效划分的时候最好使用<strong>留一法</strong>来进行划分，因为这种方法最为准确；</li></ul><p><strong>模型调参</strong></p><ul><li><p>贪心调参方法；</p><p>先使用当前对模型影响最大的参数进行调优，达到当前参数下的模型最优化，再使用对模型影响次之的参数进行调优，如此下去，直到所有的参数调整完毕。<br>这个方法的缺点就是可能会调到局部最优而不是全局最优，但是只需要一步一步的进行参数最优化调试即可，容易理解。<br>需要注意的是在树模型中参数调整的顺序，也就是各个参数对模型的影响程度，这里列举一下日常调参过程中常用的参数和调参顺序：</p><ul><li>①：max_depth、num_leaves</li><li>②：min_data_in_leaf、min_child_weight</li><li>③：bagging_fraction、 feature_fraction、bagging_freq</li><li>④：reg_lambda、reg_alpha</li><li>⑤：min_split_gain</li></ul></li><li><p>网格调参方法；</p><p>sklearn 提供GridSearchCV用于进行网格搜索，只需要把模型的参数输进去，就能给出最优化的结果和参数。相比起贪心调参，网格搜索的结果会更优，但是网格搜索只适合于小数据集，一旦数据的量级上去了，很难得出结果。</p></li><li><p>贝叶斯调参方法；</p><p>在使用之前需要先安装包bayesian-optimization，运行如下命令即可：</p><blockquote><p>pip install bayesian-optimization</p></blockquote><p>贝叶斯调参的主要思想是：给定优化的目标函数(广义的函数，只需指定输入和输出即可，无需知道内部结构以及数学性质)，通过不断地添加样本点来更新目标函数的后验分布(高斯过程,直到后验分布基本贴合于真实分布）。简单的说，就是考虑了上一次参数的信息，从而更好的调整当前的参数。</p><p>贝叶斯调参的步骤如下：</p><ul><li>定义优化函数(rf_cv）</li><li>建立模型</li><li>定义待优化的参数</li><li>得到优化结果，并返回要优化的分数指标</li></ul></li></ul><h1 id="4-模型融合"><a href="#4-模型融合" class="headerlink" title="4. 模型融合"></a>4. 模型融合</h1><p>模型融合是比赛后期上分的重要手段，特别是多人组队学习的比赛中，将不同队友的模型进行融合，可能会收获意想不到的效果哦，往往模型相差越大且模型表现都不错的前提下，模型融合后结果会有大幅提升，以下是模型融合的方式。</p><ul><li>平均：<ul><li>简单平均法</li><li>加权平均法</li></ul></li><li>投票：<ul><li>简单投票法</li><li>加权投票法</li></ul></li><li>综合：<ul><li>排序融合</li><li>log融合</li></ul></li><li>stacking:<ul><li>构建多层模型，并利用预测结果再拟合预测。</li></ul></li><li>blending：<ul><li>选取部分数据预测训练得到预测结果作为新特征，带入剩下的数据中预测。</li></ul></li><li>boosting/bagging</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;1-探索性数据分析-EDA&quot;&gt;&lt;a href=&quot;#1-探索性数据分析-EDA&quot; class=&quot;headerlink&quot; title=&quot;1. 探索性数据分析(EDA)&quot;&gt;&lt;/a&gt;1. 探索性数据分析(EDA)&lt;/h1&gt;&lt;h2 id=&quot;1-数据总体了解&quot;&gt;&lt;a href=&quot;#1-数据总体了解&quot; class=&quot;headerlink&quot; title=&quot;(1) 数据总体了解&quot;&gt;&lt;/a&gt;(1) 数据总体了解&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;读取数据集并了解数据集大小，原始特征维度；&lt;/li&gt;
&lt;li&gt;通过info熟悉数据类型；&lt;/li&gt;
&lt;li&gt;粗略查看数据集中各特征基本统计量；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;2-缺失值和唯一值&quot;&gt;&lt;a href=&quot;#2-缺失值和唯一值&quot; class=&quot;headerlink&quot; title=&quot;(2) 缺失值和唯一值&quot;&gt;&lt;/a&gt;(2) 缺失值和唯一值&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;查看数据缺失值情况&lt;/li&gt;
&lt;li&gt;查看唯一值特征情况&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;3-深入数据-查看数据类型&quot;&gt;&lt;a href=&quot;#3-深入数据-查看数据类型&quot; class=&quot;headerlink&quot; title=&quot;(3) 深入数据-查看数据类型&quot;&gt;&lt;/a&gt;(3) 深入数据-查看数据类型&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;类别型数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;数值型数据&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;离散数值型数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;连续数值型数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;4-数据间相关关系&quot;&gt;&lt;a href=&quot;#4-数据间相关关系&quot; class=&quot;headerlink&quot; title=&quot;(4) 数据间相关关系&quot;&gt;&lt;/a&gt;(4) 数据间相关关系&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;特征和特征之间关系&lt;/li&gt;
&lt;li&gt;特征和目标变量之间关系&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;5-用pandas-profiling生成数据报告&quot;&gt;&lt;a href=&quot;#5-用pandas-profiling生成数据报告&quot; class=&quot;headerlink&quot; title=&quot;(5) 用pandas_profiling生成数据报告&quot;&gt;&lt;/a&gt;(5) 用pandas_profiling生成数据报告&lt;/h2&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>用户消费记录数据分析案例</title>
    <link href="http://woody0819.github.io/2021/05/27/test_9/"/>
    <id>http://woody0819.github.io/2021/05/27/test_9/</id>
    <published>2021-05-27T03:58:56.970Z</published>
    <updated>2021-06-03T11:13:33.978Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第一部分：数据类型处理"><a href="#第一部分：数据类型处理" class="headerlink" title="第一部分：数据类型处理"></a>第一部分：数据类型处理</h2><ul><li>数据加载<ul><li>字段含义：<ul><li>user_id:用户ID</li><li>order_dt:购买日期</li><li>order_product:购买产品的数量</li><li>order_amount:购买金额</li></ul></li></ul></li><li>观察数据<ul><li>查看数据的数据类型</li><li>数据中是否存储在缺失值</li><li>将order_dt转换成时间类型</li><li>查看数据的统计描述<ul><li>计算所有用户购买商品的平均数量</li><li>计算所有用户购买商品的平均花费</li></ul></li><li>在源数据中添加一列表示月份:astype(‘datetime64[M]‘)</li></ul></li></ul><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame,Series</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据的加载</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./data/CDNOW_master.txt&#x27;</span>,header=<span class="literal">None</span>,sep=<span class="string">&#x27;\s+&#x27;</span>,names=[<span class="string">&#x27;user_id&#x27;</span>,<span class="string">&#x27;order_dt&#x27;</span>,<span class="string">&#x27;order_product&#x27;</span>,<span class="string">&#x27;order_amount&#x27;</span>])</span><br><span class="line">df  <span class="comment"># 该数据没有列索引故header=None，原数据用空格分割数据需要拆分故seq=&#x27;\s+&#x27;(表示n个不同空格)，添加列索引names=[&#x27;......&#x27;]</span></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>user_id</th>      <th>order_dt</th>      <th>order_product</th>      <th>order_amount</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>19970101</td>      <td>1</td>      <td>11.77</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>19970112</td>      <td>1</td>      <td>12.00</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>19970112</td>      <td>5</td>      <td>77.00</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>19970102</td>      <td>2</td>      <td>20.76</td>    </tr>    <tr>      <th>4</th>      <td>3</td>      <td>19970330</td>      <td>2</td>      <td>20.76</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>69654</th>      <td>23568</td>      <td>19970405</td>      <td>4</td>      <td>83.74</td>    </tr>    <tr>      <th>69655</th>      <td>23568</td>      <td>19970422</td>      <td>1</td>      <td>14.99</td>    </tr>    <tr>      <th>69656</th>      <td>23569</td>      <td>19970325</td>      <td>2</td>      <td>25.74</td>    </tr>    <tr>      <th>69657</th>      <td>23570</td>      <td>19970325</td>      <td>3</td>      <td>51.12</td>    </tr>    <tr>      <th>69658</th>      <td>23570</td>      <td>19970326</td>      <td>2</td>      <td>42.96</td>    </tr>  </tbody></table><p>69659 rows × 4 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.info()   <span class="comment"># 数据类型和缺失值尽收眼底，此处表格满编无空值</span></span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 69659 entries, 0 to 69658Data columns (total 4 columns): #   Column         Non-Null Count  Dtype  ---  ------         --------------  -----   0   user_id        69659 non-null  int64   1   order_dt       69659 non-null  int64   2   order_product  69659 non-null  int64   3   order_amount   69659 non-null  float64dtypes: float64(1), int64(3)memory usage: 2.1 MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将order_dt转换成时间类型</span></span><br><span class="line">df[<span class="string">&#x27;order_dt&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;order_dt&#x27;</span>],<span class="built_in">format</span>=<span class="string">&#x27;%Y%m%d&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>user_id</th>      <th>order_dt</th>      <th>order_product</th>      <th>order_amount</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>1997-01-01</td>      <td>1</td>      <td>11.77</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1997-01-12</td>      <td>1</td>      <td>12.00</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>1997-01-12</td>      <td>5</td>      <td>77.00</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>1997-01-02</td>      <td>2</td>      <td>20.76</td>    </tr>    <tr>      <th>4</th>      <td>3</td>      <td>1997-03-30</td>      <td>2</td>      <td>20.76</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据统计描述</span></span><br><span class="line">df.describe()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>user_id</th>      <th>order_product</th>      <th>order_amount</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>69659.000000</td>      <td>69659.000000</td>      <td>69659.000000</td>    </tr>    <tr>      <th>mean</th>      <td>11470.854592</td>      <td>2.410040</td>      <td>35.893648</td>    </tr>    <tr>      <th>std</th>      <td>6819.904848</td>      <td>2.333924</td>      <td>36.281942</td>    </tr>    <tr>      <th>min</th>      <td>1.000000</td>      <td>1.000000</td>      <td>0.000000</td>    </tr>    <tr>      <th>25%</th>      <td>5506.000000</td>      <td>1.000000</td>      <td>14.490000</td>    </tr>    <tr>      <th>50%</th>      <td>11410.000000</td>      <td>2.000000</td>      <td>25.980000</td>    </tr>    <tr>      <th>75%</th>      <td>17273.000000</td>      <td>3.000000</td>      <td>43.700000</td>    </tr>    <tr>      <th>max</th>      <td>23570.000000</td>      <td>99.000000</td>      <td>1286.010000</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在源数据中添加一列表示月份:astype(&#x27;datetime64[M]&#x27;)</span></span><br><span class="line">df[<span class="string">&#x27;order_dt&#x27;</span>].astype(<span class="string">&#x27;datetime64[M]&#x27;</span>)  <span class="comment"># 基于order_dt取出其中的月份</span></span><br><span class="line">df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;order_dt&#x27;</span>].astype(<span class="string">&#x27;datetime64[M]&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>user_id</th>      <th>order_dt</th>      <th>order_product</th>      <th>order_amount</th>      <th>month</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>1997-01-01</td>      <td>1</td>      <td>11.77</td>      <td>1997-01-01</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1997-01-12</td>      <td>1</td>      <td>12.00</td>      <td>1997-01-01</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>1997-01-12</td>      <td>5</td>      <td>77.00</td>      <td>1997-01-01</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>1997-01-02</td>      <td>2</td>      <td>20.76</td>      <td>1997-01-01</td>    </tr>    <tr>      <th>4</th>      <td>3</td>      <td>1997-03-30</td>      <td>2</td>      <td>20.76</td>      <td>1997-03-01</td>    </tr>  </tbody></table></div><h2 id="第二部分：按月数据分析"><a href="#第二部分：按月数据分析" class="headerlink" title="第二部分：按月数据分析"></a>第二部分：按月数据分析</h2><ul><li>用户每月花费的总金额<ul><li>绘制曲线图展示</li></ul></li><li>所有用户每月的产品购买量</li><li>所有用户每月的消费总次数</li><li>统计每月的消费人数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户每月花费的总金额</span></span><br><span class="line">df.groupby(<span class="string">&#x27;month&#x27;</span>)[<span class="string">&#x27;order_amount&#x27;</span>].<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><pre><code>month1997-01-01    299060.171997-02-01    379590.031997-03-01    393155.271997-04-01    142824.491997-05-01    107933.301997-06-01    108395.871997-07-01    122078.881997-08-01     88367.691997-09-01     81948.801997-10-01     89780.771997-11-01    115448.641997-12-01     95577.351998-01-01     76756.781998-02-01     77096.961998-03-01    108970.151998-04-01     66231.521998-05-01     70989.661998-06-01     76109.30Name: order_amount, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制曲线图展示    df.groupby(&#x27;month&#x27;)[&#x27;order_amount&#x27;].sum().plot()</span></span><br><span class="line">plt.plot(df.groupby(<span class="string">&#x27;month&#x27;</span>)[<span class="string">&#x27;order_amount&#x27;</span>].<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x16f5d926e48&gt;]</code></pre><p><a href="https://imgtu.com/i/23WL3F"><img src="https://z3.ax1x.com/2021/06/03/23WL3F.jpg" alt="23WL3F.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 所有用户每月的产品购买量</span></span><br><span class="line">df.groupby(<span class="string">&#x27;month&#x27;</span>)[<span class="string">&#x27;order_product&#x27;</span>].<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><pre><code>month1997-01-01    194161997-02-01    249211997-03-01    261591997-04-01     97291997-05-01     72751997-06-01     73011997-07-01     81311997-08-01     58511997-09-01     57291997-10-01     62031997-11-01     78121997-12-01     64181998-01-01     52781998-02-01     53401998-03-01     74311998-04-01     46971998-05-01     49031998-06-01     5287Name: order_product, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 所有用户每月的消费总次数(原始数据中的一行数据表示一次消费记录)</span></span><br><span class="line">df.groupby(<span class="string">&#x27;month&#x27;</span>)[<span class="string">&#x27;user_id&#x27;</span>].count()</span><br></pre></td></tr></table></figure><pre><code>month1997-01-01     89281997-02-01    112721997-03-01    115981997-04-01     37811997-05-01     28951997-06-01     30541997-07-01     29421997-08-01     23201997-09-01     22961997-10-01     25621997-11-01     27501997-12-01     25041998-01-01     20321998-02-01     20261998-03-01     27931998-04-01     18781998-05-01     19851998-06-01     2043Name: user_id, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每月的消费人数，可能同一天一个用户会消费多次</span></span><br><span class="line">df.groupby(<span class="string">&#x27;month&#x27;</span>)[<span class="string">&#x27;user_id&#x27;</span>].nunique()    <span class="comment"># nunique表示去重后的数据个数</span></span><br></pre></td></tr></table></figure><pre><code>month1997-01-01    78461997-02-01    96331997-03-01    95241997-04-01    28221997-05-01    22141997-06-01    23391997-07-01    21801997-08-01    17721997-09-01    17391997-10-01    18391997-11-01    20281997-12-01    18641998-01-01    15371998-02-01    15511998-03-01    20601998-04-01    14371998-05-01    14881998-06-01    1506Name: user_id, dtype: int64</code></pre><h2 id="第三部分：用户个体消费数据分析"><a href="#第三部分：用户个体消费数据分析" class="headerlink" title="第三部分：用户个体消费数据分析"></a>第三部分：用户个体消费数据分析</h2><ul><li>用户消费总金额和消费总次数的统计描述</li><li>用户消费金额和消费产品数量的散点图</li><li>各个用户消费总金额的直方分布图(消费金额在1000之内的分布)</li><li>各个用户消费的总数量的直方分布图(消费商品的数量在100次之内的分布)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户消费总金额和消费总次数的统计描述</span></span><br><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;order_amount&#x27;</span>].<span class="built_in">sum</span>() <span class="comment"># 每个用户消费的总金额</span></span><br></pre></td></tr></table></figure><pre><code>user_id1         11.772         89.003        156.464        100.505        385.61          ...  23566     36.0023567     20.9723568    121.7023569     25.7423570     94.08Name: order_amount, Length: 23570, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个用户消费的总次数</span></span><br><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>).count()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>order_dt</th>      <th>order_product</th>      <th>order_amount</th>      <th>month</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>    </tr>    <tr>      <th>3</th>      <td>6</td>      <td>6</td>      <td>6</td>      <td>6</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>4</td>      <td>4</td>      <td>4</td>    </tr>    <tr>      <th>5</th>      <td>11</td>      <td>11</td>      <td>11</td>      <td>11</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>23566</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>23567</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>23568</th>      <td>3</td>      <td>3</td>      <td>3</td>      <td>3</td>    </tr>    <tr>      <th>23569</th>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>23570</th>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>    </tr>  </tbody></table><p>23570 rows × 4 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户消费金额和消费产品数量的散点图</span></span><br><span class="line">user_amount_sum = df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;order_amount&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">user_product_sum = df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;order_product&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">plt.scatter(user_product_sum,user_amount_sum)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x16f5d83d6d8&gt;</code></pre><p><a href="https://imgtu.com/i/23WOc4"><img src="https://z3.ax1x.com/2021/06/03/23WOc4.jpg" alt="23WOc4.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各个用户消费总金额的直方分布图(消费金额在1000之内的分布)</span></span><br><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>).<span class="built_in">sum</span>().query(<span class="string">&#x27;order_amount &lt;= 1000&#x27;</span>)[<span class="string">&#x27;order_amount&#x27;</span>]   <span class="comment"># 取相应的数据</span></span><br><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>).<span class="built_in">sum</span>().query(<span class="string">&#x27;order_amount &lt;= 1000&#x27;</span>)[<span class="string">&#x27;order_amount&#x27;</span>].hist()    <span class="comment"># 作图</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x16f5da9b240&gt;</code></pre><p><a href="https://imgtu.com/i/23WxBR"><img src="https://z3.ax1x.com/2021/06/03/23WxBR.jpg" alt="23WxBR.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各个用户消费的总数量的直方分布图(消费商品的数量在100次之内的分布)</span></span><br><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>).<span class="built_in">sum</span>().query(<span class="string">&#x27;order_product &lt;= 100&#x27;</span>)[<span class="string">&#x27;order_product&#x27;</span>].hist()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x16f5db37208&gt;</code></pre><p><a href="https://imgtu.com/i/23WXjJ"><img src="https://z3.ax1x.com/2021/06/03/23WXjJ.jpg" alt="23WXjJ.jpg"></a></p><h2 id="第四部分：用户消费行为分析"><a href="#第四部分：用户消费行为分析" class="headerlink" title="第四部分：用户消费行为分析"></a>第四部分：用户消费行为分析</h2><ul><li>用户第一次消费的月份分布，和人数统计<ul><li>绘制线形图</li></ul></li><li>用户最后一次消费的时间分布，和人数统计<ul><li>绘制线形图</li></ul></li><li>新老客户的占比<ul><li>消费一次为新用户</li><li>消费多次为老用户<ul><li>分析出每一个用户的第一个消费和最后一次消费的时间<ul><li>agg([‘func1’,’func2’]):对分组后的结果进行指定聚合</li></ul></li><li>分析出新老客户的消费比例</li></ul></li></ul></li><li>用户分层<ul><li>分析得出每个用户的总购买量和总消费金额and最近一次消费的时间的表格rfm</li><li>RFM模型设计<ul><li>R表示客户最近一次交易时间的间隔。<ul><li>/np.timedelta64(1,’D’)：去除days</li></ul></li><li>F表示客户购买商品的总数量,F值越大，表示客户交易越频繁，反之则表示客户交易不够活跃。</li><li>M表示客户交易的金额。M值越大，表示客户价值越高，反之则表示客户价值越低。</li><li>将R，F，M作用到rfm表中</li></ul></li><li>根据价值分层，将用户分为：<ul><li>重要价值客户</li><li>重要保持客户</li><li>重要挽留客户</li><li>重要发展客户</li><li>一般价值客户</li><li>一般保持客户</li><li>一般挽留客户</li><li>一般发展客户<ul><li>使用已有的分层模型即可rfm_func</li></ul></li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户第一次消费的月份分布，和人数统计</span></span><br><span class="line"><span class="comment"># 第一次消费的月份：每一个用户消费月份的最小值就是该用户第一次消费的月份</span></span><br><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;month&#x27;</span>].<span class="built_in">min</span>()</span><br></pre></td></tr></table></figure><pre><code>user_id1       1997-01-012       1997-01-013       1997-01-014       1997-01-015       1997-01-01           ...    23566   1997-03-0123567   1997-03-0123568   1997-03-0123569   1997-03-0123570   1997-03-01Name: month, Length: 23570, dtype: datetime64[ns]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;month&#x27;</span>].<span class="built_in">min</span>().value_counts() <span class="comment"># 人数统计</span></span><br><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;month&#x27;</span>].<span class="built_in">min</span>().value_counts().plot()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x16f5ecd5c88&gt;</code></pre><p><a href="https://imgtu.com/i/23Wvu9"><img src="https://z3.ax1x.com/2021/06/03/23Wvu9.jpg" alt="23Wvu9.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户最后一次消费的时间分布，和人数统计</span></span><br><span class="line"><span class="comment"># 用户消费月份的最大值就是用户最后一次消费的月份</span></span><br><span class="line">df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;month&#x27;</span>].<span class="built_in">max</span>().value_counts().plot()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x16f5db224e0&gt;</code></pre><p><a href="https://imgtu.com/i/23WzH1"><img src="https://z3.ax1x.com/2021/06/03/23WzH1.jpg" alt="23WzH1.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新老客户的占比</span></span><br><span class="line"><span class="comment"># 消费一次为新用户，消费多次为老用户</span></span><br><span class="line"><span class="comment"># 如何获知用户是否为第一次消费？可以根据用户的消费时间进行判定？</span></span><br><span class="line">    <span class="comment"># 如果用户的第一次消费时间和最后一次消费时间一样，则该用户只消费了一次为新用户，否则为老用户</span></span><br><span class="line">new_old_user_df = df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;order_dt&#x27;</span>].agg([<span class="string">&#x27;min&#x27;</span>,<span class="string">&#x27;max&#x27;</span>])   <span class="comment"># agg对分组后的结果进行多种指定聚合</span></span><br><span class="line">new_old_user_df[<span class="string">&#x27;min&#x27;</span>] == new_old_user_df[<span class="string">&#x27;max&#x27;</span>] <span class="comment"># True新用户，False老用户</span></span><br><span class="line"><span class="comment"># 统计True和False的个数</span></span><br><span class="line">(new_old_user_df[<span class="string">&#x27;min&#x27;</span>] == new_old_user_df[<span class="string">&#x27;max&#x27;</span>]).value_counts()</span><br></pre></td></tr></table></figure><pre><code>True     12054False    11516dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分析得出每个用户的总购买量和总消费金额and最近一次消费的时间的表格rfm</span></span><br><span class="line">rfm = df.pivot_table(index=<span class="string">&#x27;user_id&#x27;</span>,aggfunc=&#123;<span class="string">&#x27;order_product&#x27;</span>:<span class="string">&#x27;sum&#x27;</span>,<span class="string">&#x27;order_amount&#x27;</span>:<span class="string">&#x27;sum&#x27;</span>,<span class="string">&#x27;order_dt&#x27;</span>:<span class="string">&quot;max&quot;</span>&#125;)</span><br><span class="line">rfm</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>order_amount</th>      <th>order_dt</th>      <th>order_product</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>11.77</td>      <td>1997-01-01</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>89.00</td>      <td>1997-01-12</td>      <td>6</td>    </tr>    <tr>      <th>3</th>      <td>156.46</td>      <td>1998-05-28</td>      <td>16</td>    </tr>    <tr>      <th>4</th>      <td>100.50</td>      <td>1997-12-12</td>      <td>7</td>    </tr>    <tr>      <th>5</th>      <td>385.61</td>      <td>1998-01-03</td>      <td>29</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>23566</th>      <td>36.00</td>      <td>1997-03-25</td>      <td>2</td>    </tr>    <tr>      <th>23567</th>      <td>20.97</td>      <td>1997-03-25</td>      <td>1</td>    </tr>    <tr>      <th>23568</th>      <td>121.70</td>      <td>1997-04-22</td>      <td>6</td>    </tr>    <tr>      <th>23569</th>      <td>25.74</td>      <td>1997-03-25</td>      <td>2</td>    </tr>    <tr>      <th>23570</th>      <td>94.08</td>      <td>1997-03-26</td>      <td>5</td>    </tr>  </tbody></table><p>23570 rows × 3 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># R表示客户最近一次交易时间的间隔</span></span><br><span class="line">max_dt = df[<span class="string">&#x27;order_dt&#x27;</span>].<span class="built_in">max</span>() <span class="comment"># 今天的日期</span></span><br><span class="line"><span class="comment"># 每一个用户最后一次交易的时间</span></span><br><span class="line">-(df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;order_dt&#x27;</span>].<span class="built_in">max</span>() - max_dt)</span><br><span class="line">rfm[<span class="string">&#x27;R&#x27;</span>] = -(df.groupby(<span class="string">&#x27;user_id&#x27;</span>)[<span class="string">&#x27;order_dt&#x27;</span>].<span class="built_in">max</span>() - max_dt)/np.timedelta64(<span class="number">1</span>,<span class="string">&#x27;D&#x27;</span>)    <span class="comment"># 将R列中的days单位去除掉</span></span><br><span class="line">rfm</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>order_amount</th>      <th>order_dt</th>      <th>order_product</th>      <th>R</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>11.77</td>      <td>1997-01-01</td>      <td>1</td>      <td>545.0</td>    </tr>    <tr>      <th>2</th>      <td>89.00</td>      <td>1997-01-12</td>      <td>6</td>      <td>534.0</td>    </tr>    <tr>      <th>3</th>      <td>156.46</td>      <td>1998-05-28</td>      <td>16</td>      <td>33.0</td>    </tr>    <tr>      <th>4</th>      <td>100.50</td>      <td>1997-12-12</td>      <td>7</td>      <td>200.0</td>    </tr>    <tr>      <th>5</th>      <td>385.61</td>      <td>1998-01-03</td>      <td>29</td>      <td>178.0</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>23566</th>      <td>36.00</td>      <td>1997-03-25</td>      <td>2</td>      <td>462.0</td>    </tr>    <tr>      <th>23567</th>      <td>20.97</td>      <td>1997-03-25</td>      <td>1</td>      <td>462.0</td>    </tr>    <tr>      <th>23568</th>      <td>121.70</td>      <td>1997-04-22</td>      <td>6</td>      <td>434.0</td>    </tr>    <tr>      <th>23569</th>      <td>25.74</td>      <td>1997-03-25</td>      <td>2</td>      <td>462.0</td>    </tr>    <tr>      <th>23570</th>      <td>94.08</td>      <td>1997-03-26</td>      <td>5</td>      <td>461.0</td>    </tr>  </tbody></table><p>23570 rows × 4 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rfm.drop(labels=<span class="string">&#x27;order_dt&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>) <span class="comment"># 将日期删掉</span></span><br><span class="line">rfm.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>order_amount</th>      <th>order_product</th>      <th>R</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>11.77</td>      <td>1</td>      <td>545.0</td>    </tr>    <tr>      <th>2</th>      <td>89.00</td>      <td>6</td>      <td>534.0</td>    </tr>    <tr>      <th>3</th>      <td>156.46</td>      <td>16</td>      <td>33.0</td>    </tr>    <tr>      <th>4</th>      <td>100.50</td>      <td>7</td>      <td>200.0</td>    </tr>    <tr>      <th>5</th>      <td>385.61</td>      <td>29</td>      <td>178.0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rfm.columns = [<span class="string">&#x27;M&#x27;</span>,<span class="string">&#x27;F&#x27;</span>,<span class="string">&#x27;R&#x27;</span>] <span class="comment"># 重置索引</span></span><br><span class="line">rfm.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>M</th>      <th>F</th>      <th>R</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>11.77</td>      <td>1</td>      <td>545.0</td>    </tr>    <tr>      <th>2</th>      <td>89.00</td>      <td>6</td>      <td>534.0</td>    </tr>    <tr>      <th>3</th>      <td>156.46</td>      <td>16</td>      <td>33.0</td>    </tr>    <tr>      <th>4</th>      <td>100.50</td>      <td>7</td>      <td>200.0</td>    </tr>    <tr>      <th>5</th>      <td>385.61</td>      <td>29</td>      <td>178.0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rfm_func</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="comment"># 存储存储的是三个字符串形式的0或者1</span></span><br><span class="line">    level = x.<span class="built_in">map</span>(<span class="keyword">lambda</span> x :<span class="string">&#x27;1&#x27;</span> <span class="keyword">if</span> x &gt;= <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">    label = level.R + level.F + level.M</span><br><span class="line">    d = &#123;</span><br><span class="line">        <span class="string">&#x27;111&#x27;</span>:<span class="string">&#x27;重要价值客户&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;011&#x27;</span>:<span class="string">&#x27;重要保持客户&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;101&#x27;</span>:<span class="string">&#x27;重要挽留客户&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;001&#x27;</span>:<span class="string">&#x27;重要发展客户&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;110&#x27;</span>:<span class="string">&#x27;一般价值客户&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;010&#x27;</span>:<span class="string">&#x27;一般保持客户&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;100&#x27;</span>:<span class="string">&#x27;一般挽留客户&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;000&#x27;</span>:<span class="string">&#x27;一般发展客户&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    result = d[label]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"><span class="comment"># df.apply(func):可以对df中的行或者列进行某种（func）形式的运算</span></span><br><span class="line">rfm[<span class="string">&#x27;label&#x27;</span>] = rfm.apply(<span class="keyword">lambda</span> x : x - x.mean()).apply(rfm_func,axis = <span class="number">1</span>)</span><br><span class="line">rfm.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>M</th>      <th>F</th>      <th>R</th>      <th>label</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>11.77</td>      <td>1</td>      <td>545.0</td>      <td>一般挽留客户</td>    </tr>    <tr>      <th>2</th>      <td>89.00</td>      <td>6</td>      <td>534.0</td>      <td>一般挽留客户</td>    </tr>    <tr>      <th>3</th>      <td>156.46</td>      <td>16</td>      <td>33.0</td>      <td>重要保持客户</td>    </tr>    <tr>      <th>4</th>      <td>100.50</td>      <td>7</td>      <td>200.0</td>      <td>一般发展客户</td>    </tr>    <tr>      <th>5</th>      <td>385.61</td>      <td>29</td>      <td>178.0</td>      <td>重要保持客户</td>    </tr>  </tbody></table></div><h2 id="第五部分：用户的生命周期"><a href="#第五部分：用户的生命周期" class="headerlink" title="第五部分：用户的生命周期"></a>第五部分：用户的生命周期</h2><ul><li>将用户划分为活跃用户和其他用户<ul><li>统计每个用户每个月的消费次数</li><li>统计每个用户每个月是否消费，消费记录为1否则记录为0<ul><li>知识点：DataFrame的apply和applymap的区别<ul><li>applymap:返回df</li><li>将函数做用于DataFrame中的所有元素(elements)</li><li>apply:返回Series</li><li>apply()将一个函数作用于DataFrame中的每个行或者列</li></ul></li></ul></li><li>将用户按照每一个月份分成：<ul><li>unreg:观望用户（前两月没买，第三个月才第一次买,则用户前两个月为观望用户）</li><li>unactive:首月购买后，后序月份没有购买则在没有购买的月份中该用户的为非活跃用户</li><li>new:当前月就进行首次购买的用户在当前月为新用户</li><li>active:连续月份购买的用户在这些月中为活跃用户</li><li>return:购买之后间隔n月再次购买的第一个月份为该月份的回头客</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每个用户每个月的消费次数</span></span><br><span class="line">user_month_count_df = df.pivot_table(index=<span class="string">&#x27;user_id&#x27;</span>,values=<span class="string">&#x27;order_dt&#x27;</span>,aggfunc=<span class="string">&#x27;count&#x27;</span>,columns=<span class="string">&#x27;month&#x27;</span>).fillna(<span class="number">0</span>)</span><br><span class="line">user_month_count_df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>month</th>      <th>1997-01-01</th>      <th>1997-02-01</th>      <th>1997-03-01</th>      <th>1997-04-01</th>      <th>1997-05-01</th>      <th>1997-06-01</th>      <th>1997-07-01</th>      <th>1997-08-01</th>      <th>1997-09-01</th>      <th>1997-10-01</th>      <th>1997-11-01</th>      <th>1997-12-01</th>      <th>1998-01-01</th>      <th>1998-02-01</th>      <th>1998-03-01</th>      <th>1998-04-01</th>      <th>1998-05-01</th>      <th>1998-06-01</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <th>2</th>      <td>2.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <th>3</th>      <td>1.0</td>      <td>0.0</td>      <td>1.0</td>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>2.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>1.0</td>      <td>0.0</td>    </tr>    <tr>      <th>4</th>      <td>2.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <th>5</th>      <td>2.0</td>      <td>1.0</td>      <td>0.0</td>      <td>1.0</td>      <td>1.0</td>      <td>1.0</td>      <td>1.0</td>      <td>0.0</td>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>      <td>2.0</td>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每个用户每个月是否消费，消费记录为1否则记录为0</span></span><br><span class="line">df_purchase = user_month_count_df.applymap(<span class="keyword">lambda</span> x:<span class="number">1</span> <span class="keyword">if</span> x &gt;= <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">df_purchase.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>month</th>      <th>1997-01-01</th>      <th>1997-02-01</th>      <th>1997-03-01</th>      <th>1997-04-01</th>      <th>1997-05-01</th>      <th>1997-06-01</th>      <th>1997-07-01</th>      <th>1997-08-01</th>      <th>1997-09-01</th>      <th>1997-10-01</th>      <th>1997-11-01</th>      <th>1997-12-01</th>      <th>1998-01-01</th>      <th>1998-02-01</th>      <th>1998-03-01</th>      <th>1998-04-01</th>      <th>1998-05-01</th>      <th>1998-06-01</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>1</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>5</th>      <td>1</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将df_purchase中的原始数据0和1修改为new，unactive......,返回新的df叫做df_purchase_new</span></span><br><span class="line"><span class="comment"># 固定算法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">active_status</span>(<span class="params">data</span>):</span></span><br><span class="line">    status = [] <span class="comment"># 某个用户每一个月的活跃度</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">18</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 若本月没有消费</span></span><br><span class="line">        <span class="keyword">if</span> data[i] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(status) &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> status[i-<span class="number">1</span>] == <span class="string">&#x27;unreg&#x27;</span>:</span><br><span class="line">                    status.append(<span class="string">&#x27;unreg&#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    status.append(<span class="string">&#x27;unactive&#x27;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                status.append(<span class="string">&#x27;unreg&#x27;</span>)</span><br><span class="line">                    </span><br><span class="line">        <span class="comment"># 若本月消费</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(status) == <span class="number">0</span>:</span><br><span class="line">                status.append(<span class="string">&#x27;new&#x27;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> status[i-<span class="number">1</span>] == <span class="string">&#x27;unactive&#x27;</span>:</span><br><span class="line">                    status.append(<span class="string">&#x27;return&#x27;</span>)</span><br><span class="line">                <span class="keyword">elif</span> status[i-<span class="number">1</span>] == <span class="string">&#x27;unreg&#x27;</span>:</span><br><span class="line">                    status.append(<span class="string">&#x27;new&#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    status.append(<span class="string">&#x27;active&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> status</span><br><span class="line"></span><br><span class="line">pivoted_status = df_purchase.apply(active_status,axis = <span class="number">1</span>) </span><br><span class="line">pivoted_status.head()</span><br></pre></td></tr></table></figure><pre><code>user_id1    [new, unactive, unactive, unactive, unactive, ...2    [new, unactive, unactive, unactive, unactive, ...3    [new, unactive, return, active, unactive, unac...4    [new, unactive, unactive, unactive, unactive, ...5    [new, active, unactive, return, active, active...dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_purchase_new = DataFrame(data=pivoted_status.values.tolist(),index=df_purchase.index,columns=df_purchase.columns)</span><br><span class="line">df_purchase_new</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>month</th>      <th>1997-01-01</th>      <th>1997-02-01</th>      <th>1997-03-01</th>      <th>1997-04-01</th>      <th>1997-05-01</th>      <th>1997-06-01</th>      <th>1997-07-01</th>      <th>1997-08-01</th>      <th>1997-09-01</th>      <th>1997-10-01</th>      <th>1997-11-01</th>      <th>1997-12-01</th>      <th>1998-01-01</th>      <th>1998-02-01</th>      <th>1998-03-01</th>      <th>1998-04-01</th>      <th>1998-05-01</th>      <th>1998-06-01</th>    </tr>    <tr>      <th>user_id</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>new</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>    <tr>      <th>2</th>      <td>new</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>    <tr>      <th>3</th>      <td>new</td>      <td>unactive</td>      <td>return</td>      <td>active</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>return</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>return</td>      <td>unactive</td>    </tr>    <tr>      <th>4</th>      <td>new</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>return</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>return</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>    <tr>      <th>5</th>      <td>new</td>      <td>active</td>      <td>unactive</td>      <td>return</td>      <td>active</td>      <td>active</td>      <td>active</td>      <td>unactive</td>      <td>return</td>      <td>unactive</td>      <td>unactive</td>      <td>return</td>      <td>active</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>23566</th>      <td>unreg</td>      <td>unreg</td>      <td>new</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>    <tr>      <th>23567</th>      <td>unreg</td>      <td>unreg</td>      <td>new</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>    <tr>      <th>23568</th>      <td>unreg</td>      <td>unreg</td>      <td>new</td>      <td>active</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>    <tr>      <th>23569</th>      <td>unreg</td>      <td>unreg</td>      <td>new</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>    <tr>      <th>23570</th>      <td>unreg</td>      <td>unreg</td>      <td>new</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>      <td>unactive</td>    </tr>  </tbody></table><p>23570 rows × 18 columns</p></div><ul><li>每月【不同活跃】用户的计数<ul><li>purchase_status_ct = df_purchase_new.apply(lambda x : pd.value_counts(x)).fillna(0)</li><li>转置进行最终结果的查看</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">purchase_status_ct = df_purchase_new.apply(<span class="keyword">lambda</span> x : pd.value_counts(x)).fillna(<span class="number">0</span>)</span><br><span class="line">purchase_status_ct</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>month</th>      <th>1997-01-01</th>      <th>1997-02-01</th>      <th>1997-03-01</th>      <th>1997-04-01</th>      <th>1997-05-01</th>      <th>1997-06-01</th>      <th>1997-07-01</th>      <th>1997-08-01</th>      <th>1997-09-01</th>      <th>1997-10-01</th>      <th>1997-11-01</th>      <th>1997-12-01</th>      <th>1998-01-01</th>      <th>1998-02-01</th>      <th>1998-03-01</th>      <th>1998-04-01</th>      <th>1998-05-01</th>      <th>1998-06-01</th>    </tr>  </thead>  <tbody>    <tr>      <th>active</th>      <td>0.0</td>      <td>1157.0</td>      <td>1681.0</td>      <td>1773.0</td>      <td>852.0</td>      <td>747.0</td>      <td>746.0</td>      <td>604.0</td>      <td>528.0</td>      <td>532.0</td>      <td>624.0</td>      <td>632.0</td>      <td>512.0</td>      <td>472.0</td>      <td>571.0</td>      <td>518.0</td>      <td>459.0</td>      <td>446.0</td>    </tr>    <tr>      <th>new</th>      <td>7846.0</td>      <td>8476.0</td>      <td>7248.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <th>return</th>      <td>0.0</td>      <td>0.0</td>      <td>595.0</td>      <td>1049.0</td>      <td>1362.0</td>      <td>1592.0</td>      <td>1434.0</td>      <td>1168.0</td>      <td>1211.0</td>      <td>1307.0</td>      <td>1404.0</td>      <td>1232.0</td>      <td>1025.0</td>      <td>1079.0</td>      <td>1489.0</td>      <td>919.0</td>      <td>1029.0</td>      <td>1060.0</td>    </tr>    <tr>      <th>unactive</th>      <td>0.0</td>      <td>6689.0</td>      <td>14046.0</td>      <td>20748.0</td>      <td>21356.0</td>      <td>21231.0</td>      <td>21390.0</td>      <td>21798.0</td>      <td>21831.0</td>      <td>21731.0</td>      <td>21542.0</td>      <td>21706.0</td>      <td>22033.0</td>      <td>22019.0</td>      <td>21510.0</td>      <td>22133.0</td>      <td>22082.0</td>      <td>22064.0</td>    </tr>    <tr>      <th>unreg</th>      <td>15724.0</td>      <td>7248.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">purchase_status_ct.T</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>active</th>      <th>new</th>      <th>return</th>      <th>unactive</th>      <th>unreg</th>    </tr>    <tr>      <th>month</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1997-01-01</th>      <td>0.0</td>      <td>7846.0</td>      <td>0.0</td>      <td>0.0</td>      <td>15724.0</td>    </tr>    <tr>      <th>1997-02-01</th>      <td>1157.0</td>      <td>8476.0</td>      <td>0.0</td>      <td>6689.0</td>      <td>7248.0</td>    </tr>    <tr>      <th>1997-03-01</th>      <td>1681.0</td>      <td>7248.0</td>      <td>595.0</td>      <td>14046.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-04-01</th>      <td>1773.0</td>      <td>0.0</td>      <td>1049.0</td>      <td>20748.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-05-01</th>      <td>852.0</td>      <td>0.0</td>      <td>1362.0</td>      <td>21356.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-06-01</th>      <td>747.0</td>      <td>0.0</td>      <td>1592.0</td>      <td>21231.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-07-01</th>      <td>746.0</td>      <td>0.0</td>      <td>1434.0</td>      <td>21390.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-08-01</th>      <td>604.0</td>      <td>0.0</td>      <td>1168.0</td>      <td>21798.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-09-01</th>      <td>528.0</td>      <td>0.0</td>      <td>1211.0</td>      <td>21831.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-10-01</th>      <td>532.0</td>      <td>0.0</td>      <td>1307.0</td>      <td>21731.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-11-01</th>      <td>624.0</td>      <td>0.0</td>      <td>1404.0</td>      <td>21542.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1997-12-01</th>      <td>632.0</td>      <td>0.0</td>      <td>1232.0</td>      <td>21706.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1998-01-01</th>      <td>512.0</td>      <td>0.0</td>      <td>1025.0</td>      <td>22033.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1998-02-01</th>      <td>472.0</td>      <td>0.0</td>      <td>1079.0</td>      <td>22019.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1998-03-01</th>      <td>571.0</td>      <td>0.0</td>      <td>1489.0</td>      <td>21510.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1998-04-01</th>      <td>518.0</td>      <td>0.0</td>      <td>919.0</td>      <td>22133.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1998-05-01</th>      <td>459.0</td>      <td>0.0</td>      <td>1029.0</td>      <td>22082.0</td>      <td>0.0</td>    </tr>    <tr>      <th>1998-06-01</th>      <td>446.0</td>      <td>0.0</td>      <td>1060.0</td>      <td>22064.0</td>      <td>0.0</td>    </tr>  </tbody></table></div><hr><p>本文提及的数据集下载地址：<br>链接：<a href="https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg">https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg</a><br>提取码：1111 </p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;第一部分：数据类型处理&quot;&gt;&lt;a href=&quot;#第一部分：数据类型处理&quot; class=&quot;headerlink&quot; title=&quot;第一部分：数据类型处理&quot;&gt;&lt;/a&gt;第一部分：数据类型处理&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据加载&lt;ul&gt;
&lt;li&gt;字段含义：&lt;ul&gt;
&lt;li&gt;user_id:用户ID&lt;/li&gt;
&lt;li&gt;order_dt:购买日期&lt;/li&gt;
&lt;li&gt;order_product:购买产品的数量&lt;/li&gt;
&lt;li&gt;order_amount:购买金额&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;观察数据&lt;ul&gt;
&lt;li&gt;查看数据的数据类型&lt;/li&gt;
&lt;li&gt;数据中是否存储在缺失值&lt;/li&gt;
&lt;li&gt;将order_dt转换成时间类型&lt;/li&gt;
&lt;li&gt;查看数据的统计描述&lt;ul&gt;
&lt;li&gt;计算所有用户购买商品的平均数量&lt;/li&gt;
&lt;li&gt;计算所有用户购买商品的平均花费&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在源数据中添加一列表示月份:astype(‘datetime64[M]‘)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>绘图 matplotlib</title>
    <link href="http://woody0819.github.io/2021/05/27/test_8/"/>
    <id>http://woody0819.github.io/2021/05/27/test_8/</id>
    <published>2021-05-27T03:58:27.836Z</published>
    <updated>2021-06-03T11:09:38.287Z</updated>
    
    <content type="html"><![CDATA[<h2 id="plt-plot-绘制线性图"><a href="#plt-plot-绘制线性图" class="headerlink" title="plt.plot()绘制线性图"></a>plt.plot()绘制线性图</h2><ul><li>绘制单条线形图</li><li>绘制多条线形图</li><li>设置坐标系的比例</li><li>设置图例legend()</li><li>设置轴的标识</li><li>图例保存</li><li>曲线的样式和风格</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 绘制单条线形图</span></span><br><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">y = x + <span class="number">3</span></span><br><span class="line">plt.plot(x,y)</span><br></pre></td></tr></table></figure><span id="more"></span><pre><code>[&lt;matplotlib.lines.Line2D at 0x1d441b225f8&gt;]</code></pre><p><a href="https://imgtu.com/i/23Rwd0"><img src="https://z3.ax1x.com/2021/06/03/23Rwd0.jpg" alt="23Rwd0.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制多条线形图</span></span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.plot(x+<span class="number">1</span>,y-<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x1d4419feb38&gt;]</code></pre><p><a href="https://imgtu.com/i/23RdZq"><img src="https://z3.ax1x.com/2021/06/03/23RdZq.jpg" alt="23RdZq.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x,y,x+<span class="number">1</span>,y-<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x1d441abb2b0&gt;, &lt;matplotlib.lines.Line2D at 0x1d441abb3c8&gt;]</code></pre><p><a href="https://imgtu.com/i/23RDiT"><img src="https://z3.ax1x.com/2021/06/03/23RDiT.jpg" alt="23RDiT.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置坐标系的比例plt.figure(figsize=(a,b))</span></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>,<span class="number">9</span>))   <span class="comment"># 放置在绘图的plot方法之前</span></span><br><span class="line">plt.plot(x,y)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x1d441beef98&gt;]</code></pre><p><a href="https://imgtu.com/i/23R0oV"><img src="https://z3.ax1x.com/2021/06/03/23R0oV.jpg" alt="23R0oV.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置图例legend()</span></span><br><span class="line">plt.plot(x,y,label=<span class="string">&#x27;x,y&#x27;</span>)</span><br><span class="line">plt.plot(x+<span class="number">1</span>,y-<span class="number">2</span>,label=<span class="string">&#x27;x+1,y-2&#x27;</span>)</span><br><span class="line">plt.legend()    <span class="comment"># 图例生效</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x1d441c6f780&gt;</code></pre><p><a href="https://imgtu.com/i/23RNss"><img src="https://z3.ax1x.com/2021/06/03/23RNss.jpg" alt="23RNss.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置轴的标识</span></span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;temp&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;dist&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;dist&amp;temp&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>Text(0.5, 1.0, &#39;dist&amp;temp&#39;)</code></pre><p><a href="https://imgtu.com/i/23RrJU"><img src="https://z3.ax1x.com/2021/06/03/23RrJU.jpg" alt="23RrJU.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图例保存</span></span><br><span class="line">fig = plt.figure()  <span class="comment"># 该对象的创建一定要放置在plot绘图之前</span></span><br><span class="line">plt.plot(x,y,label=<span class="string">&#x27;x,y&#x27;</span>)</span><br><span class="line">fig.savefig(<span class="string">&#x27;./123.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/23RsWF"><img src="https://z3.ax1x.com/2021/06/03/23RsWF.jpg" alt="23RsWF.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 曲线的样式和风格资料很多，相关参数设置可自行查询按需更改</span></span><br><span class="line">plt.plot(x,y,c=<span class="string">&#x27;red&#x27;</span>,alpha=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x1d441dc6eb8&gt;]</code></pre><p><a href="https://imgtu.com/i/23Ryz4"><img src="https://z3.ax1x.com/2021/06/03/23Ryz4.jpg" alt="23Ryz4.jpg"></a></p><h2 id="柱状图：plt-bar"><a href="#柱状图：plt-bar" class="headerlink" title="柱状图：plt.bar()"></a>柱状图：plt.bar()</h2><ul><li>参数：第一个参数是索引。第二个参数是数据值。第三个参数是条形的宽度</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.bar(x,y)</span><br></pre></td></tr></table></figure><pre><code>&lt;BarContainer object of 5 artists&gt;</code></pre><p><a href="https://imgtu.com/i/23RcQJ"><img src="https://z3.ax1x.com/2021/06/03/23RcQJ.jpg" alt="23RcQJ.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.barh(x,y)</span><br></pre></td></tr></table></figure><pre><code>&lt;BarContainer object of 5 artists&gt;</code></pre><p><a href="https://imgtu.com/i/23Rgy9"><img src="https://z3.ax1x.com/2021/06/03/23Rgy9.jpg" alt="23Rgy9.jpg"></a></p><h2 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h2><ul><li>是一个特殊的柱状图，又叫做密度图</li><li>plt.hist()的参数<ul><li>bins<br>可以是一个bin数量的整数值，也可以是表示bin的一个序列。默认值为10</li><li>normed<br>如果值为True，直方图的值将进行归一化处理，形成概率密度，默认值为False</li><li>color<br>指定直方图的颜色。可以是单一颜色值或颜色的序列。如果指定了多个数据集合,例如DataFrame对象，颜色序列将会设置为相同的顺序。如果未指定，将会使用一个默认的线条颜色</li><li>orientation<br>通过设置orientation为horizontal创建水平直方图。默认值为vertical</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>]</span><br><span class="line">plt.hist(data,bins=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([1., 0., 2., 0., 3., 0., 1., 0., 1., 0., 0., 1., 0., 6., 0., 1., 0.,        1., 0., 1.]), array([0.  , 0.45, 0.9 , 1.35, 1.8 , 2.25, 2.7 , 3.15, 3.6 , 4.05, 4.5 ,        4.95, 5.4 , 5.85, 6.3 , 6.75, 7.2 , 7.65, 8.1 , 8.55, 9.  ]), &lt;a list of 20 Patch objects&gt;)</code></pre><p><a href="https://imgtu.com/i/23Rfdx"><img src="https://z3.ax1x.com/2021/06/03/23Rfdx.jpg" alt="23Rfdx.jpg"></a></p><h2 id="饼图"><a href="#饼图" class="headerlink" title="饼图"></a>饼图</h2><ul><li>pie()，饼图也只有一个参数x</li><li>饼图适合展示各部分占总体的比例，条形图适合比较各部分的大小</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr=[<span class="number">11</span>,<span class="number">22</span>,<span class="number">31</span>,<span class="number">15</span>]</span><br><span class="line">plt.pie(arr)</span><br></pre></td></tr></table></figure><pre><code>([&lt;matplotlib.patches.Wedge at 0x1d441a7bb00&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441aefef0&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441aef8d0&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441abbdd8&gt;], [Text(0.9964244374501308, 0.46598105160209097, &#39;&#39;),  Text(-0.19579764419425466, 1.0824339622018426, &#39;&#39;),  Text(-0.830021124093439, -0.7218482759961848, &#39;&#39;),  Text(0.9100343885615038, -0.617929940717789, &#39;&#39;)])</code></pre><p><a href="https://imgtu.com/i/23R2LR"><img src="https://z3.ax1x.com/2021/06/03/23R2LR.jpg" alt="23R2LR.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr=[<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.1</span>]</span><br><span class="line">plt.pie(arr)</span><br></pre></td></tr></table></figure><pre><code>([&lt;matplotlib.patches.Wedge at 0x1d441b6fdd8&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441a72630&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441c0e5c0&gt;], [Text(0.8899186877588753, 0.6465637858537406, &#39;&#39;),  Text(-0.64656382751384, 0.8899186574910392, &#39;&#39;),  Text(-1.0461621345079049, -0.3399187966586502, &#39;&#39;)])</code></pre><p><a href="https://imgtu.com/i/23Rho6"><img src="https://z3.ax1x.com/2021/06/03/23Rho6.jpg" alt="23Rho6.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr=[<span class="number">11</span>,<span class="number">22</span>,<span class="number">31</span>,<span class="number">15</span>]</span><br><span class="line">plt.pie(arr,labels=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>])</span><br></pre></td></tr></table></figure><pre><code>([&lt;matplotlib.patches.Wedge at 0x1d441d3a4a8&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441cd02e8&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441d24748&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441d24b00&gt;], [Text(0.9964244374501308, 0.46598105160209097, &#39;a&#39;),  Text(-0.19579764419425466, 1.0824339622018426, &#39;b&#39;),  Text(-0.830021124093439, -0.7218482759961848, &#39;c&#39;),  Text(0.9100343885615038, -0.617929940717789, &#39;d&#39;)])</code></pre><p><a href="https://imgtu.com/i/23RWe1"><img src="https://z3.ax1x.com/2021/06/03/23RWe1.jpg" alt="23RWe1.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr=[<span class="number">11</span>,<span class="number">22</span>,<span class="number">31</span>,<span class="number">15</span>]</span><br><span class="line">plt.pie(arr,labels=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>],labeldistance=<span class="number">0.3</span>)</span><br></pre></td></tr></table></figure><pre><code>([&lt;matplotlib.patches.Wedge at 0x1d441e3ebe0&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441f0a588&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441f0aa90&gt;,  &lt;matplotlib.patches.Wedge at 0x1d441e782e8&gt;], [Text(0.2717521193045811, 0.1270857413460248, &#39;a&#39;),  Text(-0.05339935750752399, 0.29520926241868434, &#39;b&#39;),  Text(-0.2263693974800288, -0.1968677116353231, &#39;c&#39;),  Text(0.24819119688041008, -0.16852634746848788, &#39;d&#39;)])</code></pre><p><a href="https://imgtu.com/i/23R5FK"><img src="https://z3.ax1x.com/2021/06/03/23R5FK.jpg" alt="23R5FK.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr=[<span class="number">11</span>,<span class="number">22</span>,<span class="number">31</span>,<span class="number">15</span>]</span><br><span class="line">plt.pie(arr,labels=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>],labeldistance=<span class="number">0.3</span>,autopct=<span class="string">&#x27;%.6f%%&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>([&lt;matplotlib.patches.Wedge at 0x1d44201f908&gt;,  &lt;matplotlib.patches.Wedge at 0x1d44202f0b8&gt;,  &lt;matplotlib.patches.Wedge at 0x1d44202f7f0&gt;,  &lt;matplotlib.patches.Wedge at 0x1d44202ff28&gt;], [Text(0.2717521193045811, 0.1270857413460248, &#39;a&#39;),  Text(-0.05339935750752399, 0.29520926241868434, &#39;b&#39;),  Text(-0.2263693974800288, -0.1968677116353231, &#39;c&#39;),  Text(0.24819119688041008, -0.16852634746848788, &#39;d&#39;)], [Text(0.5435042386091622, 0.2541714826920496, &#39;13.924050%&#39;),  Text(-0.10679871501504798, 0.5904185248373687, &#39;27.848101%&#39;),  Text(-0.4527387949600576, -0.3937354232706462, &#39;39.240506%&#39;),  Text(0.49638239376082016, -0.33705269493697576, &#39;18.987341%&#39;)])</code></pre><p><a href="https://imgtu.com/i/23R7Se"><img src="https://z3.ax1x.com/2021/06/03/23R7Se.jpg" alt="23R7Se.jpg"></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr=[<span class="number">11</span>,<span class="number">22</span>,<span class="number">31</span>,<span class="number">15</span>]</span><br><span class="line">plt.pie(arr,labels=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>],labeldistance=<span class="number">0.3</span>,shadow=<span class="literal">True</span>,explode=[<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.2</span>,<span class="number">0.4</span>])</span><br></pre></td></tr></table></figure><pre><code>([&lt;matplotlib.patches.Wedge at 0x1d44207b278&gt;,  &lt;matplotlib.patches.Wedge at 0x1d44207ba58&gt;,  &lt;matplotlib.patches.Wedge at 0x1d442089240&gt;,  &lt;matplotlib.patches.Wedge at 0x1d4420899e8&gt;], [Text(0.4529201988409685, 0.21180956891004132, &#39;a&#39;),  Text(-0.10679871501504798, 0.5904185248373687, &#39;b&#39;),  Text(-0.37728232913338133, -0.32811285272553853, &#39;c&#39;),  Text(0.579112792720957, -0.3932281440931384, &#39;d&#39;)])</code></pre><p><a href="https://imgtu.com/i/23RIJO"><img src="https://z3.ax1x.com/2021/06/03/23RIJO.jpg" alt="23RIJO.jpg"></a></p><h2 id="散点图scatter"><a href="#散点图scatter" class="headerlink" title="散点图scatter()"></a>散点图scatter()</h2><ul><li>因变量随自变量而变化的大致趋势</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>])</span><br><span class="line">y = x ** <span class="number">2</span> - <span class="number">3</span></span><br><span class="line">plt.scatter(x,y)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x1d4420c7ba8&gt;</code></pre><p><a href="https://imgtu.com/i/23RoWD"><img src="https://z3.ax1x.com/2021/06/03/23RoWD.jpg" alt="23RoWD.jpg"></a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;plt-plot-绘制线性图&quot;&gt;&lt;a href=&quot;#plt-plot-绘制线性图&quot; class=&quot;headerlink&quot; title=&quot;plt.plot()绘制线性图&quot;&gt;&lt;/a&gt;plt.plot()绘制线性图&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;绘制单条线形图&lt;/li&gt;
&lt;li&gt;绘制多条线形图&lt;/li&gt;
&lt;li&gt;设置坐标系的比例&lt;/li&gt;
&lt;li&gt;设置图例legend()&lt;/li&gt;
&lt;li&gt;设置轴的标识&lt;/li&gt;
&lt;li&gt;图例保存&lt;/li&gt;
&lt;li&gt;曲线的样式和风格&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 绘制单条线形图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;x = np.array([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;y = x + &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;plt.plot(x,y)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>2012美国大选献金项目数据分析案例</title>
    <link href="http://woody0819.github.io/2021/05/27/test_7/"/>
    <id>http://woody0819.github.io/2021/05/27/test_7/</id>
    <published>2021-05-27T03:58:00.508Z</published>
    <updated>2021-05-27T04:01:31.967Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><ul><li>加载数据</li><li>查看数据的基本信息</li><li>指定数据截取，将如下字段的数据进行提取，其他数据舍弃<ul><li>cand_nm ：候选人姓名</li><li>contbr_nm ： 捐赠人姓名</li><li>contbr_st ：捐赠人所在州</li><li>contbr_employer ： 捐赠人所在公司</li><li>contbr_occupation ： 捐赠人职业</li><li>contb_receipt_amt ：捐赠数额（美元）</li><li>contb_receipt_dt ： 捐款的日期</li></ul></li><li>对新数据进行总览,查看是否存在缺失数据</li><li>用统计学指标快速描述数值型属性的概要</li><li>空值处理，可能因为忘记填写或者保密等等原因，相关字段出现了空值，将其填充为NOT PROVIDE</li><li>异常值处理，将捐款金额&lt;=0的数据删除</li><li>新建一列为各个候选人所在党派party</li><li>查看party这一列中有哪些不同的元素</li><li>统计party列中各个元素出现次数</li><li>查看各个党派收到的政治献金总数contb_receipt_amt</li><li>查看具体每天各个党派收到的政治献金总数contb_receipt_amt</li><li>将表中日期格式转换为’yyyy-mm-dd’</li><li>查看老兵(捐献者职业)DISABLED VETERAN主要支持谁</li></ul><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./data/usa_election.txt&#x27;</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><pre><code>C:\Users\86156\.conda\envs\DL\lib\site-packages\IPython\core\interactiveshell.py:2714: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.  interactivity=interactivity, compiler=compiler, result=result)</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>cmte_id</th>      <th>cand_id</th>      <th>cand_nm</th>      <th>contbr_nm</th>      <th>contbr_city</th>      <th>contbr_st</th>      <th>contbr_zip</th>      <th>contbr_employer</th>      <th>contbr_occupation</th>      <th>contb_receipt_amt</th>      <th>contb_receipt_dt</th>      <th>receipt_desc</th>      <th>memo_cd</th>      <th>memo_text</th>      <th>form_tp</th>      <th>file_num</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>HARVEY, WILLIAM</td>      <td>MOBILE</td>      <td>AL</td>      <td>3.6601e+08</td>      <td>RETIRED</td>      <td>RETIRED</td>      <td>250.0</td>      <td>20-JUN-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>736166</td>    </tr>    <tr>      <th>1</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>HARVEY, WILLIAM</td>      <td>MOBILE</td>      <td>AL</td>      <td>3.6601e+08</td>      <td>RETIRED</td>      <td>RETIRED</td>      <td>50.0</td>      <td>23-JUN-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>736166</td>    </tr>    <tr>      <th>2</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>SMITH, LANIER</td>      <td>LANETT</td>      <td>AL</td>      <td>3.68633e+08</td>      <td>INFORMATION REQUESTED</td>      <td>INFORMATION REQUESTED</td>      <td>250.0</td>      <td>05-JUL-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>749073</td>    </tr>    <tr>      <th>3</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>BLEVINS, DARONDA</td>      <td>PIGGOTT</td>      <td>AR</td>      <td>7.24548e+08</td>      <td>NONE</td>      <td>RETIRED</td>      <td>250.0</td>      <td>01-AUG-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>749073</td>    </tr>    <tr>      <th>4</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>WARDENBURG, HAROLD</td>      <td>HOT SPRINGS NATION</td>      <td>AR</td>      <td>7.19016e+08</td>      <td>NONE</td>      <td>RETIRED</td>      <td>300.0</td>      <td>20-JUN-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>736166</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>536036</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>ANDERSON, MARILEE MRS.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>2500.0</td>      <td>31-AUG-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>751678</td>    </tr>    <tr>      <th>536037</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>TOLBERT, DARYL MR.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>T.A.C.C.</td>      <td>LONGWALL MAINTENANCE FOREMAN</td>      <td>500.0</td>      <td>30-SEP-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>751678</td>    </tr>    <tr>      <th>536038</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>GRANE, BRYAN F. MR.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>500.0</td>      <td>29-SEP-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>751678</td>    </tr>    <tr>      <th>536039</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>DUFFY, DAVID A. MR.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>DUFFY EQUIPMENT COMPANY INC.</td>      <td>BUSINESS OWNER</td>      <td>2500.0</td>      <td>30-SEP-11</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>SA17A</td>      <td>751678</td>    </tr>    <tr>      <th>536040</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>GORMAN, CHRIS D. MR.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>5000.0</td>      <td>29-SEP-11</td>      <td>REATTRIBUTION / REDESIGNATION REQUESTED (AUTOM...</td>      <td>NaN</td>      <td>REATTRIBUTION / REDESIGNATION REQUESTED (AUTOM...</td>      <td>SA17A</td>      <td>751678</td>    </tr>  </tbody></table><p>536041 rows × 16 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定数据截取</span></span><br><span class="line">df[<span class="string">&#x27;cand_nm&#x27;</span>]</span><br></pre></td></tr></table></figure><pre><code>0         Bachmann, Michelle1         Bachmann, Michelle2         Bachmann, Michelle3         Bachmann, Michelle4         Bachmann, Michelle                 ...        536036           Perry, Rick536037           Perry, Rick536038           Perry, Rick536039           Perry, Rick536040           Perry, RickName: cand_nm, Length: 536041, dtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据的基本信息，是否存在缺失数据</span></span><br><span class="line">df.info()   <span class="comment"># 可以看到并非所有列都是536041，即这些列有空值</span></span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 536041 entries, 0 to 536040Data columns (total 16 columns): #   Column             Non-Null Count   Dtype  ---  ------             --------------   -----   0   cmte_id            536041 non-null  object  1   cand_id            536041 non-null  object  2   cand_nm            536041 non-null  object  3   contbr_nm          536041 non-null  object  4   contbr_city        536026 non-null  object  5   contbr_st          536040 non-null  object  6   contbr_zip         535973 non-null  object  7   contbr_employer    525088 non-null  object  8   contbr_occupation  530520 non-null  object  9   contb_receipt_amt  536041 non-null  float64 10  contb_receipt_dt   536041 non-null  object  11  receipt_desc       8479 non-null    object  12  memo_cd            49718 non-null   object  13  memo_text          52740 non-null   object  14  form_tp            536041 non-null  object  15  file_num           536041 non-null  int64  dtypes: float64(1), int64(1), object(14)memory usage: 65.4+ MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用统计学指标快速描述数值型属性的概要</span></span><br><span class="line">df.describe()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>contb_receipt_amt</th>      <th>file_num</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>5.360410e+05</td>      <td>536041.000000</td>    </tr>    <tr>      <th>mean</th>      <td>3.750373e+02</td>      <td>761472.107800</td>    </tr>    <tr>      <th>std</th>      <td>3.564436e+03</td>      <td>5148.893508</td>    </tr>    <tr>      <th>min</th>      <td>-3.080000e+04</td>      <td>723511.000000</td>    </tr>    <tr>      <th>25%</th>      <td>5.000000e+01</td>      <td>756218.000000</td>    </tr>    <tr>      <th>50%</th>      <td>1.000000e+02</td>      <td>763233.000000</td>    </tr>    <tr>      <th>75%</th>      <td>2.500000e+02</td>      <td>763621.000000</td>    </tr>    <tr>      <th>max</th>      <td>1.944042e+06</td>      <td>767394.000000</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 空值处理。可能因为忘记填写或者保密等等原因，相关字段出现了空值，将其填充为NOT PROVIDE</span></span><br><span class="line">df.fillna(value=<span class="string">&#x27;NOT PROVIDE&#x27;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">df.info()   <span class="comment"># 可以观察到已经没有空值</span></span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 536041 entries, 0 to 536040Data columns (total 16 columns): #   Column             Non-Null Count   Dtype  ---  ------             --------------   -----   0   cmte_id            536041 non-null  object  1   cand_id            536041 non-null  object  2   cand_nm            536041 non-null  object  3   contbr_nm          536041 non-null  object  4   contbr_city        536041 non-null  object  5   contbr_st          536041 non-null  object  6   contbr_zip         536041 non-null  object  7   contbr_employer    536041 non-null  object  8   contbr_occupation  536041 non-null  object  9   contb_receipt_amt  536041 non-null  float64 10  contb_receipt_dt   536041 non-null  object  11  receipt_desc       536041 non-null  object  12  memo_cd            536041 non-null  object  13  memo_text          536041 non-null  object  14  form_tp            536041 non-null  object  15  file_num           536041 non-null  int64  dtypes: float64(1), int64(1), object(14)memory usage: 65.4+ MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 异常值处理，将捐款金额&lt;=0的数据删除</span></span><br><span class="line">df[<span class="string">&#x27;contb_receipt_amt&#x27;</span>] &lt;= <span class="number">0</span> <span class="comment">#判断哪些值为小于等于0</span></span><br><span class="line">df.loc[df[<span class="string">&#x27;contb_receipt_amt&#x27;</span>] &lt;= <span class="number">0</span>]    <span class="comment"># 获得捐赠金额小于等于0的行数据</span></span><br><span class="line">drop_indexs = df.loc[df[<span class="string">&#x27;contb_receipt_amt&#x27;</span>] &lt;= <span class="number">0</span>].index    <span class="comment"># 获取相应数据行索引</span></span><br><span class="line">df.drop(labels=drop_indexs,axis=<span class="number">0</span>,inplace=<span class="literal">True</span>) <span class="comment"># 此处加入drop和dropna的区别，dropna针对空值进行处理，与any连用存在空值即删相应行列，与all连用全是空值才删相应行列</span></span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>cmte_id</th>      <th>cand_id</th>      <th>cand_nm</th>      <th>contbr_nm</th>      <th>contbr_city</th>      <th>contbr_st</th>      <th>contbr_zip</th>      <th>contbr_employer</th>      <th>contbr_occupation</th>      <th>contb_receipt_amt</th>      <th>contb_receipt_dt</th>      <th>receipt_desc</th>      <th>memo_cd</th>      <th>memo_text</th>      <th>form_tp</th>      <th>file_num</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>HARVEY, WILLIAM</td>      <td>MOBILE</td>      <td>AL</td>      <td>3.6601e+08</td>      <td>RETIRED</td>      <td>RETIRED</td>      <td>250.0</td>      <td>20-JUN-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>    </tr>    <tr>      <th>1</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>HARVEY, WILLIAM</td>      <td>MOBILE</td>      <td>AL</td>      <td>3.6601e+08</td>      <td>RETIRED</td>      <td>RETIRED</td>      <td>50.0</td>      <td>23-JUN-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>    </tr>    <tr>      <th>2</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>SMITH, LANIER</td>      <td>LANETT</td>      <td>AL</td>      <td>3.68633e+08</td>      <td>INFORMATION REQUESTED</td>      <td>INFORMATION REQUESTED</td>      <td>250.0</td>      <td>05-JUL-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>749073</td>    </tr>    <tr>      <th>3</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>BLEVINS, DARONDA</td>      <td>PIGGOTT</td>      <td>AR</td>      <td>7.24548e+08</td>      <td>NONE</td>      <td>RETIRED</td>      <td>250.0</td>      <td>01-AUG-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>749073</td>    </tr>    <tr>      <th>4</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>WARDENBURG, HAROLD</td>      <td>HOT SPRINGS NATION</td>      <td>AR</td>      <td>7.19016e+08</td>      <td>NONE</td>      <td>RETIRED</td>      <td>300.0</td>      <td>20-JUN-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>536036</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>ANDERSON, MARILEE MRS.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>2500.0</td>      <td>31-AUG-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>751678</td>    </tr>    <tr>      <th>536037</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>TOLBERT, DARYL MR.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>T.A.C.C.</td>      <td>LONGWALL MAINTENANCE FOREMAN</td>      <td>500.0</td>      <td>30-SEP-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>751678</td>    </tr>    <tr>      <th>536038</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>GRANE, BRYAN F. MR.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>500.0</td>      <td>29-SEP-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>751678</td>    </tr>    <tr>      <th>536039</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>DUFFY, DAVID A. MR.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>DUFFY EQUIPMENT COMPANY INC.</td>      <td>BUSINESS OWNER</td>      <td>2500.0</td>      <td>30-SEP-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>751678</td>    </tr>    <tr>      <th>536040</th>      <td>C00500587</td>      <td>P20003281</td>      <td>Perry, Rick</td>      <td>GORMAN, CHRIS D. MR.</td>      <td>INFO REQUESTED</td>      <td>XX</td>      <td>99999</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>INFORMATION REQUESTED PER BEST EFFORTS</td>      <td>5000.0</td>      <td>29-SEP-11</td>      <td>REATTRIBUTION / REDESIGNATION REQUESTED (AUTOM...</td>      <td>NOT PROVIDE</td>      <td>REATTRIBUTION / REDESIGNATION REQUESTED (AUTOM...</td>      <td>SA17A</td>      <td>751678</td>    </tr>  </tbody></table><p>530314 rows × 16 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建一列为各个候选人所在党派party</span></span><br><span class="line">parties = &#123;</span><br><span class="line">  <span class="string">&#x27;Bachmann, Michelle&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Romney, Mitt&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Obama, Barack&#x27;</span>: <span class="string">&#x27;Democrat&#x27;</span>,</span><br><span class="line">  <span class="string">&quot;Roemer, Charles E. &#x27;Buddy&#x27; III&quot;</span>: <span class="string">&#x27;Reform&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Pawlenty, Timothy&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Johnson, Gary Earl&#x27;</span>: <span class="string">&#x27;Libertarian&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Paul, Ron&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Santorum, Rick&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Cain, Herman&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Gingrich, Newt&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;McCotter, Thaddeus G&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Huntsman, Jon&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;Perry, Rick&#x27;</span>: <span class="string">&#x27;Republican&#x27;</span>           </span><br><span class="line"> &#125;  <span class="comment"># 此处利用字典新建了相应候选人对应的党派信息</span></span><br><span class="line">df[<span class="string">&#x27;cand_nm&#x27;</span>].<span class="built_in">map</span>(parties)  <span class="comment"># 此处需要映射</span></span><br><span class="line">df[<span class="string">&#x27;party&#x27;</span>] = df[<span class="string">&#x27;cand_nm&#x27;</span>].<span class="built_in">map</span>(parties)   <span class="comment"># 将映射结果加入列表新建的party列</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>cmte_id</th>      <th>cand_id</th>      <th>cand_nm</th>      <th>contbr_nm</th>      <th>contbr_city</th>      <th>contbr_st</th>      <th>contbr_zip</th>      <th>contbr_employer</th>      <th>contbr_occupation</th>      <th>contb_receipt_amt</th>      <th>contb_receipt_dt</th>      <th>receipt_desc</th>      <th>memo_cd</th>      <th>memo_text</th>      <th>form_tp</th>      <th>file_num</th>      <th>party</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>HARVEY, WILLIAM</td>      <td>MOBILE</td>      <td>AL</td>      <td>3.6601e+08</td>      <td>RETIRED</td>      <td>RETIRED</td>      <td>250.0</td>      <td>20-JUN-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>      <td>Republican</td>    </tr>    <tr>      <th>1</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>HARVEY, WILLIAM</td>      <td>MOBILE</td>      <td>AL</td>      <td>3.6601e+08</td>      <td>RETIRED</td>      <td>RETIRED</td>      <td>50.0</td>      <td>23-JUN-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>      <td>Republican</td>    </tr>    <tr>      <th>2</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>SMITH, LANIER</td>      <td>LANETT</td>      <td>AL</td>      <td>3.68633e+08</td>      <td>INFORMATION REQUESTED</td>      <td>INFORMATION REQUESTED</td>      <td>250.0</td>      <td>05-JUL-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>749073</td>      <td>Republican</td>    </tr>    <tr>      <th>3</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>BLEVINS, DARONDA</td>      <td>PIGGOTT</td>      <td>AR</td>      <td>7.24548e+08</td>      <td>NONE</td>      <td>RETIRED</td>      <td>250.0</td>      <td>01-AUG-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>749073</td>      <td>Republican</td>    </tr>    <tr>      <th>4</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>WARDENBURG, HAROLD</td>      <td>HOT SPRINGS NATION</td>      <td>AR</td>      <td>7.19016e+08</td>      <td>NONE</td>      <td>RETIRED</td>      <td>300.0</td>      <td>20-JUN-11</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>      <td>Republican</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看party这一列中有哪些不同的元素</span></span><br><span class="line">df[<span class="string">&#x27;party&#x27;</span>].unique()    <span class="comment"># unique以列表形式返回Series中出现的数据有哪些，即不重复数据直接返回，重复相同数据只返回一个</span></span><br></pre></td></tr></table></figure><pre><code>array([&#39;Republican&#39;, &#39;Democrat&#39;, &#39;Reform&#39;, &#39;Libertarian&#39;], dtype=object)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计party列中各个元素出现次数</span></span><br><span class="line">df[<span class="string">&#x27;party&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure><pre><code>Democrat       289999Republican     234300Reform           5313Libertarian       702Name: party, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看各个党派收到的政治献金总数contb_receipt_amt</span></span><br><span class="line">df.groupby(<span class="string">&#x27;party&#x27;</span>)[<span class="string">&#x27;contb_receipt_amt&#x27;</span>].<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><pre><code>partyDemocrat       8.259441e+07Libertarian    4.132769e+05Reform         3.429658e+05Republican     1.251181e+08Name: contb_receipt_amt, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看具体每天各个党派收到的政治献金总数contb_receipt_amt</span></span><br><span class="line">df.groupby([<span class="string">&#x27;contb_receipt_dt&#x27;</span>,<span class="string">&#x27;party&#x27;</span>])[<span class="string">&#x27;contb_receipt_amt&#x27;</span>].<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><pre><code>contb_receipt_dt  party      01-APR-11         Reform             50.00                  Republican      12635.0001-AUG-11         Democrat       182198.00                  Libertarian      1000.00                  Reform           1847.00                                   ...    31-MAY-11         Republican     313839.8031-OCT-11         Democrat       216971.87                  Libertarian      4250.00                  Reform           3205.00                  Republican     751542.36Name: contb_receipt_amt, Length: 1183, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将表中日期格式转换为&#x27;yyyy-mm-dd&#x27;</span></span><br><span class="line">months = &#123;<span class="string">&#x27;JAN&#x27;</span> : <span class="number">1</span>, <span class="string">&#x27;FEB&#x27;</span> : <span class="number">2</span>, <span class="string">&#x27;MAR&#x27;</span> : <span class="number">3</span>, <span class="string">&#x27;APR&#x27;</span> : <span class="number">4</span>, <span class="string">&#x27;MAY&#x27;</span> : <span class="number">5</span>, <span class="string">&#x27;JUN&#x27;</span> : <span class="number">6</span>,</span><br><span class="line">          <span class="string">&#x27;JUL&#x27;</span> : <span class="number">7</span>, <span class="string">&#x27;AUG&#x27;</span> : <span class="number">8</span>, <span class="string">&#x27;SEP&#x27;</span> : <span class="number">9</span>, <span class="string">&#x27;OCT&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;NOV&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;DEC&#x27;</span> : <span class="number">12</span>&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transformDate</span>(<span class="params">d</span>):</span></span><br><span class="line">    day,month,year = d.split(<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">    month = months[month]   <span class="comment"># 字典取值，将英文形式的月份转换为数字形式的月份</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;20&#x27;</span>+year+<span class="string">&#x27;-&#x27;</span>+<span class="built_in">str</span>(month)+<span class="string">&#x27;-&#x27;</span>+day</span><br><span class="line">df[<span class="string">&#x27;contb_receipt_dt&#x27;</span>] = df[<span class="string">&#x27;contb_receipt_dt&#x27;</span>].<span class="built_in">map</span>(transformDate)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>cmte_id</th>      <th>cand_id</th>      <th>cand_nm</th>      <th>contbr_nm</th>      <th>contbr_city</th>      <th>contbr_st</th>      <th>contbr_zip</th>      <th>contbr_employer</th>      <th>contbr_occupation</th>      <th>contb_receipt_amt</th>      <th>contb_receipt_dt</th>      <th>receipt_desc</th>      <th>memo_cd</th>      <th>memo_text</th>      <th>form_tp</th>      <th>file_num</th>      <th>party</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>HARVEY, WILLIAM</td>      <td>MOBILE</td>      <td>AL</td>      <td>3.6601e+08</td>      <td>RETIRED</td>      <td>RETIRED</td>      <td>250.0</td>      <td>2011-6-20</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>      <td>Republican</td>    </tr>    <tr>      <th>1</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>HARVEY, WILLIAM</td>      <td>MOBILE</td>      <td>AL</td>      <td>3.6601e+08</td>      <td>RETIRED</td>      <td>RETIRED</td>      <td>50.0</td>      <td>2011-6-23</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>      <td>Republican</td>    </tr>    <tr>      <th>2</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>SMITH, LANIER</td>      <td>LANETT</td>      <td>AL</td>      <td>3.68633e+08</td>      <td>INFORMATION REQUESTED</td>      <td>INFORMATION REQUESTED</td>      <td>250.0</td>      <td>2011-7-05</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>749073</td>      <td>Republican</td>    </tr>    <tr>      <th>3</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>BLEVINS, DARONDA</td>      <td>PIGGOTT</td>      <td>AR</td>      <td>7.24548e+08</td>      <td>NONE</td>      <td>RETIRED</td>      <td>250.0</td>      <td>2011-8-01</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>749073</td>      <td>Republican</td>    </tr>    <tr>      <th>4</th>      <td>C00410118</td>      <td>P20002978</td>      <td>Bachmann, Michelle</td>      <td>WARDENBURG, HAROLD</td>      <td>HOT SPRINGS NATION</td>      <td>AR</td>      <td>7.19016e+08</td>      <td>NONE</td>      <td>RETIRED</td>      <td>300.0</td>      <td>2011-6-20</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>NOT PROVIDE</td>      <td>SA17A</td>      <td>736166</td>      <td>Republican</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看老兵(捐献者职业)DISABLED VETERAN主要支持谁，给谁捐赠的钱越多表示越支持谁</span></span><br><span class="line">df[<span class="string">&#x27;contbr_occupation&#x27;</span>] == <span class="string">&#x27;DISABLED VETERAN&#x27;</span>    <span class="comment"># 找到职业中老兵数据</span></span><br><span class="line">df_old = df.loc[df[<span class="string">&#x27;contbr_occupation&#x27;</span>] == <span class="string">&#x27;DISABLED VETERAN&#x27;</span>]    <span class="comment"># 取出</span></span><br><span class="line">df_old.groupby(<span class="string">&#x27;cand_nm&#x27;</span>)[<span class="string">&#x27;contb_receipt_amt&#x27;</span>].<span class="built_in">sum</span>()    <span class="comment"># 按候选人分组，对金额求和</span></span><br></pre></td></tr></table></figure><pre><code>cand_nmCain, Herman       300.00Obama, Barack     4205.00Paul, Ron         2425.49Santorum, Rick     250.00Name: contb_receipt_amt, dtype: float64</code></pre><hr><p>本文提及的数据集下载地址：<br>链接：<a href="https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg">https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg</a><br>提取码：1111 </p><hr>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;加载数据&lt;/li&gt;
&lt;li&gt;查看数据的基本信息&lt;/li&gt;
&lt;li&gt;指定数据截取，将如下字段的数据进行提取，其他数据舍弃&lt;ul&gt;
&lt;li&gt;cand_nm ：候选人姓名&lt;/li&gt;
&lt;li&gt;contbr_nm ： 捐赠人姓名&lt;/li&gt;
&lt;li&gt;contbr_st ：捐赠人所在州&lt;/li&gt;
&lt;li&gt;contbr_employer ： 捐赠人所在公司&lt;/li&gt;
&lt;li&gt;contbr_occupation ： 捐赠人职业&lt;/li&gt;
&lt;li&gt;contb_receipt_amt ：捐赠数额（美元）&lt;/li&gt;
&lt;li&gt;contb_receipt_dt ： 捐款的日期&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;对新数据进行总览,查看是否存在缺失数据&lt;/li&gt;
&lt;li&gt;用统计学指标快速描述数值型属性的概要&lt;/li&gt;
&lt;li&gt;空值处理，可能因为忘记填写或者保密等等原因，相关字段出现了空值，将其填充为NOT PROVIDE&lt;/li&gt;
&lt;li&gt;异常值处理，将捐款金额&amp;lt;=0的数据删除&lt;/li&gt;
&lt;li&gt;新建一列为各个候选人所在党派party&lt;/li&gt;
&lt;li&gt;查看party这一列中有哪些不同的元素&lt;/li&gt;
&lt;li&gt;统计party列中各个元素出现次数&lt;/li&gt;
&lt;li&gt;查看各个党派收到的政治献金总数contb_receipt_amt&lt;/li&gt;
&lt;li&gt;查看具体每天各个党派收到的政治献金总数contb_receipt_amt&lt;/li&gt;
&lt;li&gt;将表中日期格式转换为’yyyy-mm-dd’&lt;/li&gt;
&lt;li&gt;查看老兵(捐献者职业)DISABLED VETERAN主要支持谁&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Pandas中的一些高级操作</title>
    <link href="http://woody0819.github.io/2021/05/25/test_6/"/>
    <id>http://woody0819.github.io/2021/05/25/test_6/</id>
    <published>2021-05-25T12:27:32.867Z</published>
    <updated>2021-05-26T00:39:59.239Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Pandas中的一些高级操作"><a href="#Pandas中的一些高级操作" class="headerlink" title="Pandas中的一些高级操作"></a>Pandas中的一些高级操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="替换操作"><a href="#替换操作" class="headerlink" title="替换操作"></a>替换操作</h2><ul><li>替换操作可以同步作用于Series和DataFrame中</li><li>单值替换<ul><li>普通替换：替换所有符合要求的元素：to_replace=15,value=’e’</li><li>按列指定单值替换：to_replace={列标签：替换值},value=’value’</li></ul></li><li>多值替换<ul><li>列表替换：to_replace=[],value=[]</li><li>字典替换（推荐）：to_replace={to_replace:value,to_replace:value}</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = DataFrame(data=np.random.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">5</span>,<span class="number">6</span>)))</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><pre><code>    0   1   2   3   4   50  15  45   9   1   2  481  47  74  68  90  84   42  41  30  14  26  22  273   4  64  46  20   8  634  48  80  95  58   0  90</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.replace(to_replace=<span class="number">2</span>,value=<span class="string">&#x27;Two&#x27;</span>)    <span class="comment"># 对指定元素进行替换</span></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>15</td>      <td>45</td>      <td>9</td>      <td>1</td>      <td>Two</td>      <td>48</td>    </tr>    <tr>      <th>1</th>      <td>47</td>      <td>74</td>      <td>68</td>      <td>90</td>      <td>84</td>      <td>4</td>    </tr>    <tr>      <th>2</th>      <td>41</td>      <td>30</td>      <td>14</td>      <td>26</td>      <td>22</td>      <td>27</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>64</td>      <td>46</td>      <td>20</td>      <td>8</td>      <td>63</td>    </tr>    <tr>      <th>4</th>      <td>48</td>      <td>80</td>      <td>95</td>      <td>58</td>      <td>0</td>      <td>90</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.replace(to_replace=&#123;<span class="number">1</span>:<span class="string">&#x27;One&#x27;</span>&#125;)    <span class="comment"># 使用字典形式做替换</span></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>15</td>      <td>45</td>      <td>9</td>      <td>One</td>      <td>2</td>      <td>48</td>    </tr>    <tr>      <th>1</th>      <td>47</td>      <td>74</td>      <td>68</td>      <td>90</td>      <td>84</td>      <td>4</td>    </tr>    <tr>      <th>2</th>      <td>41</td>      <td>30</td>      <td>14</td>      <td>26</td>      <td>22</td>      <td>27</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>64</td>      <td>46</td>      <td>20</td>      <td>8</td>      <td>63</td>    </tr>    <tr>      <th>4</th>      <td>48</td>      <td>80</td>      <td>95</td>      <td>58</td>      <td>0</td>      <td>90</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将指定列的元素进行替换：to_replace=&#123;列索引：被替换的值&#125;,value=&#x27;value&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(df.replace(to_replace=&#123;<span class="number">5</span>:<span class="number">4</span>&#125;,value=<span class="string">&#x27;Four&#x27;</span>))    <span class="comment"># 将第5列的4替换为‘Four’</span></span><br><span class="line">df.replace(to_replace=&#123;<span class="number">0</span>:<span class="number">4</span>&#125;,value=<span class="string">&#x27;Four&#x27;</span>)   <span class="comment"># 将第0列的4替换为‘Four’</span></span><br></pre></td></tr></table></figure><pre><code>    0   1   2   3   4     50  15  45   9   1   2    481  47  74  68  90  84  Four2  41  30  14  26  22    273   4  64  46  20   8    634  48  80  95  58   0    90</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>15</td>      <td>45</td>      <td>9</td>      <td>1</td>      <td>2</td>      <td>48</td>    </tr>    <tr>      <th>1</th>      <td>47</td>      <td>74</td>      <td>68</td>      <td>90</td>      <td>84</td>      <td>4</td>    </tr>    <tr>      <th>2</th>      <td>41</td>      <td>30</td>      <td>14</td>      <td>26</td>      <td>22</td>      <td>27</td>    </tr>    <tr>      <th>3</th>      <td>Four</td>      <td>64</td>      <td>46</td>      <td>20</td>      <td>8</td>      <td>63</td>    </tr>    <tr>      <th>4</th>      <td>48</td>      <td>80</td>      <td>95</td>      <td>58</td>      <td>0</td>      <td>90</td>    </tr>  </tbody></table></div><h2 id="映射操作"><a href="#映射操作" class="headerlink" title="映射操作"></a>映射操作</h2><ul><li>概念：创建一个映射关系列表，把values元素和一个特定的标签或者字符串绑定（给一个元素值提供不同的表现形式）</li><li>创建一个df，两列分别是姓名和薪资，然后给其名字起对应的英文名</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dic = &#123;</span><br><span class="line">    <span class="string">&#x27;name&#x27;</span>:[<span class="string">&#x27;张三&#x27;</span>,<span class="string">&#x27;李四&#x27;</span>,<span class="string">&#x27;张三&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;salary&#x27;</span>:[<span class="number">15000</span>,<span class="number">20000</span>,<span class="number">15000</span>]</span><br><span class="line">&#125;</span><br><span class="line">df = DataFrame(data=dic)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name</th>      <th>salary</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>张三</td>      <td>15000</td>    </tr>    <tr>      <th>1</th>      <td>李四</td>      <td>20000</td>    </tr>    <tr>      <th>2</th>      <td>张三</td>      <td>15000</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 映射关系表</span></span><br><span class="line">dic = &#123;</span><br><span class="line">    <span class="string">&#x27;张三&#x27;</span>:<span class="string">&#x27;Tom&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;李四&#x27;</span>:<span class="string">&#x27;Jack&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(df[<span class="string">&#x27;name&#x27;</span>].<span class="built_in">map</span>(dic))  <span class="comment"># map()属于Series的映射函数只能通过Series去调</span></span><br><span class="line">df[<span class="string">&#x27;e_name&#x27;</span>] = df[<span class="string">&#x27;name&#x27;</span>].<span class="built_in">map</span>(dic)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><pre><code>0     Tom1    Jack2     TomName: name, dtype: object</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name</th>      <th>salary</th>      <th>e_name</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>张三</td>      <td>15000</td>      <td>Tom</td>    </tr>    <tr>      <th>1</th>      <td>李四</td>      <td>20000</td>      <td>Jack</td>    </tr>    <tr>      <th>2</th>      <td>张三</td>      <td>15000</td>      <td>Tom</td>    </tr>  </tbody></table></div><h2 id="运算工具"><a href="#运算工具" class="headerlink" title="运算工具"></a>运算工具</h2><ul><li>超过3000部分的钱缴纳50%的税，计算每个人的税后薪资</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">after_sal</span>(<span class="params">s</span>):</span>   <span class="comment">#计算s对应的税后薪资</span></span><br><span class="line">    <span class="keyword">return</span> s - (s-<span class="number">3000</span>)*<span class="number">0.5</span></span><br><span class="line">df[<span class="string">&#x27;after_sal&#x27;</span>] = df[<span class="string">&#x27;salary&#x27;</span>].<span class="built_in">map</span>(after_sal) <span class="comment"># 可以将df[&#x27;salary&#x27;]这个Series中每一个元素（薪资）作为参数传递给s</span></span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name</th>      <th>salary</th>      <th>e_name</th>      <th>after_sal</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>张三</td>      <td>15000</td>      <td>Tom</td>      <td>9000.0</td>    </tr>    <tr>      <th>1</th>      <td>李四</td>      <td>20000</td>      <td>Jack</td>      <td>11500.0</td>    </tr>    <tr>      <th>2</th>      <td>张三</td>      <td>15000</td>      <td>Tom</td>      <td>9000.0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 排序实现的随机抽样</span></span><br><span class="line">- take()</span><br><span class="line">- np.random.permutation()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = DataFrame(data=np.random.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">100</span>,<span class="number">3</span>)),columns=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>A</th>      <th>B</th>      <th>C</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>55</td>      <td>52</td>      <td>52</td>    </tr>    <tr>      <th>1</th>      <td>95</td>      <td>33</td>      <td>80</td>    </tr>    <tr>      <th>2</th>      <td>31</td>      <td>72</td>      <td>31</td>    </tr>    <tr>      <th>3</th>      <td>49</td>      <td>79</td>      <td>65</td>    </tr>    <tr>      <th>4</th>      <td>53</td>      <td>88</td>      <td>23</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>95</th>      <td>38</td>      <td>30</td>      <td>99</td>    </tr>    <tr>      <th>96</th>      <td>83</td>      <td>47</td>      <td>98</td>    </tr>    <tr>      <th>97</th>      <td>61</td>      <td>37</td>      <td>37</td>    </tr>    <tr>      <th>98</th>      <td>51</td>      <td>97</td>      <td>48</td>    </tr>    <tr>      <th>99</th>      <td>61</td>      <td>92</td>      <td>7</td>    </tr>  </tbody></table><p>100 rows × 3 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成乱序的随机序列</span></span><br><span class="line">np.random.permutation(<span class="number">10</span>)   <span class="comment"># 生成0-9的乱序随机序列</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将原始数据打乱</span></span><br><span class="line"><span class="built_in">print</span>(df.take([<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>],axis=<span class="number">1</span>))   <span class="comment"># take与drop类似，0表示行，1表示列。并且take不能使用显示索引，只能使用“0，1，2...”隐式索引</span></span><br><span class="line">df.take(np.random.permutation(<span class="number">3</span>),axis=<span class="number">1</span>)    <span class="comment"># 将np.random.permutation()函数引入，按列打乱</span></span><br></pre></td></tr></table></figure><pre><code>     C   A   B0   52  55  521   80  95  332   31  31  723   65  49  794   23  53  88..  ..  ..  ..95  99  38  3096  98  83  4797  37  61  3798  48  51  9799   7  61  92[100 rows x 3 columns]</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>C</th>      <th>B</th>      <th>A</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>52</td>      <td>52</td>      <td>55</td>    </tr>    <tr>      <th>1</th>      <td>80</td>      <td>33</td>      <td>95</td>    </tr>    <tr>      <th>2</th>      <td>31</td>      <td>72</td>      <td>31</td>    </tr>    <tr>      <th>3</th>      <td>65</td>      <td>79</td>      <td>49</td>    </tr>    <tr>      <th>4</th>      <td>23</td>      <td>88</td>      <td>53</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>95</th>      <td>99</td>      <td>30</td>      <td>38</td>    </tr>    <tr>      <th>96</th>      <td>98</td>      <td>47</td>      <td>83</td>    </tr>    <tr>      <th>97</th>      <td>37</td>      <td>37</td>      <td>61</td>    </tr>    <tr>      <th>98</th>      <td>48</td>      <td>97</td>      <td>51</td>    </tr>    <tr>      <th>99</th>      <td>7</td>      <td>92</td>      <td>61</td>    </tr>  </tbody></table><p>100 rows × 3 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.take(np.random.permutation(<span class="number">3</span>),axis=<span class="number">1</span>).take(np.random.permutation(<span class="number">100</span>),axis=<span class="number">0</span>)    <span class="comment"># 行列全部打乱</span></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>C</th>      <th>A</th>      <th>B</th>    </tr>  </thead>  <tbody>    <tr>      <th>25</th>      <td>54</td>      <td>23</td>      <td>65</td>    </tr>    <tr>      <th>78</th>      <td>56</td>      <td>89</td>      <td>46</td>    </tr>    <tr>      <th>13</th>      <td>19</td>      <td>83</td>      <td>61</td>    </tr>    <tr>      <th>21</th>      <td>46</td>      <td>25</td>      <td>65</td>    </tr>    <tr>      <th>68</th>      <td>5</td>      <td>41</td>      <td>2</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>62</th>      <td>4</td>      <td>84</td>      <td>77</td>    </tr>    <tr>      <th>98</th>      <td>48</td>      <td>51</td>      <td>97</td>    </tr>    <tr>      <th>28</th>      <td>92</td>      <td>78</td>      <td>51</td>    </tr>    <tr>      <th>43</th>      <td>60</td>      <td>67</td>      <td>41</td>    </tr>    <tr>      <th>19</th>      <td>90</td>      <td>45</td>      <td>90</td>    </tr>  </tbody></table><p>100 rows × 3 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.take(np.random.permutation(<span class="number">3</span>),axis=<span class="number">1</span>).take(np.random.permutation(<span class="number">100</span>),axis=<span class="number">0</span>)[<span class="number">0</span>:<span class="number">50</span>]  <span class="comment"># 取前50行</span></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>B</th>      <th>C</th>      <th>A</th>    </tr>  </thead>  <tbody>    <tr>      <th>5</th>      <td>97</td>      <td>33</td>      <td>69</td>    </tr>    <tr>      <th>7</th>      <td>38</td>      <td>89</td>      <td>26</td>    </tr>    <tr>      <th>54</th>      <td>86</td>      <td>75</td>      <td>18</td>    </tr>    <tr>      <th>2</th>      <td>72</td>      <td>31</td>      <td>31</td>    </tr>    <tr>      <th>34</th>      <td>95</td>      <td>95</td>      <td>12</td>    </tr>    <tr>      <th>72</th>      <td>85</td>      <td>25</td>      <td>0</td>    </tr>    <tr>      <th>80</th>      <td>1</td>      <td>82</td>      <td>11</td>    </tr>    <tr>      <th>28</th>      <td>51</td>      <td>92</td>      <td>78</td>    </tr>    <tr>      <th>61</th>      <td>58</td>      <td>88</td>      <td>54</td>    </tr>    <tr>      <th>16</th>      <td>8</td>      <td>83</td>      <td>6</td>    </tr>    <tr>      <th>96</th>      <td>47</td>      <td>98</td>      <td>83</td>    </tr>    <tr>      <th>62</th>      <td>77</td>      <td>4</td>      <td>84</td>    </tr>    <tr>      <th>19</th>      <td>90</td>      <td>90</td>      <td>45</td>    </tr>    <tr>      <th>3</th>      <td>79</td>      <td>65</td>      <td>49</td>    </tr>    <tr>      <th>26</th>      <td>56</td>      <td>77</td>      <td>80</td>    </tr>    <tr>      <th>70</th>      <td>99</td>      <td>9</td>      <td>47</td>    </tr>    <tr>      <th>99</th>      <td>92</td>      <td>7</td>      <td>61</td>    </tr>    <tr>      <th>53</th>      <td>79</td>      <td>75</td>      <td>50</td>    </tr>    <tr>      <th>12</th>      <td>9</td>      <td>15</td>      <td>82</td>    </tr>    <tr>      <th>4</th>      <td>88</td>      <td>23</td>      <td>53</td>    </tr>    <tr>      <th>65</th>      <td>63</td>      <td>43</td>      <td>3</td>    </tr>    <tr>      <th>40</th>      <td>40</td>      <td>31</td>      <td>91</td>    </tr>    <tr>      <th>52</th>      <td>65</td>      <td>64</td>      <td>28</td>    </tr>    <tr>      <th>98</th>      <td>97</td>      <td>48</td>      <td>51</td>    </tr>    <tr>      <th>94</th>      <td>50</td>      <td>62</td>      <td>2</td>    </tr>    <tr>      <th>89</th>      <td>33</td>      <td>23</td>      <td>86</td>    </tr>    <tr>      <th>32</th>      <td>17</td>      <td>79</td>      <td>78</td>    </tr>    <tr>      <th>57</th>      <td>39</td>      <td>64</td>      <td>62</td>    </tr>    <tr>      <th>59</th>      <td>78</td>      <td>39</td>      <td>10</td>    </tr>    <tr>      <th>30</th>      <td>21</td>      <td>17</td>      <td>14</td>    </tr>    <tr>      <th>93</th>      <td>13</td>      <td>57</td>      <td>43</td>    </tr>    <tr>      <th>71</th>      <td>48</td>      <td>33</td>      <td>87</td>    </tr>    <tr>      <th>74</th>      <td>20</td>      <td>66</td>      <td>49</td>    </tr>    <tr>      <th>47</th>      <td>16</td>      <td>90</td>      <td>64</td>    </tr>    <tr>      <th>43</th>      <td>41</td>      <td>60</td>      <td>67</td>    </tr>    <tr>      <th>81</th>      <td>28</td>      <td>36</td>      <td>59</td>    </tr>    <tr>      <th>91</th>      <td>74</td>      <td>81</td>      <td>76</td>    </tr>    <tr>      <th>87</th>      <td>51</td>      <td>54</td>      <td>68</td>    </tr>    <tr>      <th>41</th>      <td>6</td>      <td>20</td>      <td>19</td>    </tr>    <tr>      <th>63</th>      <td>97</td>      <td>56</td>      <td>13</td>    </tr>    <tr>      <th>29</th>      <td>12</td>      <td>87</td>      <td>69</td>    </tr>    <tr>      <th>42</th>      <td>18</td>      <td>90</td>      <td>3</td>    </tr>    <tr>      <th>75</th>      <td>23</td>      <td>53</td>      <td>37</td>    </tr>    <tr>      <th>69</th>      <td>56</td>      <td>82</td>      <td>61</td>    </tr>    <tr>      <th>58</th>      <td>23</td>      <td>61</td>      <td>73</td>    </tr>    <tr>      <th>85</th>      <td>48</td>      <td>99</td>      <td>33</td>    </tr>    <tr>      <th>55</th>      <td>64</td>      <td>14</td>      <td>24</td>    </tr>    <tr>      <th>39</th>      <td>64</td>      <td>75</td>      <td>53</td>    </tr>    <tr>      <th>48</th>      <td>3</td>      <td>86</td>      <td>83</td>    </tr>    <tr>      <th>92</th>      <td>96</td>      <td>45</td>      <td>0</td>    </tr>  </tbody></table></div><h2 id="数据的分类处理"><a href="#数据的分类处理" class="headerlink" title="数据的分类处理"></a>数据的分类处理</h2><ul><li>数据分类处理的核心：<ul><li>groupby()函数</li><li>groups属性查看分组情况</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = DataFrame(&#123;<span class="string">&#x27;item&#x27;</span>:[<span class="string">&#x27;Apple&#x27;</span>,<span class="string">&#x27;Banana&#x27;</span>,<span class="string">&#x27;Orange&#x27;</span>,<span class="string">&#x27;Banana&#x27;</span>,<span class="string">&#x27;Orange&#x27;</span>,<span class="string">&#x27;Apple&#x27;</span>],</span><br><span class="line">                <span class="string">&#x27;price&#x27;</span>:[<span class="number">4</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">2.5</span>,<span class="number">4</span>,<span class="number">2</span>],</span><br><span class="line">                <span class="string">&#x27;color&#x27;</span>:[<span class="string">&#x27;red&#x27;</span>,<span class="string">&#x27;yellow&#x27;</span>,<span class="string">&#x27;yellow&#x27;</span>,<span class="string">&#x27;green&#x27;</span>,<span class="string">&#x27;green&#x27;</span>,<span class="string">&#x27;green&#x27;</span>],</span><br><span class="line">                <span class="string">&#x27;weight&#x27;</span>:[<span class="number">12</span>,<span class="number">20</span>,<span class="number">50</span>,<span class="number">30</span>,<span class="number">20</span>,<span class="number">44</span>]</span><br><span class="line">&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>item</th>      <th>price</th>      <th>color</th>      <th>weight</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Apple</td>      <td>4.0</td>      <td>red</td>      <td>12</td>    </tr>    <tr>      <th>1</th>      <td>Banana</td>      <td>3.0</td>      <td>yellow</td>      <td>20</td>    </tr>    <tr>      <th>2</th>      <td>Orange</td>      <td>3.0</td>      <td>yellow</td>      <td>50</td>    </tr>    <tr>      <th>3</th>      <td>Banana</td>      <td>2.5</td>      <td>green</td>      <td>30</td>    </tr>    <tr>      <th>4</th>      <td>Orange</td>      <td>4.0</td>      <td>green</td>      <td>20</td>    </tr>    <tr>      <th>5</th>      <td>Apple</td>      <td>2.0</td>      <td>green</td>      <td>44</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 水果的种类进行分析</span></span><br><span class="line">df.groupby(by=<span class="string">&#x27;item&#x27;</span>)   <span class="comment"># 三个分组情况在该对象当中</span></span><br></pre></td></tr></table></figure><pre><code>&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001DBA1507E48&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看详细的分组情况</span></span><br><span class="line">df.groupby(by=<span class="string">&#x27;item&#x27;</span>).groups</span><br></pre></td></tr></table></figure><pre><code>&#123;&#39;Apple&#39;: [0, 5], &#39;Banana&#39;: [1, 3], &#39;Orange&#39;: [2, 4]&#125;</code></pre><ul><li>分组聚合</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算出每一种水果的平均价格</span></span><br><span class="line"><span class="built_in">print</span>(df.groupby(<span class="string">&#x27;item&#x27;</span>).mean())    <span class="comment"># 对所有数值型数据取了平均</span></span><br><span class="line">df.groupby(<span class="string">&#x27;item&#x27;</span>)[<span class="string">&#x27;price&#x27;</span>].mean()  <span class="comment"># 只选择价钱做平均</span></span><br></pre></td></tr></table></figure><pre><code>        price  weightitem                 Apple    3.00      28Banana   2.75      25Orange   3.50      35itemApple     3.00Banana    2.75Orange    3.50Name: price, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算每种颜色对应水果的平均重量</span></span><br><span class="line">df.groupby(<span class="string">&#x27;color&#x27;</span>)[<span class="string">&#x27;weight&#x27;</span>].mean()</span><br></pre></td></tr></table></figure><pre><code>colorgreen     31.333333red       12.000000yellow    35.000000Name: weight, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dic = df.groupby(<span class="string">&#x27;color&#x27;</span>)[<span class="string">&#x27;weight&#x27;</span>].mean().to_dict()</span><br><span class="line"><span class="comment"># 将计算出的平均重量汇总到源数据</span></span><br><span class="line"><span class="built_in">print</span>(df[<span class="string">&#x27;color&#x27;</span>].<span class="built_in">map</span>(dic))    <span class="comment"># 此处使用映射将所有颜色对应的数值填充满</span></span><br><span class="line">df[<span class="string">&#x27;mean_w&#x27;</span>] = df[<span class="string">&#x27;color&#x27;</span>].<span class="built_in">map</span>(dic)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><pre><code>0    12.0000001    35.0000002    35.0000003    31.3333334    31.3333335    31.333333Name: color, dtype: float64</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>item</th>      <th>price</th>      <th>color</th>      <th>weight</th>      <th>mean_w</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Apple</td>      <td>4.0</td>      <td>red</td>      <td>12</td>      <td>12.000000</td>    </tr>    <tr>      <th>1</th>      <td>Banana</td>      <td>3.0</td>      <td>yellow</td>      <td>20</td>      <td>35.000000</td>    </tr>    <tr>      <th>2</th>      <td>Orange</td>      <td>3.0</td>      <td>yellow</td>      <td>50</td>      <td>35.000000</td>    </tr>    <tr>      <th>3</th>      <td>Banana</td>      <td>2.5</td>      <td>green</td>      <td>30</td>      <td>31.333333</td>    </tr>    <tr>      <th>4</th>      <td>Orange</td>      <td>4.0</td>      <td>green</td>      <td>20</td>      <td>31.333333</td>    </tr>    <tr>      <th>5</th>      <td>Apple</td>      <td>2.0</td>      <td>green</td>      <td>44</td>      <td>31.333333</td>    </tr>  </tbody></table></div><h2 id="高级数据聚合"><a href="#高级数据聚合" class="headerlink" title="高级数据聚合"></a>高级数据聚合</h2><ul><li>使用groupby()分组后，也可以使用transform和apply提供自定义函数实现更多的运算</li><li>df.groupby(‘item’)[‘price’].sum() &lt;==&gt; df.groupby(‘item’)[‘price’].apply(sum)</li><li>transform和apply都会进行运算，在transform或者apply中传入函数即可</li><li>transform和apply也可以传入一个lambda表达式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_mean</span>(<span class="params">s</span>):</span></span><br><span class="line">    m_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">        m_sum += i</span><br><span class="line">    <span class="keyword">return</span> m_sum / <span class="built_in">len</span>(s)</span><br><span class="line">df.groupby(<span class="string">&#x27;item&#x27;</span>)[<span class="string">&#x27;price&#x27;</span>].transform(my_mean)  <span class="comment"># transform返回的经过映射的结果</span></span><br></pre></td></tr></table></figure><pre><code>0    3.001    2.752    3.503    2.754    3.505    3.00Name: price, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.groupby(<span class="string">&#x27;item&#x27;</span>)[<span class="string">&#x27;price&#x27;</span>].apply(my_mean)  <span class="comment"># apply返回的没有经过映射</span></span><br></pre></td></tr></table></figure><pre><code>itemApple     3.00Banana    2.75Orange    3.50Name: price, dtype: float64</code></pre><h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><ul><li>读取type-.txt文件数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;./data/type-.txt&#x27;</span>)</span><br><span class="line">df  <span class="comment"># 可以看到此处将文件内容当成了索引</span></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>你好-我好-他也好</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>也许-大概-有可能</td>    </tr>    <tr>      <th>1</th>      <td>然而-未必-不见得</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;./data/type-.txt&#x27;</span>,header=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(df)  <span class="comment"># 通过header=None读取文件没有索引</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./data/type-.txt&#x27;</span>,header=<span class="literal">None</span>,sep=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">df  <span class="comment"># sep为指定分隔符，借此将数据拆分</span></span><br></pre></td></tr></table></figure><pre><code>           00  你好-我好-他也好1  也许-大概-有可能2  然而-未必-不见得</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>      <th>2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>你好</td>      <td>我好</td>      <td>他也好</td>    </tr>    <tr>      <th>1</th>      <td>也许</td>      <td>大概</td>      <td>有可能</td>    </tr>    <tr>      <th>2</th>      <td>然而</td>      <td>未必</td>      <td>不见得</td>    </tr>  </tbody></table></div><ul><li>读取数据库中的数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连接数据库，获取连接对象</span></span><br><span class="line"><span class="keyword">import</span> sqlite3 <span class="keyword">as</span> sqlite3</span><br><span class="line">conn = sqlite3.connect(<span class="string">&#x27;./data/weather_2012.sqlite&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取库表中的数据值</span></span><br><span class="line">sql_df = pd.read_sql(<span class="string">&#x27;select * from weather_2012&#x27;</span>, conn)</span><br><span class="line">sql_df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>index</th>      <th>Date/Time</th>      <th>Temp (C)</th>      <th>Dew Point Temp (C)</th>      <th>Rel Hum (%)</th>      <th>Wind Spd (km/h)</th>      <th>Visibility (km)</th>      <th>Stn Press (kPa)</th>      <th>Weather</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0.0</td>      <td>2012-01-01 00:00:00</td>      <td>-1.8</td>      <td>-3.9</td>      <td>86.0</td>      <td>4.0</td>      <td>8.0</td>      <td>101.24</td>      <td>Fog</td>    </tr>    <tr>      <th>1</th>      <td>1.0</td>      <td>2012-01-01 01:00:00</td>      <td>-1.8</td>      <td>-3.7</td>      <td>87.0</td>      <td>4.0</td>      <td>8.0</td>      <td>101.24</td>      <td>Fog</td>    </tr>    <tr>      <th>2</th>      <td>2.0</td>      <td>2012-01-01 02:00:00</td>      <td>-1.8</td>      <td>-3.4</td>      <td>89.0</td>      <td>7.0</td>      <td>4.0</td>      <td>101.26</td>      <td>Freezing Drizzle,Fog</td>    </tr>    <tr>      <th>3</th>      <td>3.0</td>      <td>2012-01-01 03:00:00</td>      <td>-1.5</td>      <td>-3.2</td>      <td>88.0</td>      <td>6.0</td>      <td>4.0</td>      <td>101.27</td>      <td>Freezing Drizzle,Fog</td>    </tr>    <tr>      <th>4</th>      <td>4.0</td>      <td>2012-01-01 04:00:00</td>      <td>-1.5</td>      <td>-3.3</td>      <td>88.0</td>      <td>7.0</td>      <td>4.8</td>      <td>101.23</td>      <td>Fog</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>8781</th>      <td>8781.0</td>      <td>2012-12-31 21:00:00</td>      <td>-0.5</td>      <td>-1.5</td>      <td>93.0</td>      <td>28.0</td>      <td>4.8</td>      <td>99.95</td>      <td>Snow</td>    </tr>    <tr>      <th>8782</th>      <td>8782.0</td>      <td>2012-12-31 22:00:00</td>      <td>-0.2</td>      <td>-1.8</td>      <td>89.0</td>      <td>28.0</td>      <td>9.7</td>      <td>99.91</td>      <td>Snow</td>    </tr>    <tr>      <th>8783</th>      <td>8783.0</td>      <td>2012-12-31 23:00:00</td>      <td>0.0</td>      <td>-2.1</td>      <td>86.0</td>      <td>30.0</td>      <td>11.3</td>      <td>99.89</td>      <td>Snow</td>    </tr>    <tr>      <th>8784</th>      <td>NaN</td>      <td>None</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>Fog</td>    </tr>    <tr>      <th>8785</th>      <td>NaN</td>      <td>None</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>Fog</td>    </tr>  </tbody></table><p>8786 rows × 9 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将一个df中的数据值写入存储到db</span></span><br><span class="line">df.to_sql(<span class="string">&#x27;sql_data666&#x27;</span>, conn)</span><br><span class="line">sql_df = pd.read_sql(<span class="string">&#x27;select * from sql_data666&#x27;</span>, conn)</span><br><span class="line">sql_df  <span class="comment"># 写入数据库后进行读取，读取成功</span></span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>index</th>      <th>0</th>      <th>1</th>      <th>2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>你好</td>      <td>我好</td>      <td>他也好</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>也许</td>      <td>大概</td>      <td>有可能</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>然而</td>      <td>未必</td>      <td>不见得</td>    </tr>  </tbody></table></div><h2 id="透视表"><a href="#透视表" class="headerlink" title="透视表"></a>透视表</h2><ul><li>透视表是一种可以对数据动态排布并且分类汇总的表格格式。或许大多数人都在Excel使用过数据透视表，也体会到它的强大功能，而在pandas中它被称作pivot_table。</li><li>透视表的优点：<ul><li>灵活性高，可以随意定制你的分析计算要求</li><li>脉络清晰易于理解数据</li><li>操作性强，报表神器</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;./data/透视表-篮球赛.csv&#x27;</span>,encoding=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>对手</th>      <th>胜负</th>      <th>主客场</th>      <th>命中</th>      <th>投篮数</th>      <th>投篮命中率</th>      <th>3分命中率</th>      <th>篮板</th>      <th>助攻</th>      <th>得分</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>勇士</td>      <td>胜</td>      <td>客</td>      <td>10</td>      <td>23</td>      <td>0.435</td>      <td>0.444</td>      <td>6</td>      <td>11</td>      <td>27</td>    </tr>    <tr>      <th>1</th>      <td>国王</td>      <td>胜</td>      <td>客</td>      <td>8</td>      <td>21</td>      <td>0.381</td>      <td>0.286</td>      <td>3</td>      <td>9</td>      <td>27</td>    </tr>    <tr>      <th>2</th>      <td>小牛</td>      <td>胜</td>      <td>主</td>      <td>10</td>      <td>19</td>      <td>0.526</td>      <td>0.462</td>      <td>3</td>      <td>7</td>      <td>29</td>    </tr>    <tr>      <th>3</th>      <td>灰熊</td>      <td>负</td>      <td>主</td>      <td>8</td>      <td>20</td>      <td>0.400</td>      <td>0.250</td>      <td>5</td>      <td>8</td>      <td>22</td>    </tr>    <tr>      <th>4</th>      <td>76人</td>      <td>胜</td>      <td>客</td>      <td>10</td>      <td>20</td>      <td>0.500</td>      <td>0.250</td>      <td>3</td>      <td>13</td>      <td>27</td>    </tr>    <tr>      <th>5</th>      <td>黄蜂</td>      <td>胜</td>      <td>客</td>      <td>8</td>      <td>18</td>      <td>0.444</td>      <td>0.400</td>      <td>10</td>      <td>11</td>      <td>27</td>    </tr>    <tr>      <th>6</th>      <td>灰熊</td>      <td>负</td>      <td>客</td>      <td>6</td>      <td>19</td>      <td>0.316</td>      <td>0.222</td>      <td>4</td>      <td>8</td>      <td>20</td>    </tr>    <tr>      <th>7</th>      <td>76人</td>      <td>负</td>      <td>主</td>      <td>8</td>      <td>21</td>      <td>0.381</td>      <td>0.429</td>      <td>4</td>      <td>7</td>      <td>29</td>    </tr>    <tr>      <th>8</th>      <td>尼克斯</td>      <td>胜</td>      <td>客</td>      <td>9</td>      <td>23</td>      <td>0.391</td>      <td>0.353</td>      <td>5</td>      <td>9</td>      <td>31</td>    </tr>    <tr>      <th>9</th>      <td>老鹰</td>      <td>胜</td>      <td>客</td>      <td>8</td>      <td>15</td>      <td>0.533</td>      <td>0.545</td>      <td>3</td>      <td>11</td>      <td>29</td>    </tr>    <tr>      <th>10</th>      <td>爵士</td>      <td>胜</td>      <td>主</td>      <td>19</td>      <td>25</td>      <td>0.760</td>      <td>0.875</td>      <td>2</td>      <td>13</td>      <td>56</td>    </tr>    <tr>      <th>11</th>      <td>骑士</td>      <td>胜</td>      <td>主</td>      <td>8</td>      <td>21</td>      <td>0.381</td>      <td>0.429</td>      <td>11</td>      <td>13</td>      <td>35</td>    </tr>    <tr>      <th>12</th>      <td>灰熊</td>      <td>胜</td>      <td>主</td>      <td>11</td>      <td>25</td>      <td>0.440</td>      <td>0.429</td>      <td>4</td>      <td>8</td>      <td>38</td>    </tr>    <tr>      <th>13</th>      <td>步行者</td>      <td>胜</td>      <td>客</td>      <td>9</td>      <td>21</td>      <td>0.429</td>      <td>0.250</td>      <td>5</td>      <td>15</td>      <td>26</td>    </tr>    <tr>      <th>14</th>      <td>猛龙</td>      <td>负</td>      <td>主</td>      <td>8</td>      <td>25</td>      <td>0.320</td>      <td>0.273</td>      <td>6</td>      <td>11</td>      <td>38</td>    </tr>    <tr>      <th>15</th>      <td>太阳</td>      <td>胜</td>      <td>客</td>      <td>12</td>      <td>22</td>      <td>0.545</td>      <td>0.545</td>      <td>2</td>      <td>7</td>      <td>48</td>    </tr>    <tr>      <th>16</th>      <td>灰熊</td>      <td>胜</td>      <td>客</td>      <td>9</td>      <td>20</td>      <td>0.450</td>      <td>0.500</td>      <td>5</td>      <td>7</td>      <td>29</td>    </tr>    <tr>      <th>17</th>      <td>掘金</td>      <td>胜</td>      <td>主</td>      <td>6</td>      <td>16</td>      <td>0.375</td>      <td>0.143</td>      <td>8</td>      <td>9</td>      <td>21</td>    </tr>    <tr>      <th>18</th>      <td>尼克斯</td>      <td>胜</td>      <td>主</td>      <td>12</td>      <td>27</td>      <td>0.444</td>      <td>0.385</td>      <td>2</td>      <td>10</td>      <td>37</td>    </tr>    <tr>      <th>19</th>      <td>篮网</td>      <td>胜</td>      <td>主</td>      <td>13</td>      <td>20</td>      <td>0.650</td>      <td>0.615</td>      <td>10</td>      <td>8</td>      <td>37</td>    </tr>    <tr>      <th>20</th>      <td>步行者</td>      <td>胜</td>      <td>主</td>      <td>8</td>      <td>22</td>      <td>0.364</td>      <td>0.333</td>      <td>8</td>      <td>10</td>      <td>29</td>    </tr>    <tr>      <th>21</th>      <td>湖人</td>      <td>胜</td>      <td>客</td>      <td>13</td>      <td>22</td>      <td>0.591</td>      <td>0.444</td>      <td>4</td>      <td>9</td>      <td>36</td>    </tr>    <tr>      <th>22</th>      <td>爵士</td>      <td>胜</td>      <td>客</td>      <td>8</td>      <td>19</td>      <td>0.421</td>      <td>0.333</td>      <td>5</td>      <td>3</td>      <td>29</td>    </tr>    <tr>      <th>23</th>      <td>开拓者</td>      <td>胜</td>      <td>客</td>      <td>16</td>      <td>29</td>      <td>0.552</td>      <td>0.571</td>      <td>8</td>      <td>3</td>      <td>48</td>    </tr>    <tr>      <th>24</th>      <td>鹈鹕</td>      <td>胜</td>      <td>主</td>      <td>8</td>      <td>16</td>      <td>0.500</td>      <td>0.400</td>      <td>1</td>      <td>17</td>      <td>26</td>    </tr>  </tbody></table></div><h3 id="pivot-table有四个最重要的参数index、values、columns、aggfunc"><a href="#pivot-table有四个最重要的参数index、values、columns、aggfunc" class="headerlink" title="pivot_table有四个最重要的参数index、values、columns、aggfunc"></a>pivot_table有四个最重要的参数index、values、columns、aggfunc</h3><ul><li>index参数：分类汇总的分类条件<ul><li>每个pivot_table必须拥有一个index。如果想查看哈登对阵每个队伍的得分则需要对每一个队进行分类并计算其各类得分的平均值</li></ul></li><li>想看哈登对阵同一对手在不同主客场下的数据，分类条件为对手和主客场</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.pivot_table(index=[<span class="string">&#x27;对手&#x27;</span>,<span class="string">&#x27;主客场&#x27;</span>])</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th></th>      <th>3分命中率</th>      <th>助攻</th>      <th>命中</th>      <th>得分</th>      <th>投篮命中率</th>      <th>投篮数</th>      <th>篮板</th>    </tr>    <tr>      <th>对手</th>      <th>主客场</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th rowspan="2" valign="top">76人</th>      <th>主</th>      <td>0.4290</td>      <td>7.0</td>      <td>8.0</td>      <td>29.0</td>      <td>0.381</td>      <td>21.0</td>      <td>4.0</td>    </tr>    <tr>      <th>客</th>      <td>0.2500</td>      <td>13.0</td>      <td>10.0</td>      <td>27.0</td>      <td>0.500</td>      <td>20.0</td>      <td>3.0</td>    </tr>    <tr>      <th>勇士</th>      <th>客</th>      <td>0.4440</td>      <td>11.0</td>      <td>10.0</td>      <td>27.0</td>      <td>0.435</td>      <td>23.0</td>      <td>6.0</td>    </tr>    <tr>      <th>国王</th>      <th>客</th>      <td>0.2860</td>      <td>9.0</td>      <td>8.0</td>      <td>27.0</td>      <td>0.381</td>      <td>21.0</td>      <td>3.0</td>    </tr>    <tr>      <th>太阳</th>      <th>客</th>      <td>0.5450</td>      <td>7.0</td>      <td>12.0</td>      <td>48.0</td>      <td>0.545</td>      <td>22.0</td>      <td>2.0</td>    </tr>    <tr>      <th>小牛</th>      <th>主</th>      <td>0.4620</td>      <td>7.0</td>      <td>10.0</td>      <td>29.0</td>      <td>0.526</td>      <td>19.0</td>      <td>3.0</td>    </tr>    <tr>      <th rowspan="2" valign="top">尼克斯</th>      <th>主</th>      <td>0.3850</td>      <td>10.0</td>      <td>12.0</td>      <td>37.0</td>      <td>0.444</td>      <td>27.0</td>      <td>2.0</td>    </tr>    <tr>      <th>客</th>      <td>0.3530</td>      <td>9.0</td>      <td>9.0</td>      <td>31.0</td>      <td>0.391</td>      <td>23.0</td>      <td>5.0</td>    </tr>    <tr>      <th>开拓者</th>      <th>客</th>      <td>0.5710</td>      <td>3.0</td>      <td>16.0</td>      <td>48.0</td>      <td>0.552</td>      <td>29.0</td>      <td>8.0</td>    </tr>    <tr>      <th>掘金</th>      <th>主</th>      <td>0.1430</td>      <td>9.0</td>      <td>6.0</td>      <td>21.0</td>      <td>0.375</td>      <td>16.0</td>      <td>8.0</td>    </tr>    <tr>      <th rowspan="2" valign="top">步行者</th>      <th>主</th>      <td>0.3330</td>      <td>10.0</td>      <td>8.0</td>      <td>29.0</td>      <td>0.364</td>      <td>22.0</td>      <td>8.0</td>    </tr>    <tr>      <th>客</th>      <td>0.2500</td>      <td>15.0</td>      <td>9.0</td>      <td>26.0</td>      <td>0.429</td>      <td>21.0</td>      <td>5.0</td>    </tr>    <tr>      <th>湖人</th>      <th>客</th>      <td>0.4440</td>      <td>9.0</td>      <td>13.0</td>      <td>36.0</td>      <td>0.591</td>      <td>22.0</td>      <td>4.0</td>    </tr>    <tr>      <th rowspan="2" valign="top">灰熊</th>      <th>主</th>      <td>0.3395</td>      <td>8.0</td>      <td>9.5</td>      <td>30.0</td>      <td>0.420</td>      <td>22.5</td>      <td>4.5</td>    </tr>    <tr>      <th>客</th>      <td>0.3610</td>      <td>7.5</td>      <td>7.5</td>      <td>24.5</td>      <td>0.383</td>      <td>19.5</td>      <td>4.5</td>    </tr>    <tr>      <th rowspan="2" valign="top">爵士</th>      <th>主</th>      <td>0.8750</td>      <td>13.0</td>      <td>19.0</td>      <td>56.0</td>      <td>0.760</td>      <td>25.0</td>      <td>2.0</td>    </tr>    <tr>      <th>客</th>      <td>0.3330</td>      <td>3.0</td>      <td>8.0</td>      <td>29.0</td>      <td>0.421</td>      <td>19.0</td>      <td>5.0</td>    </tr>    <tr>      <th>猛龙</th>      <th>主</th>      <td>0.2730</td>      <td>11.0</td>      <td>8.0</td>      <td>38.0</td>      <td>0.320</td>      <td>25.0</td>      <td>6.0</td>    </tr>    <tr>      <th>篮网</th>      <th>主</th>      <td>0.6150</td>      <td>8.0</td>      <td>13.0</td>      <td>37.0</td>      <td>0.650</td>      <td>20.0</td>      <td>10.0</td>    </tr>    <tr>      <th>老鹰</th>      <th>客</th>      <td>0.5450</td>      <td>11.0</td>      <td>8.0</td>      <td>29.0</td>      <td>0.533</td>      <td>15.0</td>      <td>3.0</td>    </tr>    <tr>      <th>骑士</th>      <th>主</th>      <td>0.4290</td>      <td>13.0</td>      <td>8.0</td>      <td>35.0</td>      <td>0.381</td>      <td>21.0</td>      <td>11.0</td>    </tr>    <tr>      <th>鹈鹕</th>      <th>主</th>      <td>0.4000</td>      <td>17.0</td>      <td>8.0</td>      <td>26.0</td>      <td>0.500</td>      <td>16.0</td>      <td>1.0</td>    </tr>    <tr>      <th>黄蜂</th>      <th>客</th>      <td>0.4000</td>      <td>11.0</td>      <td>8.0</td>      <td>27.0</td>      <td>0.444</td>      <td>18.0</td>      <td>10.0</td>    </tr>  </tbody></table></div><ul><li>values参数：需要对计算的数据进行筛选<ul><li>如果我们只需要哈登在主客场和不同胜负情况下的得分、篮板与助攻三项数据：</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.pivot_table(index=[<span class="string">&#x27;主客场&#x27;</span>,<span class="string">&#x27;胜负&#x27;</span>],values=[<span class="string">&#x27;得分&#x27;</span>,<span class="string">&#x27;篮板&#x27;</span>,<span class="string">&#x27;助攻&#x27;</span>])</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th></th>      <th>助攻</th>      <th>得分</th>      <th>篮板</th>    </tr>    <tr>      <th>主客场</th>      <th>胜负</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th rowspan="2" valign="top">主</th>      <th>胜</th>      <td>10.555556</td>      <td>34.222222</td>      <td>5.444444</td>    </tr>    <tr>      <th>负</th>      <td>8.666667</td>      <td>29.666667</td>      <td>5.000000</td>    </tr>    <tr>      <th rowspan="2" valign="top">客</th>      <th>胜</th>      <td>9.000000</td>      <td>32.000000</td>      <td>4.916667</td>    </tr>    <tr>      <th>负</th>      <td>8.000000</td>      <td>20.000000</td>      <td>4.000000</td>    </tr>  </tbody></table></div><ul><li>Aggfunc参数：设置我们对数据聚合时进行的函数操作<ul><li>当我们未设置aggfunc时，它默认aggfunc=’mean’计算均值。</li></ul></li><li>还想获得james harden在主客场和不同胜负情况下的总得分、总篮板、总助攻时：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.pivot_table(index=[<span class="string">&#x27;主客场&#x27;</span>,<span class="string">&#x27;胜负&#x27;</span>],values=[<span class="string">&#x27;得分&#x27;</span>,<span class="string">&#x27;篮板&#x27;</span>,<span class="string">&#x27;助攻&#x27;</span>],aggfunc=<span class="string">&#x27;sum&#x27;</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th></th>      <th>助攻</th>      <th>得分</th>      <th>篮板</th>    </tr>    <tr>      <th>主客场</th>      <th>胜负</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th rowspan="2" valign="top">主</th>      <th>胜</th>      <td>95</td>      <td>308</td>      <td>49</td>    </tr>    <tr>      <th>负</th>      <td>26</td>      <td>89</td>      <td>15</td>    </tr>    <tr>      <th rowspan="2" valign="top">客</th>      <th>胜</th>      <td>108</td>      <td>384</td>      <td>59</td>    </tr>    <tr>      <th>负</th>      <td>8</td>      <td>20</td>      <td>4</td>    </tr>  </tbody></table></div><ul><li>Columns:可以设置列层次字段<ul><li>对values字段进行分类</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取所有队主客场的总得分</span></span><br><span class="line">df.pivot_table(index=[<span class="string">&#x27;主客场&#x27;</span>],values=[<span class="string">&#x27;得分&#x27;</span>],aggfunc=<span class="string">&#x27;sum&#x27;</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>得分</th>    </tr>    <tr>      <th>主客场</th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>主</th>      <td>397</td>    </tr>    <tr>      <th>客</th>      <td>404</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取每个队主客场的总得分（在总得分的基础上又进行了对手的分类）</span></span><br><span class="line">df.pivot_table(index=[<span class="string">&#x27;主客场&#x27;</span>],values=[<span class="string">&#x27;得分&#x27;</span>],columns=<span class="string">&#x27;对手&#x27;</span>,aggfunc=<span class="string">&#x27;sum&#x27;</span>,fill_value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead tr th &#123;    text-align: left;&#125;.dataframe thead tr:last-of-type th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr>      <th></th>      <th colspan="18" halign="left">得分</th>    </tr>    <tr>      <th>对手</th>      <th>76人</th>      <th>勇士</th>      <th>国王</th>      <th>太阳</th>      <th>小牛</th>      <th>尼克斯</th>      <th>开拓者</th>      <th>掘金</th>      <th>步行者</th>      <th>湖人</th>      <th>灰熊</th>      <th>爵士</th>      <th>猛龙</th>      <th>篮网</th>      <th>老鹰</th>      <th>骑士</th>      <th>鹈鹕</th>      <th>黄蜂</th>    </tr>    <tr>      <th>主客场</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>主</th>      <td>29</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>29</td>      <td>37</td>      <td>0</td>      <td>21</td>      <td>29</td>      <td>0</td>      <td>60</td>      <td>56</td>      <td>38</td>      <td>37</td>      <td>0</td>      <td>35</td>      <td>26</td>      <td>0</td>    </tr>    <tr>      <th>客</th>      <td>27</td>      <td>27</td>      <td>27</td>      <td>48</td>      <td>0</td>      <td>31</td>      <td>48</td>      <td>0</td>      <td>26</td>      <td>36</td>      <td>49</td>      <td>29</td>      <td>0</td>      <td>0</td>      <td>29</td>      <td>0</td>      <td>0</td>      <td>27</td>    </tr>  </tbody></table></div><h2 id="交叉表"><a href="#交叉表" class="headerlink" title="交叉表"></a>交叉表</h2><ul><li>是一种用于计算分组的特殊透视图，对数据进行汇总</li><li>pd.crosstab(index,columns)<ul><li>index:分组数据，交叉表的行索引</li><li>columns:交叉表的列索引</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = DataFrame(&#123;<span class="string">&#x27;sex&#x27;</span>:[<span class="string">&#x27;man&#x27;</span>,<span class="string">&#x27;man&#x27;</span>,<span class="string">&#x27;women&#x27;</span>,<span class="string">&#x27;women&#x27;</span>,<span class="string">&#x27;man&#x27;</span>,<span class="string">&#x27;women&#x27;</span>,<span class="string">&#x27;man&#x27;</span>,<span class="string">&#x27;women&#x27;</span>,<span class="string">&#x27;women&#x27;</span>],</span><br><span class="line">                <span class="string">&#x27;age&#x27;</span>:[<span class="number">15</span>,<span class="number">23</span>,<span class="number">25</span>,<span class="number">17</span>,<span class="number">35</span>,<span class="number">57</span>,<span class="number">24</span>,<span class="number">31</span>,<span class="number">22</span>],</span><br><span class="line">                <span class="string">&#x27;smoke&#x27;</span>:[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">False</span>],</span><br><span class="line">                <span class="string">&#x27;height&#x27;</span>:[<span class="number">168</span>,<span class="number">179</span>,<span class="number">181</span>,<span class="number">166</span>,<span class="number">173</span>,<span class="number">178</span>,<span class="number">188</span>,<span class="number">190</span>,<span class="number">160</span>]</span><br><span class="line">&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>sex</th>      <th>age</th>      <th>smoke</th>      <th>height</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>man</td>      <td>15</td>      <td>True</td>      <td>168</td>    </tr>    <tr>      <th>1</th>      <td>man</td>      <td>23</td>      <td>False</td>      <td>179</td>    </tr>    <tr>      <th>2</th>      <td>women</td>      <td>25</td>      <td>False</td>      <td>181</td>    </tr>    <tr>      <th>3</th>      <td>women</td>      <td>17</td>      <td>True</td>      <td>166</td>    </tr>    <tr>      <th>4</th>      <td>man</td>      <td>35</td>      <td>True</td>      <td>173</td>    </tr>    <tr>      <th>5</th>      <td>women</td>      <td>57</td>      <td>False</td>      <td>178</td>    </tr>    <tr>      <th>6</th>      <td>man</td>      <td>24</td>      <td>False</td>      <td>188</td>    </tr>    <tr>      <th>7</th>      <td>women</td>      <td>31</td>      <td>True</td>      <td>190</td>    </tr>    <tr>      <th>8</th>      <td>women</td>      <td>22</td>      <td>False</td>      <td>160</td>    </tr>  </tbody></table></div><ul><li>求出各个性别抽烟的人数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.crosstab(df.smoke,df.sex)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>sex</th>      <th>man</th>      <th>women</th>    </tr>    <tr>      <th>smoke</th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>False</th>      <td>2</td>      <td>3</td>    </tr>    <tr>      <th>True</th>      <td>2</td>      <td>2</td>    </tr>  </tbody></table></div><ul><li>求出各个年龄段抽烟人情况</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.crosstab(df.age,df.smoke)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>smoke</th>      <th>False</th>      <th>True</th>    </tr>    <tr>      <th>age</th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>15</th>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>17</th>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>22</th>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>23</th>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>24</th>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>25</th>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>31</th>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>35</th>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>57</th>      <td>1</td>      <td>0</td>    </tr>  </tbody></table></div><hr><p>本文提及的数据集下载地址：<br>链接：<a href="https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg">https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg</a><br>提取码：1111 </p><hr>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Pandas中的一些高级操作&quot;&gt;&lt;a href=&quot;#Pandas中的一些高级操作&quot; class=&quot;headerlink&quot; title=&quot;Pandas中的一些高级操作&quot;&gt;&lt;/a&gt;Pandas中的一些高级操作&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; DataFrame&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>人口分析案例</title>
    <link href="http://woody0819.github.io/2021/05/25/test_5/"/>
    <id>http://woody0819.github.io/2021/05/25/test_5/</id>
    <published>2021-05-25T12:27:32.549Z</published>
    <updated>2021-05-25T13:31:01.746Z</updated>
    
    <content type="html"><![CDATA[<h1 id="人口分析案例"><a href="#人口分析案例" class="headerlink" title="人口分析案例"></a>人口分析案例</h1><ul><li>需求：<ul><li>导入文件，查看原始数据</li><li>将人口数据和各州的简称数据进行合并</li><li>将合并的数据中重复的abbreviation列进行删除</li><li>查看存在缺失数据的列</li><li>找到有哪些state/region使得state的值为NaN，进行去重操作</li><li>为找到的这些state/region的state项补上正确的值，从而去除掉state这一列的所有NaN</li><li>合并各州面积数据areas</li><li>我们会发现area(sq.mi)这一列有缺失数据，找出是哪些行</li><li>去除含有缺失数据的行</li><li>找出2010年的全民人口数据</li><li>计算各州的人口密度</li><li>排序，并找出人口密度最高的州</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br></pre></td></tr></table></figure><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入文件，查看原始数据</span></span><br><span class="line">abb = pd.read_csv(<span class="string">&#x27;data\\state-abbrevs.csv&#x27;</span>)    <span class="comment"># state表示州的全称，abbreviation表示州的简称</span></span><br><span class="line"><span class="built_in">print</span>(abb.head())</span><br><span class="line">area = pd.read_csv(<span class="string">&#x27;data\\state-areas.csv&#x27;</span>) <span class="comment"># state州全称，area(sq.mi)州面积</span></span><br><span class="line"><span class="built_in">print</span>(area.head())</span><br><span class="line">pop = pd.read_csv(<span class="string">&#x27;data\\state-population.csv&#x27;</span>)    <span class="comment"># state/region简称，population人口数量</span></span><br><span class="line"><span class="built_in">print</span>(pop.head())</span><br><span class="line"><span class="comment"># 将人口数据和各州的简称数据进行合并</span></span><br><span class="line">abb_pop = pd.merge(abb,pop,left_on=<span class="string">&#x27;abbreviation&#x27;</span>,right_on=<span class="string">&#x27;state/region&#x27;</span>,how=<span class="string">&#x27;outer&#x27;</span>) <span class="comment"># 默认是内连接inner,为了保证数据完整性此处指定outer</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop.head())</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>        state abbreviation0     Alabama           AL1      Alaska           AK2     Arizona           AZ3    Arkansas           AR4  California           CA        state  area (sq. mi)0     Alabama          524231      Alaska         6564252     Arizona         1140063    Arkansas          531824  California         163707  state/region     ages  year  population0           AL  under18  2012   1117489.01           AL    total  2012   4817528.02           AL  under18  2010   1130966.03           AL    total  2010   4785570.04           AL  under18  2011   1125763.0     state abbreviation state/region     ages  year  population0  Alabama           AL           AL  under18  2012   1117489.01  Alabama           AL           AL    total  2012   4817528.02  Alabama           AL           AL  under18  2010   1130966.03  Alabama           AL           AL    total  2010   4785570.04  Alabama           AL           AL  under18  2011   1125763.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将合并的数据中重复的abbreviation列进行删除</span></span><br><span class="line">abb_pop.drop(labels=<span class="string">&#x27;abbreviation&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>) <span class="comment"># inplace=True将编辑的数据映射入原始数据,故不需要再次使用‘abb_pop=’来重新赋值</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop.head())</span><br><span class="line"><span class="comment"># 查看存在缺失数据的列</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop.isnull().<span class="built_in">any</span>(axis=<span class="number">0</span>)) <span class="comment"># 存在空值的列为True</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop.info())   <span class="comment"># 返回数据基本信息，从数据数量看出哪些列存在空值</span></span><br></pre></td></tr></table></figure><pre><code>     state state/region     ages  year  population0  Alabama           AL  under18  2012   1117489.01  Alabama           AL    total  2012   4817528.02  Alabama           AL  under18  2010   1130966.03  Alabama           AL    total  2010   4785570.04  Alabama           AL  under18  2011   1125763.0state            Truestate/region    Falseages            Falseyear            Falsepopulation       Truedtype: bool&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 2544 entries, 0 to 2543Data columns (total 5 columns): #   Column        Non-Null Count  Dtype  ---  ------        --------------  -----   0   state         2448 non-null   object  1   state/region  2544 non-null   object  2   ages          2544 non-null   object  3   year          2544 non-null   int64   4   population    2524 non-null   float64dtypes: float64(1), int64(1), object(3)memory usage: 119.2+ KBNone</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找到有哪些state/region使得state的值为NaN，进行去重操作</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop.loc[abb_pop[<span class="string">&#x27;state&#x27;</span>].isnull()][<span class="string">&#x27;state/region&#x27;</span>].unique())  <span class="comment"># series的unique方法按顺序返回出现唯一一次的内容</span></span><br><span class="line"><span class="comment"># 为找到的这些state/region的state项补上正确的值，从而去除掉state这一列的所有NaN</span></span><br><span class="line"><span class="comment"># 此处不能使用fillna填充，因为不是使用临近值和固定值填充；使用元素赋值的方式进行填充</span></span><br><span class="line"><span class="comment"># 1.先给USA的全称对应的空值进行批量赋值，首先找到USA对应的行数据。</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop.loc[abb_pop[<span class="string">&#x27;state/region&#x27;</span>] == <span class="string">&#x27;USA&#x27;</span>])</span><br></pre></td></tr></table></figure><pre><code>[&#39;PR&#39; &#39;USA&#39;]     state state/region     ages  year   population2496   NaN          USA  under18  1990   64218512.02497   NaN          USA    total  1990  249622814.02498   NaN          USA    total  1991  252980942.02499   NaN          USA  under18  1991   65313018.02500   NaN          USA  under18  1992   66509177.02501   NaN          USA    total  1992  256514231.02502   NaN          USA    total  1993  259918595.02503   NaN          USA  under18  1993   67594938.02504   NaN          USA  under18  1994   68640936.02505   NaN          USA    total  1994  263125826.02506   NaN          USA  under18  1995   69473140.02507   NaN          USA  under18  1996   70233512.02508   NaN          USA    total  1995  266278403.02509   NaN          USA    total  1996  269394291.02510   NaN          USA    total  1997  272646932.02511   NaN          USA  under18  1997   70920738.02512   NaN          USA  under18  1998   71431406.02513   NaN          USA    total  1998  275854116.02514   NaN          USA  under18  1999   71946051.02515   NaN          USA    total  2000  282162411.02516   NaN          USA  under18  2000   72376189.02517   NaN          USA    total  1999  279040181.02518   NaN          USA    total  2001  284968955.02519   NaN          USA  under18  2001   72671175.02520   NaN          USA    total  2002  287625193.02521   NaN          USA  under18  2002   72936457.02522   NaN          USA    total  2003  290107933.02523   NaN          USA  under18  2003   73100758.02524   NaN          USA    total  2004  292805298.02525   NaN          USA  under18  2004   73297735.02526   NaN          USA    total  2005  295516599.02527   NaN          USA  under18  2005   73523669.02528   NaN          USA    total  2006  298379912.02529   NaN          USA  under18  2006   73757714.02530   NaN          USA    total  2007  301231207.02531   NaN          USA  under18  2007   74019405.02532   NaN          USA    total  2008  304093966.02533   NaN          USA  under18  2008   74104602.02534   NaN          USA  under18  2013   73585872.02535   NaN          USA    total  2013  316128839.02536   NaN          USA    total  2009  306771529.02537   NaN          USA  under18  2009   74134167.02538   NaN          USA  under18  2010   74119556.02539   NaN          USA    total  2010  309326295.02540   NaN          USA  under18  2011   73902222.02541   NaN          USA    total  2011  311582564.02542   NaN          USA  under18  2012   73708179.02543   NaN          USA    total  2012  313873685.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2.获取USA全称为空的数据对应的行索引</span></span><br><span class="line">indexs = abb_pop.loc[abb_pop[<span class="string">&#x27;state/region&#x27;</span>] == <span class="string">&#x27;USA&#x27;</span>].index</span><br><span class="line"><span class="built_in">print</span>(indexs)</span><br><span class="line">abb_pop.loc[indexs,<span class="string">&#x27;state&#x27;</span>] = <span class="string">&#x27;United States&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop.loc[abb_pop[<span class="string">&#x27;state&#x27;</span>].isnull()][<span class="string">&#x27;state/region&#x27;</span>].unique())  <span class="comment"># 此处只剩PR</span></span><br><span class="line"><span class="comment"># 对于PR来说过程与USA相同</span></span><br><span class="line">indexs = abb_pop.loc[abb_pop[<span class="string">&#x27;state/region&#x27;</span>] == <span class="string">&#x27;PR&#x27;</span>].index</span><br><span class="line">abb_pop.loc[indexs,<span class="string">&#x27;state&#x27;</span>] = <span class="string">&#x27;Puerto Rico&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop.loc[abb_pop[<span class="string">&#x27;state&#x27;</span>].isnull()][<span class="string">&#x27;state/region&#x27;</span>].unique())  <span class="comment"># 此处没有空值了</span></span><br></pre></td></tr></table></figure><pre><code>Int64Index([2496, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2504, 2505, 2506,            2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517,            2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528,            2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539,            2540, 2541, 2542, 2543],           dtype=&#39;int64&#39;)[&#39;PR&#39;][]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 合并各州面积数据areas</span></span><br><span class="line">abb_pop_area = pd.merge(abb_pop,area,how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line"><span class="comment"># 我们会发现area(sq.mi)这一列有缺失数据，找出是哪些行</span></span><br><span class="line">abb_pop_area.loc[abb_pop_area[<span class="string">&#x27;area (sq. mi)&#x27;</span>].isnull()]    <span class="comment"># 空对应的行数据</span></span><br><span class="line">indexs = abb_pop_area.loc[abb_pop_area[<span class="string">&#x27;area (sq. mi)&#x27;</span>].isnull()].index</span><br><span class="line"><span class="comment"># 去除含有缺失数据的行</span></span><br><span class="line">abb_pop_area.drop(labels=indexs,axis=<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>state/region</th>      <th>ages</th>      <th>year</th>      <th>population</th>      <th>area (sq. mi)</th>    </tr>  </thead>  <tbody>    <tr>      <th>2496</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1990</td>      <td>64218512.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2497</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1990</td>      <td>249622814.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2498</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1991</td>      <td>252980942.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2499</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1991</td>      <td>65313018.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2500</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1992</td>      <td>66509177.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2501</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1992</td>      <td>256514231.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2502</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1993</td>      <td>259918595.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2503</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1993</td>      <td>67594938.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2504</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1994</td>      <td>68640936.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2505</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1994</td>      <td>263125826.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2506</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1995</td>      <td>69473140.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2507</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1996</td>      <td>70233512.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2508</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1995</td>      <td>266278403.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2509</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1996</td>      <td>269394291.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2510</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1997</td>      <td>272646932.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2511</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1997</td>      <td>70920738.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2512</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1998</td>      <td>71431406.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2513</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1998</td>      <td>275854116.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2514</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>1999</td>      <td>71946051.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2515</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2000</td>      <td>282162411.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2516</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2000</td>      <td>72376189.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2517</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>1999</td>      <td>279040181.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2518</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2001</td>      <td>284968955.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2519</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2001</td>      <td>72671175.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2520</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2002</td>      <td>287625193.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2521</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2002</td>      <td>72936457.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2522</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2003</td>      <td>290107933.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2523</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2003</td>      <td>73100758.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2524</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2004</td>      <td>292805298.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2525</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2004</td>      <td>73297735.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2526</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2005</td>      <td>295516599.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2527</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2005</td>      <td>73523669.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2528</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2006</td>      <td>298379912.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2529</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2006</td>      <td>73757714.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2530</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2007</td>      <td>301231207.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2531</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2007</td>      <td>74019405.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2532</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2008</td>      <td>304093966.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2533</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2008</td>      <td>74104602.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2534</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2013</td>      <td>73585872.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2535</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2013</td>      <td>316128839.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2536</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2009</td>      <td>306771529.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2537</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2009</td>      <td>74134167.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2538</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2010</td>      <td>74119556.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2539</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2010</td>      <td>309326295.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2540</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2011</td>      <td>73902222.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2541</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2011</td>      <td>311582564.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2542</th>      <td>United States</td>      <td>USA</td>      <td>under18</td>      <td>2012</td>      <td>73708179.0</td>      <td>NaN</td>    </tr>    <tr>      <th>2543</th>      <td>United States</td>      <td>USA</td>      <td>total</td>      <td>2012</td>      <td>313873685.0</td>      <td>NaN</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找出2010年的全民人口数据(基于df做条件查询)</span></span><br><span class="line"><span class="built_in">print</span>(abb_pop_area.query(<span class="string">&#x27;ages == &quot;total&quot; &amp; year == 2010&#x27;</span>))</span><br><span class="line"><span class="comment"># 计算各州的人口密度(人口/面积)</span></span><br><span class="line">abb_pop_area[<span class="string">&#x27;density of population&#x27;</span>] = abb_pop_area[<span class="string">&#x27;population&#x27;</span>] / abb_pop_area[<span class="string">&#x27;area (sq. mi)&#x27;</span>]</span><br><span class="line">abb_pop_area.head()</span><br><span class="line"><span class="comment"># 排序，并找出人口密度最高的州</span></span><br><span class="line">abb_pop_area.sort_values(by=<span class="string">&#x27;density of population&#x27;</span>,axis=<span class="number">0</span>,ascending=<span class="literal">False</span>).iloc[<span class="number">0</span>][<span class="string">&#x27;state&#x27;</span>]    <span class="comment"># ascending是否升序排序，默认升序为True，降序则为False。</span></span><br></pre></td></tr></table></figure><pre><code>                     state state/region   ages  year   population  \3                  Alabama           AL  total  2010    4785570.0   91                  Alaska           AK  total  2010     713868.0   101                Arizona           AZ  total  2010    6408790.0   189               Arkansas           AR  total  2010    2922280.0   197             California           CA  total  2010   37333601.0   283               Colorado           CO  total  2010    5048196.0   293            Connecticut           CT  total  2010    3579210.0   379               Delaware           DE  total  2010     899711.0   389   District of Columbia           DC  total  2010     605125.0   475                Florida           FL  total  2010   18846054.0   485                Georgia           GA  total  2010    9713248.0   570                 Hawaii           HI  total  2010    1363731.0   581                  Idaho           ID  total  2010    1570718.0   666               Illinois           IL  total  2010   12839695.0   677                Indiana           IN  total  2010    6489965.0   762                   Iowa           IA  total  2010    3050314.0   773                 Kansas           KS  total  2010    2858910.0   858               Kentucky           KY  total  2010    4347698.0   869              Louisiana           LA  total  2010    4545392.0   954                  Maine           ME  total  2010    1327366.0   965                Montana           MT  total  2010     990527.0   1050              Nebraska           NE  total  2010    1829838.0   1061                Nevada           NV  total  2010    2703230.0   1146         New Hampshire           NH  total  2010    1316614.0   1157            New Jersey           NJ  total  2010    8802707.0   1242            New Mexico           NM  total  2010    2064982.0   1253              New York           NY  total  2010   19398228.0   1338        North Carolina           NC  total  2010    9559533.0   1349          North Dakota           ND  total  2010     674344.0   1434                  Ohio           OH  total  2010   11545435.0   1445              Oklahoma           OK  total  2010    3759263.0   1530                Oregon           OR  total  2010    3837208.0   1541              Maryland           MD  total  2010    5787193.0   1626         Massachusetts           MA  total  2010    6563263.0   1637              Michigan           MI  total  2010    9876149.0   1722             Minnesota           MN  total  2010    5310337.0   1733           Mississippi           MS  total  2010    2970047.0   1818              Missouri           MO  total  2010    5996063.0   1829          Pennsylvania           PA  total  2010   12710472.0   1914          Rhode Island           RI  total  2010    1052669.0   1925        South Carolina           SC  total  2010    4636361.0   2010          South Dakota           SD  total  2010     816211.0   2021             Tennessee           TN  total  2010    6356683.0   2106                 Texas           TX  total  2010   25245178.0   2117                  Utah           UT  total  2010    2774424.0   2202               Vermont           VT  total  2010     625793.0   2213              Virginia           VA  total  2010    8024417.0   2298            Washington           WA  total  2010    6742256.0   2309         West Virginia           WV  total  2010    1854146.0   2394             Wisconsin           WI  total  2010    5689060.0   2405               Wyoming           WY  total  2010     564222.0   2490           Puerto Rico           PR  total  2010    3721208.0   2539         United States          USA  total  2010  309326295.0         area (sq. mi)         midu  density of population  3           52423.0    91.287603              91.287603  91         656425.0     1.087509               1.087509  101        114006.0    56.214497              56.214497  189         53182.0    54.948667              54.948667  197        163707.0   228.051342             228.051342  283        104100.0    48.493718              48.493718  293          5544.0   645.600649             645.600649  379          1954.0   460.445752             460.445752  389            68.0  8898.897059            8898.897059  475         65758.0   286.597129             286.597129  485         59441.0   163.409902             163.409902  570         10932.0   124.746707             124.746707  581         83574.0    18.794338              18.794338  666         57918.0   221.687472             221.687472  677         36420.0   178.197831             178.197831  762         56276.0    54.202751              54.202751  773         82282.0    34.745266              34.745266  858         40411.0   107.586994             107.586994  869         51843.0    87.676099              87.676099  954         35387.0    37.509990              37.509990  965        147046.0     6.736171               6.736171  1050        77358.0    23.654153              23.654153  1061       110567.0    24.448796              24.448796  1146         9351.0   140.799273             140.799273  1157         8722.0  1009.253268            1009.253268  1242       121593.0    16.982737              16.982737  1253        54475.0   356.094135             356.094135  1338        53821.0   177.617157             177.617157  1349        70704.0     9.537565               9.537565  1434        44828.0   257.549634             257.549634  1445        69903.0    53.778278              53.778278  1530        98386.0    39.001565              39.001565  1541        12407.0   466.445797             466.445797  1626        10555.0   621.815538             621.815538  1637        96810.0   102.015794             102.015794  1722        86943.0    61.078373              61.078373  1733        48434.0    61.321530              61.321530  1818        69709.0    86.015622              86.015622  1829        46058.0   275.966651             275.966651  1914         1545.0   681.339159             681.339159  1925        32007.0   144.854594             144.854594  2010        77121.0    10.583512              10.583512  2021        42146.0   150.825298             150.825298  2106       268601.0    93.987655              93.987655  2117        84904.0    32.677188              32.677188  2202         9615.0    65.085075              65.085075  2213        42769.0   187.622273             187.622273  2298        71303.0    94.557817              94.557817  2309        24231.0    76.519582              76.519582  2394        65503.0    86.851900              86.851900  2405        97818.0     5.768079               5.768079  2490         3515.0  1058.665149            1058.665149  2539            NaN          NaN                    NaN  &#39;District of Columbia&#39;</code></pre><hr><p>本文提及的数据集下载地址：<br>链接：<a href="https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg">https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg</a><br>提取码：1111 </p><hr>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;人口分析案例&quot;&gt;&lt;a href=&quot;#人口分析案例&quot; class=&quot;headerlink&quot; title=&quot;人口分析案例&quot;&gt;&lt;/a&gt;人口分析案例&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;需求：&lt;ul&gt;
&lt;li&gt;导入文件，查看原始数据&lt;/li&gt;
&lt;li&gt;将人口数据和各州的简称数据进行合并&lt;/li&gt;
&lt;li&gt;将合并的数据中重复的abbreviation列进行删除&lt;/li&gt;
&lt;li&gt;查看存在缺失数据的列&lt;/li&gt;
&lt;li&gt;找到有哪些state/region使得state的值为NaN，进行去重操作&lt;/li&gt;
&lt;li&gt;为找到的这些state/region的state项补上正确的值，从而去除掉state这一列的所有NaN&lt;/li&gt;
&lt;li&gt;合并各州面积数据areas&lt;/li&gt;
&lt;li&gt;我们会发现area(sq.mi)这一列有缺失数据，找出是哪些行&lt;/li&gt;
&lt;li&gt;去除含有缺失数据的行&lt;/li&gt;
&lt;li&gt;找出2010年的全民人口数据&lt;/li&gt;
&lt;li&gt;计算各州的人口密度&lt;/li&gt;
&lt;li&gt;排序，并找出人口密度最高的州&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; DataFrame&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>级联操作</title>
    <link href="http://woody0819.github.io/2021/05/25/test_4/"/>
    <id>http://woody0819.github.io/2021/05/25/test_4/</id>
    <published>2021-05-25T12:27:32.460Z</published>
    <updated>2021-05-26T00:38:21.130Z</updated>
    
    <content type="html"><![CDATA[<h1 id="级联操作"><a href="#级联操作" class="headerlink" title="级联操作"></a>级联操作</h1><ul><li>pd.concat,pd.append<br>pandas使用pd.concat函数，与np.concatenate函数类似，只是多了一些参数：<br>objs<br>axis<br>keys<br>join=’outer’/‘inner’：表示的是级联方式，outer会将所有的项进行级联（忽略匹配和不匹配），而inner只会将匹配的项级联在一起，不匹配的不级联<br>ignore_index=False</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br></pre></td></tr></table></figure><span id="more"></span><ul><li>匹配级联</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df1 = DataFrame(np.random.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">5</span>,<span class="number">3</span>)),columns=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>])</span><br><span class="line">df2 = DataFrame(np.random.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">5</span>,<span class="number">3</span>)),columns=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;D&#x27;</span>,<span class="string">&#x27;C&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df1)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br></pre></td></tr></table></figure><pre><code>    A   B   C0  79  32  251  25  25  372  10  83  723   0  48   34  59  31  86    A   D   C0  35  54  591   5   7  762  76  82  893  17  93  464  99  56   8</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pd.concat((df1,df2),axis=<span class="number">1</span>))  <span class="comment"># 横向级联</span></span><br></pre></td></tr></table></figure><pre><code>    A   B   C   A   D   C0  79  32  25  35  54  591  25  25  37   5   7  762  10  83  72  76  82  893   0  48   3  17  93  464  59  31  86  99  56   8</code></pre><ul><li>不匹配级联<ul><li>不匹配级联指的是级联的维度索引不一致。例如纵向级联时列索引不一致，横向级联时行索引不一致</li><li>有2中连接方式：<ul><li>外连接：补NAN（默认模式），如果想要保留数据的完整性必须使用outer(外连接)</li><li>内连接：只连接匹配的项</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pd.concat((df1,df2),axis=<span class="number">0</span>))  <span class="comment"># 纵向级联，出现不匹配级联</span></span><br><span class="line"><span class="built_in">print</span>(pd.concat((df1,df2),axis=<span class="number">0</span>,join=<span class="string">&#x27;inner&#x27;</span>))</span><br></pre></td></tr></table></figure><pre><code>    A     B   C     D0  79  32.0  25   NaN1  25  25.0  37   NaN2  10  83.0  72   NaN3   0  48.0   3   NaN4  59  31.0  86   NaN0  35   NaN  59  54.01   5   NaN  76   7.02  76   NaN  89  82.03  17   NaN  46  93.04  99   NaN   8  56.0    A   C0  79  251  25  372  10  723   0   34  59  860  35  591   5  762  76  893  17  464  99   8</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df3 = DataFrame(np.random.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">5</span>,<span class="number">2</span>)),columns=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(pd.concat((df1,df3),axis=<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(pd.concat((df1,df3),axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure><ul><li>append函数的使用<ul><li>默认纵向级联外连接</li><li>知道即可，一般不用</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df1.append(df2))</span><br></pre></td></tr></table></figure><pre><code>    A     B   C     D0  79  32.0  25   NaN1  25  25.0  37   NaN2  10  83.0  72   NaN3   0  48.0   3   NaN4  59  31.0  86   NaN0  35   NaN  59  54.01   5   NaN  76   7.02  76   NaN  89  82.03  17   NaN  46  93.04  99   NaN   8  56.0</code></pre><h1 id="合并操作"><a href="#合并操作" class="headerlink" title="合并操作"></a>合并操作</h1><ul><li>merge与concat的区别在于，merge需要依据某一共同列来进行合并；merge是对数据进行合并，而concat是对表格进行级联</li><li>使用pd.merge()合并时，会自动根据两者相同column名称的那一列，作为key来进行合并</li><li>注意每一列元素的顺序不要求一致</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一对一合并</span></span><br><span class="line">df1 = DataFrame(&#123;<span class="string">&#x27;employee&#x27;</span>:[<span class="string">&#x27;Bob&#x27;</span>,<span class="string">&#x27;Jake&#x27;</span>,<span class="string">&#x27;Lisa&#x27;</span>],<span class="string">&#x27;group&#x27;</span>:[<span class="string">&#x27;Accounting&#x27;</span>,<span class="string">&#x27;Engineering&#x27;</span>,<span class="string">&#x27;Engineering&#x27;</span>]&#125;)</span><br><span class="line">df2 = DataFrame(&#123;<span class="string">&#x27;employee&#x27;</span>:[<span class="string">&#x27;Lisa&#x27;</span>,<span class="string">&#x27;Bob&#x27;</span>,<span class="string">&#x27;Jake&#x27;</span>],<span class="string">&#x27;hire_date&#x27;</span>:[<span class="number">2004</span>,<span class="number">2008</span>,<span class="number">2012</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(df1)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df2,on=<span class="string">&#x27;employee&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df2))    <span class="comment"># on也可以不写，默认会将两表中共有的列作为合并条件，此处结果相同</span></span><br></pre></td></tr></table></figure><pre><code>  employee        group0      Bob   Accounting1     Jake  Engineering2     Lisa  Engineering  employee  hire_date0     Lisa       20041      Bob       20082     Jake       2012  employee        group  hire_date0      Bob   Accounting       20081     Jake  Engineering       20122     Lisa  Engineering       2004  employee        group  hire_date0      Bob   Accounting       20081     Jake  Engineering       20122     Lisa  Engineering       2004</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一对多合并</span></span><br><span class="line">df3 = DataFrame(&#123;<span class="string">&#x27;employee&#x27;</span>:[<span class="string">&#x27;Lisa&#x27;</span>,<span class="string">&#x27;Jake&#x27;</span>],<span class="string">&#x27;group&#x27;</span>:[<span class="string">&#x27;Accounting&#x27;</span>,<span class="string">&#x27;Engineering&#x27;</span>],<span class="string">&#x27;hire_date&#x27;</span>:[<span class="number">2004</span>,<span class="number">2016</span>]&#125;)</span><br><span class="line">df4 = DataFrame(&#123;<span class="string">&#x27;group&#x27;</span>:[<span class="string">&#x27;Accounting&#x27;</span>,<span class="string">&#x27;Engineering&#x27;</span>,<span class="string">&#x27;Engineering&#x27;</span>],<span class="string">&#x27;supervisor&#x27;</span>:[<span class="string">&#x27;Carly&#x27;</span>,<span class="string">&#x27;Guido&#x27;</span>,<span class="string">&#x27;Steve&#x27;</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(df3)</span><br><span class="line"><span class="built_in">print</span>(df4)</span><br><span class="line"><span class="built_in">print</span>(pd.merge(df3,df4))</span><br></pre></td></tr></table></figure><pre><code>  employee        group  hire_date0     Lisa   Accounting       20041     Jake  Engineering       2016         group supervisor0   Accounting      Carly1  Engineering      Guido2  Engineering      Steve  employee        group  hire_date supervisor0     Lisa   Accounting       2004      Carly1     Jake  Engineering       2016      Guido2     Jake  Engineering       2016      Steve</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多对多合并</span></span><br><span class="line">df5 = DataFrame(&#123;<span class="string">&#x27;group&#x27;</span>:[<span class="string">&#x27;Engineering&#x27;</span>,<span class="string">&#x27;Engineering&#x27;</span>,<span class="string">&#x27;HR&#x27;</span>],<span class="string">&#x27;supervisor&#x27;</span>:[<span class="string">&#x27;Carly&#x27;</span>,<span class="string">&#x27;Guido&#x27;</span>,<span class="string">&#x27;Steve&#x27;</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(df5)</span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df5))    <span class="comment"># 默认内连接</span></span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df5,how=<span class="string">&#x27;outer&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df5,how=<span class="string">&#x27;left&#x27;</span>)) <span class="comment"># 保留左连接</span></span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df5,how=<span class="string">&#x27;right&#x27;</span>))    <span class="comment"># 保留右连接</span></span><br></pre></td></tr></table></figure><pre><code>         group supervisor0  Engineering      Carly1  Engineering      Guido2           HR      Steve  employee        group supervisor0     Jake  Engineering      Carly1     Jake  Engineering      Guido2     Lisa  Engineering      Carly3     Lisa  Engineering      Guido  employee        group supervisor0      Bob   Accounting        NaN1     Jake  Engineering      Carly2     Jake  Engineering      Guido3     Lisa  Engineering      Carly4     Lisa  Engineering      Guido5      NaN           HR      Steve  employee        group supervisor0      Bob   Accounting        NaN1     Jake  Engineering      Carly2     Jake  Engineering      Guido3     Lisa  Engineering      Carly4     Lisa  Engineering      Guido  employee        group supervisor0     Jake  Engineering      Carly1     Lisa  Engineering      Carly2     Jake  Engineering      Guido3     Lisa  Engineering      Guido4      NaN           HR      Steve</code></pre><h2 id="key的规范化"><a href="#key的规范化" class="headerlink" title="key的规范化"></a>key的规范化</h2><ul><li>当列冲突时，即有多个列名称相同时需要使用on=来指定哪一个列作为Key,配合suffixes指定冲突列名</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df1 = DataFrame(&#123;<span class="string">&#x27;employee&#x27;</span>:[<span class="string">&#x27;Jack&#x27;</span>,<span class="string">&#x27;Summer&#x27;</span>,<span class="string">&#x27;Steve&#x27;</span>],<span class="string">&#x27;group&#x27;</span>:[<span class="string">&#x27;Accounting&#x27;</span>,<span class="string">&#x27;Finance&#x27;</span>,<span class="string">&#x27;Marketing&#x27;</span>]&#125;)</span><br><span class="line">df2 = DataFrame(&#123;<span class="string">&#x27;employee&#x27;</span>:[<span class="string">&#x27;Jack&#x27;</span>,<span class="string">&#x27;Bob&#x27;</span>,<span class="string">&#x27;Jake&#x27;</span>],<span class="string">&#x27;hire_date&#x27;</span>:[<span class="number">2003</span>,<span class="number">2009</span>,<span class="number">2012</span>],<span class="string">&#x27;group&#x27;</span>:[<span class="string">&#x27;Accounting&#x27;</span>,<span class="string">&#x27;Sell&#x27;</span>,<span class="string">&#x27;CEO&#x27;</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(df1)</span><br><span class="line"><span class="built_in">print</span>(df2)</span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df2))    <span class="comment"># 不指定合并条件则相同的几项共同作为合并条件</span></span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df2,on=<span class="string">&#x27;group&#x27;</span>))</span><br></pre></td></tr></table></figure><pre><code>  employee       group0     Jack  Accounting1   Summer     Finance2    Steve   Marketing  employee  hire_date       group0     Jack       2003  Accounting1      Bob       2009        Sell2     Jake       2012         CEO  employee       group  hire_date0     Jack  Accounting       2003  employee_x       group employee_y  hire_date0       Jack  Accounting       Jack       2003</code></pre><ul><li>当两张表没有可进行连接的列时，可使用left_on和right_on手动指定merge中左右两边的哪一列作为连接的列</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df1 = DataFrame(&#123;<span class="string">&#x27;employee&#x27;</span>:[<span class="string">&#x27;Bobs&#x27;</span>,<span class="string">&#x27;Linda&#x27;</span>,<span class="string">&#x27;Bill&#x27;</span>],<span class="string">&#x27;group&#x27;</span>:[<span class="string">&#x27;Accounting&#x27;</span>,<span class="string">&#x27;Product&#x27;</span>,<span class="string">&#x27;Marketing&#x27;</span>],<span class="string">&#x27;hire_date&#x27;</span>:[<span class="number">1998</span>,<span class="number">2017</span>,<span class="number">2018</span>]&#125;)</span><br><span class="line">df5 = DataFrame(&#123;<span class="string">&#x27;name&#x27;</span>:[<span class="string">&#x27;Lisa&#x27;</span>,<span class="string">&#x27;Bobs&#x27;</span>,<span class="string">&#x27;Bill&#x27;</span>],<span class="string">&#x27;hire_dates&#x27;</span>:[<span class="number">1998</span>,<span class="number">2016</span>,<span class="number">2007</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(df1)</span><br><span class="line"><span class="built_in">print</span>(df5)</span><br><span class="line"><span class="comment"># print(pd.merge(df1,df5))  # 此处合并出错，因为没有共同的列，需要指定左右标准</span></span><br><span class="line"><span class="built_in">print</span>(pd.merge(df1,df5,left_on=<span class="string">&#x27;employee&#x27;</span>,right_on=<span class="string">&#x27;name&#x27;</span>))</span><br></pre></td></tr></table></figure><pre><code>  employee       group  hire_date0     Bobs  Accounting       19981    Linda     Product       20172     Bill   Marketing       2018   name  hire_dates0  Lisa        19981  Bobs        20162  Bill        2007  employee       group  hire_date  name  hire_dates0     Bobs  Accounting       1998  Bobs        20161     Bill   Marketing       2018  Bill        2007</code></pre>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;级联操作&quot;&gt;&lt;a href=&quot;#级联操作&quot; class=&quot;headerlink&quot; title=&quot;级联操作&quot;&gt;&lt;/a&gt;级联操作&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;pd.concat,pd.append&lt;br&gt;pandas使用pd.concat函数，与np.concatenate函数类似，只是多了一些参数：&lt;br&gt;objs&lt;br&gt;axis&lt;br&gt;keys&lt;br&gt;join=’outer’/‘inner’：表示的是级联方式，outer会将所有的项进行级联（忽略匹配和不匹配），而inner只会将匹配的项级联在一起，不匹配的不级联&lt;br&gt;ignore_index=False&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; DataFrame&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>处理丢失数据</title>
    <link href="http://woody0819.github.io/2021/05/25/test_3/"/>
    <id>http://woody0819.github.io/2021/05/25/test_3/</id>
    <published>2021-05-25T12:27:32.215Z</published>
    <updated>2021-07-07T07:28:11.213Z</updated>
    
    <content type="html"><![CDATA[<h1 id="处理丢失数据"><a href="#处理丢失数据" class="headerlink" title="处理丢失数据"></a>处理丢失数据</h1><p>1、原始数据中会存在缺失值（空值）<br>2、重复值<br>3、异常值  </p><ul><li>有两种丢失数据  <ul><li>None  </li><li>np.nan(NAN)</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">两种丢失数据的区别</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(<span class="literal">None</span>))   <span class="comment"># None对象类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(np.nan)) <span class="comment"># NAN浮点型</span></span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;NoneType&#39;&gt;&lt;class &#39;float&#39;&gt;</code></pre><span id="more"></span><ul><li>为什么在数据分析中需要用到的是浮点类型的空而不是对象类型？  <ul><li>数据分析中会经常使用某些形式的运算来处理原始数据，如果原始数据中的空值为NAN形式，则不会干扰或者中断运算，NAN是可以参与运算的；  </li><li>None是不可以参与运算的  </li></ul></li><li>在pandas中如果遇到了None形式的空值则pandas会将其强转成NAN的形式。    </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.nan+<span class="number">1</span>) <span class="comment"># 输出结果仍为nan</span></span><br><span class="line"><span class="built_in">print</span>(<span class="literal">None</span>+<span class="number">1</span>)   <span class="comment"># 会出现编译错误</span></span><br></pre></td></tr></table></figure><pre><code>nan---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)&lt;ipython-input-49-e38e0a464830&gt; in &lt;module&gt;()      1 print(np.nan+1) # 输出结果仍为nan----&gt; 2 print(None+1)   # 会出现编译错误TypeError: unsupported operand type(s) for +: &#39;NoneType&#39; and &#39;int&#39;</code></pre><h1 id="pandas处理空值操作"><a href="#pandas处理空值操作" class="headerlink" title="pandas处理空值操作"></a>pandas处理空值操作</h1><ul><li>isnull</li><li>notnull</li><li>any</li><li>all</li><li>dropna</li><li>fillna</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame,Series</span><br><span class="line"><span class="comment"># 创建一组含有空值的数据</span></span><br><span class="line">df = DataFrame(np.random.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">8</span>,<span class="number">6</span>)))</span><br><span class="line">df.iloc[<span class="number">2</span>,<span class="number">3</span>] = <span class="literal">None</span></span><br><span class="line">df.iloc[<span class="number">4</span>,<span class="number">4</span>] = np.nan</span><br><span class="line">df.iloc[<span class="number">5</span>,<span class="number">2</span>] = <span class="literal">None</span></span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><pre><code>    0   1     2     3     4   50  44  13  76.0  12.0  75.0  271   7  67  62.0  46.0  95.0  602  88  31   2.0   NaN  18.0  333  90   1  61.0  66.0  50.0  694  54  78  65.0  31.0   NaN  195  97   7   NaN  37.0  26.0  906  52  79   2.0  46.0   1.0  217   7  58  29.0  87.0   7.0  49</code></pre><ul><li>方式1：对空值进行过滤（删除空值所在的行数据）<ul><li>isnull, notnull, any, all  <ul><li>isnull-&gt;any</li><li>notnull-&gt;all</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.isnull())</span><br><span class="line"><span class="comment"># 哪些行中存在true</span></span><br><span class="line"><span class="built_in">print</span>(df.isnull().<span class="built_in">any</span>(axis=<span class="number">1</span>)) <span class="comment"># any：用来检测行或列中是否存在True，若存在返回True否则返回False</span></span><br><span class="line"><span class="comment"># 将该Boolean值作为行索引，即可得到存在缺失值的行数据以及相应的行索引</span></span><br><span class="line"><span class="built_in">print</span>(df.loc[df.isnull().<span class="built_in">any</span>(axis=<span class="number">1</span>)])</span><br><span class="line">drop_index = df.loc[df.isnull().<span class="built_in">any</span>(axis=<span class="number">1</span>)].index  <span class="comment"># 将要删除的行索引</span></span><br><span class="line"><span class="built_in">print</span>(df.drop(labels=drop_index,axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>       0      1      2      3      4      50  False  False  False  False  False  False1  False  False  False  False  False  False2  False  False  False   True  False  False3  False  False  False  False  False  False4  False  False  False  False   True  False5  False  False   True  False  False  False6  False  False  False  False  False  False7  False  False  False  False  False  False0    False1    False2     True3    False4     True5     True6    False7    Falsedtype: bool    0   1     2     3     4   52  88  31   2.0   NaN  18.0  334  54  78  65.0  31.0   NaN  195  97   7   NaN  37.0  26.0  90    0   1     2     3     4   50  44  13  76.0  12.0  75.0  271   7  67  62.0  46.0  95.0  603  90   1  61.0  66.0  50.0  696  52  79   2.0  46.0   1.0  217   7  58  29.0  87.0   7.0  49</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.notnull())</span><br><span class="line"><span class="built_in">print</span>(df.notnull().<span class="built_in">all</span>(axis=<span class="number">1</span>)) <span class="comment"># all:用来检测行或列中是否存在False,如果全为True返回True否则返回False</span></span><br><span class="line"><span class="built_in">print</span>(df.loc[df.notnull().<span class="built_in">all</span>(axis=<span class="number">1</span>)]) <span class="comment"># 以True为索引即忽略了含有缺失值的行</span></span><br></pre></td></tr></table></figure><pre><code>      0     1      2      3      4     50  True  True   True   True   True  True1  True  True   True   True   True  True2  True  True   True  False   True  True3  True  True   True   True   True  True4  True  True   True   True  False  True5  True  True  False   True   True  True6  True  True   True   True   True  True7  True  True   True   True   True  True0     True1     True2    False3     True4    False5    False6     True7     Truedtype: bool    0   1     2     3     4   50  44  13  76.0  12.0  75.0  271   7  67  62.0  46.0  95.0  603  90   1  61.0  66.0  50.0  696  52  79   2.0  46.0   1.0  217   7  58  29.0  87.0   7.0  49</code></pre><ul><li><p>方式2：</p><ul><li>dropna:可以直接将缺失的行或者列进行删除</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.dropna(axis=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(df.dropna(axis=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><pre><code>    0   1     2     3     4   50  44  13  76.0  12.0  75.0  271   7  67  62.0  46.0  95.0  603  90   1  61.0  66.0  50.0  696  52  79   2.0  46.0   1.0  217   7  58  29.0  87.0   7.0  49    0   1   50  44  13  271   7  67  602  88  31  333  90   1  694  54  78  195  97   7  906  52  79  217   7  58  49</code></pre><ul><li>对缺失值进行覆盖<ul><li>fillna</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.fillna(value=<span class="number">666</span>)) <span class="comment"># 使用设定值覆盖缺失值，但合理性不足意义不大</span></span><br><span class="line"><span class="built_in">print</span>(df.fillna(method=<span class="string">&#x27;ffill&#x27;</span>,axis=<span class="number">1</span>)) <span class="comment"># 一般采用缺失值周围临近的值去覆盖,ffill使用前值覆盖bfill使用后值覆盖，axis选择水平或垂直方向</span></span><br><span class="line"><span class="built_in">print</span>(df.fillna(method=<span class="string">&#x27;bfill&#x27;</span>,axis=<span class="number">0</span>)) <span class="comment"># 使用垂直方向的后值覆盖</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">但无论如何覆盖都不是最合理的，故一般选择删除而不选择覆盖，假如删除的成本太高（删除数据太多），才选择覆盖</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><pre><code>    0   1      2      3      4   50  44  13   76.0   12.0   75.0  271   7  67   62.0   46.0   95.0  602  88  31    2.0  666.0   18.0  333  90   1   61.0   66.0   50.0  694  54  78   65.0   31.0  666.0  195  97   7  666.0   37.0   26.0  906  52  79    2.0   46.0    1.0  217   7  58   29.0   87.0    7.0  49      0     1     2     3     4     50  44.0  13.0  76.0  12.0  75.0  27.01   7.0  67.0  62.0  46.0  95.0  60.02  88.0  31.0   2.0   2.0  18.0  33.03  90.0   1.0  61.0  66.0  50.0  69.04  54.0  78.0  65.0  31.0  31.0  19.05  97.0   7.0   7.0  37.0  26.0  90.06  52.0  79.0   2.0  46.0   1.0  21.07   7.0  58.0  29.0  87.0   7.0  49.0    0   1     2     3     4   50  44  13  76.0  12.0  75.0  271   7  67  62.0  46.0  95.0  602  88  31   2.0  66.0  18.0  333  90   1  61.0  66.0  50.0  694  54  78  65.0  31.0  26.0  195  97   7   2.0  37.0  26.0  906  52  79   2.0  46.0   1.0  217   7  58  29.0  87.0   7.0  49</code></pre><ul><li>实例<ul><li>处理丢失数据和空值</li><li>此处所用数据集在文章末尾给出</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df2 = pd.read_excel(<span class="string">&#x27;testData.xlsx&#x27;</span>,engine=<span class="string">&#x27;openpyxl&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(df2.head())</span><br><span class="line">df2 = df2[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]]</span><br><span class="line">df2.head()</span><br></pre></td></tr></table></figure><pre><code>                 time  none     1     2     3     4  none1     5     6     70 2019-01-27 17:00:00   NaN -24.8 -18.2 -20.8 -18.8    NaN   NaN   NaN   NaN1 2019-01-27 17:01:00   NaN -23.5 -18.8 -20.5 -19.8    NaN -15.2 -14.5 -16.02 2019-01-27 17:02:00   NaN -23.2 -19.2   NaN   NaN    NaN -13.0   NaN -14.03 2019-01-27 17:03:00   NaN -22.8 -19.2 -20.0 -20.5    NaN   NaN -12.2  -9.84 2019-01-27 17:04:00   NaN -23.2 -18.5 -20.0 -18.8    NaN -10.2 -10.8  -8.8C:\Users\86156\.conda\envs\DL\lib\site-packages\openpyxl\worksheet\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed  warn(msg)</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>-24.8</td>      <td>-18.2</td>      <td>-20.8</td>      <td>-18.8</td>    </tr>    <tr>      <th>1</th>      <td>-23.5</td>      <td>-18.8</td>      <td>-20.5</td>      <td>-19.8</td>    </tr>    <tr>      <th>2</th>      <td>-23.2</td>      <td>-19.2</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>3</th>      <td>-22.8</td>      <td>-19.2</td>      <td>-20.0</td>      <td>-20.5</td>    </tr>    <tr>      <th>4</th>      <td>-23.2</td>      <td>-18.5</td>      <td>-20.0</td>      <td>-18.8</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可将空值对应的行数据删除</span></span><br><span class="line"><span class="built_in">print</span>(df2.dropna(axis=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(df2.notnull().<span class="built_in">all</span>(axis=<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(df2.loc[df2.notnull().<span class="built_in">all</span>(axis=<span class="number">1</span>)])</span><br></pre></td></tr></table></figure><pre><code>         1     2     3     40    -24.8 -18.2 -20.8 -18.81    -23.5 -18.8 -20.5 -19.83    -22.8 -19.2 -20.0 -20.54    -23.2 -18.5 -20.0 -18.87    -24.8 -18.0 -17.5 -17.2...    ...   ...   ...   ...1055 -26.2 -27.2 -28.8 -27.51056 -26.8 -27.5 -29.0 -27.81057 -27.2 -27.8 -29.0 -28.01058 -27.5 -27.0 -29.0 -28.01059 -27.0 -27.2 -29.0 -27.8[982 rows x 4 columns]0        True1        True2       False3        True4        True        ...  1055     True1056     True1057     True1058     True1059     TrueLength: 1060, dtype: bool         1     2     3     40    -24.8 -18.2 -20.8 -18.81    -23.5 -18.8 -20.5 -19.83    -22.8 -19.2 -20.0 -20.54    -23.2 -18.5 -20.0 -18.87    -24.8 -18.0 -17.5 -17.2...    ...   ...   ...   ...1055 -26.2 -27.2 -28.8 -27.51056 -26.8 -27.5 -29.0 -27.81057 -27.2 -27.8 -29.0 -28.01058 -27.5 -27.0 -29.0 -28.01059 -27.0 -27.2 -29.0 -27.8[982 rows x 4 columns]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 填充空值</span></span><br><span class="line">data = df2.fillna(method=<span class="string">&#x27;ffill&#x27;</span>,axis=<span class="number">0</span>).fillna(method=<span class="string">&#x27;bfill&#x27;</span>,axis=<span class="number">0</span>)  <span class="comment"># 前部填充一次再候补填充一次确保开头和结尾没有缺失值</span></span><br><span class="line"><span class="built_in">print</span>(data.isnull().<span class="built_in">any</span>(axis=<span class="number">0</span>))    <span class="comment"># 检测下是否填充完整，any检查是否有True，此处4列中均无True故返回False</span></span><br></pre></td></tr></table></figure><pre><code>1    False2    False3    False4    Falsedtype: bool</code></pre><h1 id="处理重复数据"><a href="#处理重复数据" class="headerlink" title="处理重复数据"></a>处理重复数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成一组带有重复数据的数据源</span></span><br><span class="line">df3 = DataFrame(np.random.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">8</span>,<span class="number">4</span>)))</span><br><span class="line">df3.iloc[<span class="number">2</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">df3.iloc[<span class="number">5</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(df3)</span><br></pre></td></tr></table></figure><pre><code>    0   1   2   30  77  77  99  271  70  38  58  772   0   0   0   03  93  73  10   84  66  45  98  295   0   0   0   06  14  40  61  817  67  10  92  42</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用drop_duplicates</span></span><br><span class="line"><span class="built_in">print</span>(df3.drop_duplicates(keep=<span class="string">&#x27;first&#x27;</span>))    <span class="comment"># keep为保留第几条重复数据，也可使用last保留最后一条</span></span><br><span class="line"><span class="built_in">print</span>(df3.drop_duplicates(keep=<span class="literal">False</span>))    <span class="comment"># keep=False,删除所有重复数据</span></span><br></pre></td></tr></table></figure><pre><code>    0   1   2   30  77  77  99  271  70  38  58  772   0   0   0   03  93  73  10   84  66  45  98  296  14  40  61  817  67  10  92  42    0   1   2   30  77  77  99  271  70  38  58  773  93  73  10   84  66  45  98  296  14  40  61  817  67  10  92  42</code></pre><h1 id="处理异常数据"><a href="#处理异常数据" class="headerlink" title="处理异常数据"></a>处理异常数据</h1><ul><li>自定义一个1000行3列(A,B,C)取值范围为0-1的数据源，然后将C列中的值大于其两倍标准差的异常值进行清洗</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df4 = DataFrame(np.random.random(size=(<span class="number">1000</span>,<span class="number">3</span>)),columns=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df4)</span><br><span class="line"><span class="comment"># 判定异常值的条件</span></span><br><span class="line">twice_std = df4[<span class="string">&#x27;C&#x27;</span>].std() * <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(df4[<span class="string">&#x27;C&#x27;</span>] &gt; twice_std)  <span class="comment"># 此时True为异常值</span></span><br><span class="line"><span class="built_in">print</span>(~(df4[<span class="string">&#x27;C&#x27;</span>] &gt; twice_std))   <span class="comment"># 对其取反则False为异常值，使用True作为索引即可保留正常值</span></span><br><span class="line"><span class="built_in">print</span>(df4.loc[~(df4[<span class="string">&#x27;C&#x27;</span>] &gt; twice_std)])</span><br></pre></td></tr></table></figure><pre><code>            A         B         C0    0.215693  0.959250  0.5289531    0.136710  0.114971  0.9414492    0.295452  0.295154  0.2381883    0.187619  0.066753  0.9990184    0.398977  0.446377  0.432628..        ...       ...       ...995  0.908120  0.968931  0.765458996  0.649668  0.783493  0.058060997  0.605072  0.751010  0.243683998  0.304012  0.571452  0.004855999  0.364485  0.937335  0.601111[1000 rows x 3 columns]0      False1       True2      False3       True4      False       ...  995     True996    False997    False998    False999     TrueName: C, Length: 1000, dtype: bool0       True1      False2       True3      False4       True       ...  995    False996     True997     True998     True999    FalseName: C, Length: 1000, dtype: bool            A         B         C0    0.215693  0.959250  0.5289532    0.295452  0.295154  0.2381884    0.398977  0.446377  0.4326285    0.402174  0.704057  0.3276636    0.938079  0.919880  0.308305..        ...       ...       ...992  0.693904  0.050679  0.171809994  0.663767  0.883826  0.119215996  0.649668  0.783493  0.058060997  0.605072  0.751010  0.243683998  0.304012  0.571452  0.004855[574 rows x 3 columns]</code></pre><hr><p>本文提及的数据集下载地址：<br>链接：<a href="https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg">https://pan.baidu.com/s/1lhAiSXBw47MK9QdqwA05Lg</a><br>提取码：1111 </p><hr>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;处理丢失数据&quot;&gt;&lt;a href=&quot;#处理丢失数据&quot; class=&quot;headerlink&quot; title=&quot;处理丢失数据&quot;&gt;&lt;/a&gt;处理丢失数据&lt;/h1&gt;&lt;p&gt;1、原始数据中会存在缺失值（空值）&lt;br&gt;2、重复值&lt;br&gt;3、异常值  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有两种丢失数据  &lt;ul&gt;
&lt;li&gt;None  &lt;/li&gt;
&lt;li&gt;np.nan(NAN)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;&amp;#x27;&amp;#x27;&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;两种丢失数据的区别&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;&amp;#x27;&amp;#x27;&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;built_in&quot;&gt;type&lt;/span&gt;(&lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;))   &lt;span class=&quot;comment&quot;&gt;# None对象类型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;built_in&quot;&gt;type&lt;/span&gt;(np.nan)) &lt;span class=&quot;comment&quot;&gt;# NAN浮点型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;class &amp;#39;NoneType&amp;#39;&amp;gt;
&amp;lt;class &amp;#39;float&amp;#39;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>双均线策略制定</title>
    <link href="http://woody0819.github.io/2021/05/25/test_2/"/>
    <id>http://woody0819.github.io/2021/05/25/test_2/</id>
    <published>2021-05-25T12:27:32.017Z</published>
    <updated>2021-06-03T11:01:52.991Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求：双均线策略制定"><a href="#需求：双均线策略制定" class="headerlink" title="需求：双均线策略制定"></a>需求：双均线策略制定</h1><ul><li>使用tushare包获取某股票的历史行情数据  </li><li>计算该股票历史数据的5日均线和60日均线  <ul><li>什么是均线：  <ul><li>对于每一个交易日，都可以计算出前N天的移动平均值，然后把这些移动平均值连起来，成为一条线，就叫做N日移动平均线。移动平均线常用线有5天、10天、30天、60天、120天和240天的指标。  </li><li>5天和10天的是短线操作的参照指标，称作日均线指标；  </li><li>30天和60天的是中期均线指标，称作季均线指标；  </li><li>120天和240天的是长期均线指标，称作年均线指标。  </li></ul></li><li>均线计算方法：MA=(C1+C2+C3+…+Cn)/N    C:某日收盘价；N:移动平均周期（天数）</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">df = ts.get_k_data(code=&#x27;600519&#x27;,start=&#x27;2015-01-01&#x27;)</span></span><br><span class="line"><span class="string">df.to_csv(&#x27;moutai.csv&#x27;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;moutai.csv&#x27;</span>).drop(labels=<span class="string">&#x27;Unnamed: 0&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line">df[<span class="string">&#x27;date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;date&#x27;</span>])</span><br><span class="line">df.set_index(<span class="string">&#x27;date&#x27;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>open</th>      <th>close</th>      <th>high</th>      <th>low</th>      <th>volume</th>      <th>code</th>    </tr>    <tr>      <th>date</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>2015-01-05</th>      <td>161.056</td>      <td>172.013</td>      <td>173.474</td>      <td>160.266</td>      <td>94515.0</td>      <td>600519</td>    </tr>    <tr>      <th>2015-01-06</th>      <td>169.872</td>      <td>168.029</td>      <td>172.047</td>      <td>166.492</td>      <td>55020.0</td>      <td>600519</td>    </tr>    <tr>      <th>2015-01-07</th>      <td>166.509</td>      <td>163.876</td>      <td>169.448</td>      <td>161.370</td>      <td>54797.0</td>      <td>600519</td>    </tr>    <tr>      <th>2015-01-08</th>      <td>164.776</td>      <td>162.874</td>      <td>165.218</td>      <td>161.498</td>      <td>40525.0</td>      <td>600519</td>    </tr>    <tr>      <th>2015-01-09</th>      <td>161.719</td>      <td>161.642</td>      <td>166.280</td>      <td>161.472</td>      <td>53982.0</td>      <td>600519</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ma5 = df[<span class="string">&#x27;close&#x27;</span>].rolling(<span class="number">5</span>).mean()   <span class="comment"># rolling滑动窗口尺寸为5</span></span><br><span class="line">ma10 = df[<span class="string">&#x27;close&#x27;</span>].rolling(<span class="number">10</span>).mean()</span><br><span class="line">ma30 = df[<span class="string">&#x27;close&#x27;</span>].rolling(<span class="number">30</span>).mean()</span><br><span class="line">ma60 = df[<span class="string">&#x27;close&#x27;</span>].rolling(<span class="number">60</span>).mean()</span><br><span class="line">ma120 = df[<span class="string">&#x27;close&#x27;</span>].rolling(<span class="number">120</span>).mean()</span><br><span class="line">ma240 = df[<span class="string">&#x27;close&#x27;</span>].rolling(<span class="number">240</span>).mean()</span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.plot(ma5[<span class="number">110</span>:<span class="number">330</span>])</span><br><span class="line">plt.plot(ma30[<span class="number">110</span>:<span class="number">330</span>])</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x2a1aa5f9eb8&gt;]</code></pre><p><a href="https://imgtu.com/i/2325vj"><img src="https://z3.ax1x.com/2021/06/03/2325vj.jpg" alt="2325vj.jpg"></a></p><ul><li>分析输出所有金叉日期和死叉日期  <ul><li>股票分析技术中的金叉和死叉，可以简单解释为：  <ul><li>1.分析指标中的两根线，一根为短时间内的指标线，另一根为较长时间的指标线。  </li><li>2.如果短时间的指标线方向拐头向上，并且穿过了较长时间的指标线，这种状态叫“金叉”；  </li><li>3.如果短时间的指标线方向拐头向下，并且穿过了较长时间的指标线，这种状态叫“死叉”；  </li><li>4.一般情况下，出现金叉后，操作趋向买入；死叉则趋向卖出。当然，金叉和死叉只是分析指标之一，要和其他很多指标配合使用，才能增加操作的准确性。<br>参考讲解：<a href="https://www.bilibili.com/video/BV1Z64y1S7y3?p=15">https://www.bilibili.com/video/BV1Z64y1S7y3?p=15</a></li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ma5 = ma5[<span class="number">30</span>:]</span><br><span class="line">ma30 = ma30[<span class="number">30</span>:]</span><br><span class="line">df = df[<span class="number">30</span>:]</span><br><span class="line">s1 = ma5 &lt; ma30</span><br><span class="line">s2 = ma5 &gt; ma30</span><br><span class="line">death_ex = s1 &amp; s2.shift(<span class="number">1</span>) <span class="comment"># 判定死叉条件</span></span><br><span class="line">death_date = df.loc[death_ex].index   <span class="comment"># death_ex为Boolean型，用作索引直接提取True的对应行数据，再取行索引号即死叉对应日期</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;死叉日期：&#x27;</span>, death_date)</span><br><span class="line">golden_ex = ~(s1|s2.shift(<span class="number">1</span>))</span><br><span class="line">golden_date = df.loc[golden_ex].index</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;金叉日期：&#x27;</span>, golden_date)</span><br></pre></td></tr></table></figure><pre><code>死叉日期： DatetimeIndex([&#39;2015-06-17&#39;, &#39;2015-07-17&#39;, &#39;2015-09-28&#39;, &#39;2015-11-26&#39;,               &#39;2015-12-10&#39;, &#39;2016-01-05&#39;, &#39;2016-08-05&#39;, &#39;2016-08-18&#39;,               &#39;2016-11-21&#39;, &#39;2017-07-06&#39;, &#39;2017-09-08&#39;, &#39;2017-11-29&#39;,               &#39;2018-02-05&#39;, &#39;2018-03-27&#39;, &#39;2018-06-28&#39;, &#39;2018-07-23&#39;,               &#39;2018-07-31&#39;, &#39;2018-10-15&#39;, &#39;2018-12-25&#39;, &#39;2019-05-10&#39;,               &#39;2019-07-19&#39;, &#39;2019-11-28&#39;, &#39;2020-01-03&#39;, &#39;2020-02-28&#39;,               &#39;2020-03-18&#39;, &#39;2020-08-10&#39;, &#39;2020-09-21&#39;, &#39;2020-10-27&#39;,               &#39;2021-03-01&#39;, &#39;2021-04-15&#39;],              dtype=&#39;datetime64[ns]&#39;, name=&#39;date&#39;, freq=None)金叉日期： DatetimeIndex([&#39;2015-02-16&#39;, &#39;2015-07-15&#39;, &#39;2015-09-16&#39;, &#39;2015-10-09&#39;,               &#39;2015-12-03&#39;, &#39;2015-12-21&#39;, &#39;2016-02-22&#39;, &#39;2016-08-11&#39;,               &#39;2016-10-13&#39;, &#39;2016-11-25&#39;, &#39;2017-07-24&#39;, &#39;2017-09-18&#39;,               &#39;2017-12-15&#39;, &#39;2018-03-16&#39;, &#39;2018-05-09&#39;, &#39;2018-07-18&#39;,               &#39;2018-07-25&#39;, &#39;2018-09-20&#39;, &#39;2018-12-04&#39;, &#39;2019-01-03&#39;,               &#39;2019-06-14&#39;, &#39;2019-08-13&#39;, &#39;2020-01-02&#39;, &#39;2020-02-19&#39;,               &#39;2020-03-03&#39;, &#39;2020-04-02&#39;, &#39;2020-08-19&#39;, &#39;2020-10-14&#39;,               &#39;2020-11-05&#39;, &#39;2021-04-02&#39;, &#39;2021-04-16&#39;],              dtype=&#39;datetime64[ns]&#39;, name=&#39;date&#39;, freq=None)</code></pre><ul><li>如果从2017年1月1日开始，初始资金为10W元，金叉尽量买入，死叉全部卖出，则迄今为止炒股收益率如何？  <ul><li>1.买卖股票的单价使用开盘价  </li><li>2.买卖股票的时机  </li><li>3.最终手里会有剩余的股票没有卖出去（如果最有一次是金叉即买入没有卖出则出现剩余，需估量其价值，剩余股票单价使用最后一天的收盘价计算）</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l1 = pd.Series(<span class="number">1</span>,index=golden_date)    <span class="comment"># 1作为金叉标识</span></span><br><span class="line">l2 = pd.Series(<span class="number">0</span>,index=death_date) <span class="comment"># 0作为死叉标识</span></span><br><span class="line">l = l1.append(l2)</span><br><span class="line"><span class="built_in">print</span>(l)</span><br></pre></td></tr></table></figure><pre><code>date2015-02-16    12015-07-15    12015-09-16    12015-10-09    12015-12-03    1             ..2020-08-10    02020-09-21    02020-10-27    02021-03-01    02021-04-15    0Length: 61, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l = l.sort_index()  <span class="comment"># 根据日期排序即出现金叉死叉交错</span></span><br><span class="line"><span class="built_in">print</span>(l)</span><br><span class="line">l = l[<span class="string">&#x27;2017&#x27;</span>:<span class="string">&#x27;2021&#x27;</span>]    <span class="comment"># 根据需求切出2017年至今的金叉死叉</span></span><br><span class="line"><span class="built_in">print</span>(l)</span><br></pre></td></tr></table></figure><pre><code>date2015-02-16    12015-06-17    02015-07-15    12015-07-17    02015-09-16    1             ..2020-11-05    12021-03-01    02021-04-02    12021-04-15    02021-04-16    1Length: 61, dtype: int64date2017-07-06    02017-07-24    12017-09-08    02017-09-18    12017-11-29    02017-12-15    12018-02-05    02018-03-16    12018-03-27    02018-05-09    12018-06-28    02018-07-18    12018-07-23    02018-07-25    12018-07-31    02018-09-20    12018-10-15    02018-12-04    12018-12-25    02019-01-03    12019-05-10    02019-06-14    12019-07-19    02019-08-13    12019-11-28    02020-01-02    12020-01-03    02020-02-19    12020-02-28    02020-03-03    12020-03-18    02020-04-02    12020-08-10    02020-08-19    12020-09-21    02020-10-14    12020-10-27    02020-11-05    12021-03-01    02021-04-02    12021-04-15    02021-04-16    1dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">first_money = <span class="number">100000</span>    <span class="comment"># 本金不变</span></span><br><span class="line">money = first_money <span class="comment"># 可变，买股票花的钱和卖股票赚的钱都在该变量中操作</span></span><br><span class="line">hold = <span class="number">0</span>    <span class="comment"># 持有股票的数量（股数：100股=1手）</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(l)): </span><br><span class="line">    <span class="keyword">if</span> l[i] == <span class="number">1</span>:  <span class="comment"># 金叉时间，基于10W单价尽多买入</span></span><br><span class="line">        time = l.index[i]   <span class="comment"># 获取金叉时间</span></span><br><span class="line">        p = df.loc[time][<span class="string">&#x27;open&#x27;</span>]    <span class="comment"># 取出该时间对应的开盘价，即当前单价</span></span><br><span class="line">        hand_count = money // (p*<span class="number">100</span>)   <span class="comment"># 10W能买入多少手</span></span><br><span class="line">        hold = hand_count * <span class="number">100</span> <span class="comment"># 股数</span></span><br><span class="line">        money -= (hold*p)   <span class="comment"># 将买股票的钱从money中减去</span></span><br><span class="line">    <span class="keyword">else</span>:   <span class="comment"># 死叉时间，将买入的股票卖出去</span></span><br><span class="line">        death_time = l.index[i]</span><br><span class="line">        p_death = df.loc[death_time][<span class="string">&#x27;open&#x27;</span>]    <span class="comment"># 卖股票的单价</span></span><br><span class="line">        money += (p_death * hold)   <span class="comment"># 卖股票的收入加进money中</span></span><br><span class="line">        hold = <span class="number">0</span>    <span class="comment"># 股票卖出后，注意hold要清空</span></span><br><span class="line"><span class="comment"># 判定最后一次是金叉还是死叉可以判断l[i]最后一位是1还是0，但也可以使用hold判断，hold=0则最后一次为死叉反之金叉。</span></span><br><span class="line">last_money = hold * df[<span class="string">&#x27;close&#x27;</span>][-<span class="number">1</span>] <span class="comment"># 剩余股票的价值，若为金叉有剩余价值若为死叉该值为0，不用再进行判断直接加上即可。</span></span><br><span class="line"><span class="comment"># 总收益</span></span><br><span class="line">final_money = money + last_money - first_money</span><br><span class="line"><span class="built_in">print</span>(final_money)</span><br></pre></td></tr></table></figure><pre><code>198082.0</code></pre><ul><li>金融量化实用平台：聚宽joinQuant</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;需求：双均线策略制定&quot;&gt;&lt;a href=&quot;#需求：双均线策略制定&quot; class=&quot;headerlink&quot; title=&quot;需求：双均线策略制定&quot;&gt;&lt;/a&gt;需求：双均线策略制定&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;使用tushare包获取某股票的历史行情数据  &lt;/li&gt;
&lt;li&gt;计算该股票历史数据的5日均线和60日均线  &lt;ul&gt;
&lt;li&gt;什么是均线：  &lt;ul&gt;
&lt;li&gt;对于每一个交易日，都可以计算出前N天的移动平均值，然后把这些移动平均值连起来，成为一条线，就叫做N日移动平均线。移动平均线常用线有5天、10天、30天、60天、120天和240天的指标。  &lt;/li&gt;
&lt;li&gt;5天和10天的是短线操作的参照指标，称作日均线指标；  &lt;/li&gt;
&lt;li&gt;30天和60天的是中期均线指标，称作季均线指标；  &lt;/li&gt;
&lt;li&gt;120天和240天的是长期均线指标，称作年均线指标。  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;均线计算方法：MA=(C1+C2+C3+…+Cn)/N    C:某日收盘价；N:移动平均周期（天数）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; tushare &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; ts&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>股票分析</title>
    <link href="http://woody0819.github.io/2021/05/25/test_1/"/>
    <id>http://woody0819.github.io/2021/05/25/test_1/</id>
    <published>2021-05-25T12:27:30.944Z</published>
    <updated>2021-05-26T00:34:51.886Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求：股票分析"><a href="#需求：股票分析" class="headerlink" title="需求：股票分析"></a>需求：股票分析</h1><p>1.使用tushare包获取某股票的历史行情数据<br>2.输出该股票所有收盘比开盘上涨3%以上的日期<br>3.输出该股票所有开盘比前日收盘跌幅超2%的日期<br>4.假如从2017年1月1日开始，每月第一个交易日买入1手股票，每年最后一个交易日卖出所有股票，迄今为止收益如何？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = ts.get_k_data(code=<span class="string">&#x27;600519&#x27;</span>,start=<span class="string">&#x27;2015-01-01&#x27;</span>)</span><br><span class="line">df.to_csv(<span class="string">&#x27;moutai.csv&#x27;</span>)</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;moutai.csv&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><pre><code>本接口即将停止更新，请尽快使用Pro版接口：https://waditu.com/document/2</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Unnamed: 0</th>      <th>date</th>      <th>open</th>      <th>close</th>      <th>high</th>      <th>low</th>      <th>volume</th>      <th>code</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>2015-01-05</td>      <td>161.056</td>      <td>172.013</td>      <td>173.474</td>      <td>160.266</td>      <td>94515.0</td>      <td>600519</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>2015-01-06</td>      <td>169.872</td>      <td>168.029</td>      <td>172.047</td>      <td>166.492</td>      <td>55020.0</td>      <td>600519</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>2015-01-07</td>      <td>166.509</td>      <td>163.876</td>      <td>169.448</td>      <td>161.370</td>      <td>54797.0</td>      <td>600519</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>2015-01-08</td>      <td>164.776</td>      <td>162.874</td>      <td>165.218</td>      <td>161.498</td>      <td>40525.0</td>      <td>600519</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>2015-01-09</td>      <td>161.719</td>      <td>161.642</td>      <td>166.280</td>      <td>161.472</td>      <td>53982.0</td>      <td>600519</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.drop(labels=<span class="string">&#x27;Unnamed: 0&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>) <span class="comment"># drop中axis与常规相反,1是垂直方向，0是水平方向</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>date</th>      <th>open</th>      <th>close</th>      <th>high</th>      <th>low</th>      <th>volume</th>      <th>code</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>2015-01-05</td>      <td>161.056</td>      <td>172.013</td>      <td>173.474</td>      <td>160.266</td>      <td>94515.0</td>      <td>600519</td>    </tr>    <tr>      <th>1</th>      <td>2015-01-06</td>      <td>169.872</td>      <td>168.029</td>      <td>172.047</td>      <td>166.492</td>      <td>55020.0</td>      <td>600519</td>    </tr>    <tr>      <th>2</th>      <td>2015-01-07</td>      <td>166.509</td>      <td>163.876</td>      <td>169.448</td>      <td>161.370</td>      <td>54797.0</td>      <td>600519</td>    </tr>    <tr>      <th>3</th>      <td>2015-01-08</td>      <td>164.776</td>      <td>162.874</td>      <td>165.218</td>      <td>161.498</td>      <td>40525.0</td>      <td>600519</td>    </tr>    <tr>      <th>4</th>      <td>2015-01-09</td>      <td>161.719</td>      <td>161.642</td>      <td>166.280</td>      <td>161.472</td>      <td>53982.0</td>      <td>600519</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df[<span class="string">&#x27;date&#x27;</span>].dtype)</span><br><span class="line">df.info()   <span class="comment"># 查看每一列的数据类型</span></span><br></pre></td></tr></table></figure><pre><code>object&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1536 entries, 0 to 1535Data columns (total 7 columns): #   Column  Non-Null Count  Dtype  ---  ------  --------------  -----   0   date    1536 non-null   object  1   open    1536 non-null   float64 2   close   1536 non-null   float64 3   high    1536 non-null   float64 4   low     1536 non-null   float64 5   volume  1536 non-null   float64 6   code    1536 non-null   int64  dtypes: float64(5), int64(1), object(1)memory usage: 84.1+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;date&#x27;</span>]) <span class="comment"># 将日期时间转换为时间序列格式</span></span><br><span class="line">df.info()</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1536 entries, 0 to 1535Data columns (total 7 columns): #   Column  Non-Null Count  Dtype         ---  ------  --------------  -----          0   date    1536 non-null   datetime64[ns] 1   open    1536 non-null   float64        2   close   1536 non-null   float64        3   high    1536 non-null   float64        4   low     1536 non-null   float64        5   volume  1536 non-null   float64        6   code    1536 non-null   int64         dtypes: datetime64[ns](1), float64(5), int64(1)memory usage: 84.1 KB</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>date</th>      <th>open</th>      <th>close</th>      <th>high</th>      <th>low</th>      <th>volume</th>      <th>code</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>2015-01-05</td>      <td>161.056</td>      <td>172.013</td>      <td>173.474</td>      <td>160.266</td>      <td>94515.0</td>      <td>600519</td>    </tr>    <tr>      <th>1</th>      <td>2015-01-06</td>      <td>169.872</td>      <td>168.029</td>      <td>172.047</td>      <td>166.492</td>      <td>55020.0</td>      <td>600519</td>    </tr>    <tr>      <th>2</th>      <td>2015-01-07</td>      <td>166.509</td>      <td>163.876</td>      <td>169.448</td>      <td>161.370</td>      <td>54797.0</td>      <td>600519</td>    </tr>    <tr>      <th>3</th>      <td>2015-01-08</td>      <td>164.776</td>      <td>162.874</td>      <td>165.218</td>      <td>161.498</td>      <td>40525.0</td>      <td>600519</td>    </tr>    <tr>      <th>4</th>      <td>2015-01-09</td>      <td>161.719</td>      <td>161.642</td>      <td>166.280</td>      <td>161.472</td>      <td>53982.0</td>      <td>600519</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.set_index(<span class="string">&#x27;date&#x27;</span>,inplace=<span class="literal">True</span>)   <span class="comment"># set_index重新设置索引,inplace表示是否作用于源数据</span></span><br><span class="line">df.head()</span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><pre><code>                open     close      high       low   volume    codedate                                                               2015-01-05   161.056   172.013   173.474   160.266  94515.0  6005192015-01-06   169.872   168.029   172.047   166.492  55020.0  6005192015-01-07   166.509   163.876   169.448   161.370  54797.0  6005192015-01-08   164.776   162.874   165.218   161.498  40525.0  6005192015-01-09   161.719   161.642   166.280   161.472  53982.0  600519...              ...       ...       ...       ...      ...     ...2021-04-19  2055.000  2088.000  2098.360  2033.000  31754.0  6005192021-04-20  2071.100  2094.800  2129.000  2070.000  28290.0  6005192021-04-21  2076.000  2080.000  2097.800  2065.100  26150.0  6005192021-04-22  2089.900  2055.500  2099.000  2051.500  26850.0  6005192021-04-23  2055.970  2108.940  2119.880  2052.500  33463.0  600519[1536 rows x 6 columns]</code></pre><p>2.输出该股票所有收盘比开盘上涨3%以上的日期<br>（收盘-开盘）/开盘&gt;0.03</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(df[<span class="string">&#x27;close&#x27;</span>]-df[<span class="string">&#x27;open&#x27;</span>])/df[<span class="string">&#x27;open&#x27;</span>]&gt;<span class="number">0.03</span>    <span class="comment"># 返回应为boolean类型</span></span><br><span class="line">df.loc[(df[<span class="string">&#x27;close&#x27;</span>]-df[<span class="string">&#x27;open&#x27;</span>])/df[<span class="string">&#x27;open&#x27;</span>]&gt;<span class="number">0.03</span>]   <span class="comment"># 获取了True所对应的行数据</span></span><br><span class="line">df.loc[(df[<span class="string">&#x27;close&#x27;</span>]-df[<span class="string">&#x27;open&#x27;</span>])/df[<span class="string">&#x27;open&#x27;</span>]&gt;<span class="number">0.03</span>].index  <span class="comment"># 获取对应行的索引</span></span><br></pre></td></tr></table></figure><pre><code>DatetimeIndex([&#39;2015-01-05&#39;, &#39;2015-02-09&#39;, &#39;2015-03-09&#39;, &#39;2015-04-16&#39;,               &#39;2015-04-21&#39;, &#39;2015-05-08&#39;, &#39;2015-05-19&#39;, &#39;2015-05-22&#39;,               &#39;2015-05-25&#39;, &#39;2015-06-08&#39;, &#39;2015-06-23&#39;, &#39;2015-06-24&#39;,               &#39;2015-06-30&#39;, &#39;2015-07-08&#39;, &#39;2015-07-09&#39;, &#39;2015-07-10&#39;,               &#39;2015-08-25&#39;, &#39;2015-08-26&#39;, &#39;2015-08-27&#39;, &#39;2015-08-31&#39;,               &#39;2015-09-14&#39;, &#39;2015-11-30&#39;, &#39;2015-12-02&#39;, &#39;2015-12-21&#39;,               &#39;2016-01-14&#39;, &#39;2016-01-19&#39;, &#39;2016-03-04&#39;, &#39;2016-03-15&#39;,               &#39;2016-03-24&#39;, &#39;2016-04-06&#39;, &#39;2016-05-03&#39;, &#39;2016-05-31&#39;,               &#39;2016-06-03&#39;, &#39;2016-06-27&#39;, &#39;2016-07-06&#39;, &#39;2016-07-26&#39;,               &#39;2016-12-06&#39;, &#39;2017-01-04&#39;, &#39;2017-02-20&#39;, &#39;2017-04-25&#39;,               &#39;2017-08-14&#39;, &#39;2017-10-19&#39;, &#39;2017-10-27&#39;, &#39;2017-11-10&#39;,               &#39;2017-11-16&#39;, &#39;2017-11-28&#39;, &#39;2017-12-11&#39;, &#39;2017-12-28&#39;,               &#39;2018-01-09&#39;, &#39;2018-01-31&#39;, &#39;2018-04-19&#39;, &#39;2018-05-07&#39;,               &#39;2018-05-28&#39;, &#39;2018-06-04&#39;, &#39;2018-06-20&#39;, &#39;2018-08-09&#39;,               &#39;2018-08-21&#39;, &#39;2018-08-27&#39;, &#39;2018-09-18&#39;, &#39;2018-09-26&#39;,               &#39;2018-10-19&#39;, &#39;2018-10-31&#39;, &#39;2018-11-13&#39;, &#39;2018-12-28&#39;,               &#39;2019-01-15&#39;, &#39;2019-02-11&#39;, &#39;2019-03-01&#39;, &#39;2019-03-18&#39;,               &#39;2019-04-10&#39;, &#39;2019-04-16&#39;, &#39;2019-05-10&#39;, &#39;2019-05-15&#39;,               &#39;2019-06-11&#39;, &#39;2019-06-20&#39;, &#39;2019-09-12&#39;, &#39;2019-09-18&#39;,               &#39;2020-02-11&#39;, &#39;2020-03-02&#39;, &#39;2020-03-05&#39;, &#39;2020-03-10&#39;,               &#39;2020-04-02&#39;, &#39;2020-04-22&#39;, &#39;2020-05-06&#39;, &#39;2020-05-18&#39;,               &#39;2020-07-02&#39;, &#39;2020-07-06&#39;, &#39;2020-07-07&#39;, &#39;2020-07-13&#39;,               &#39;2020-12-30&#39;, &#39;2021-01-05&#39;, &#39;2021-01-12&#39;, &#39;2021-01-25&#39;,               &#39;2021-02-04&#39;, &#39;2021-02-09&#39;, &#39;2021-02-10&#39;, &#39;2021-03-03&#39;,               &#39;2021-03-05&#39;, &#39;2021-03-11&#39;, &#39;2021-04-02&#39;],              dtype=&#39;datetime64[ns]&#39;, name=&#39;date&#39;, freq=None)</code></pre><p>3.输出该股票所有开盘比前日收盘跌幅超2%的日期<br>（开盘-前日收盘）/前日收盘&lt;-0.02</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>open</th>      <th>close</th>      <th>high</th>      <th>low</th>      <th>volume</th>      <th>code</th>    </tr>    <tr>      <th>date</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>2015-01-05</th>      <td>161.056</td>      <td>172.013</td>      <td>173.474</td>      <td>160.266</td>      <td>94515.0</td>      <td>600519</td>    </tr>    <tr>      <th>2015-01-06</th>      <td>169.872</td>      <td>168.029</td>      <td>172.047</td>      <td>166.492</td>      <td>55020.0</td>      <td>600519</td>    </tr>    <tr>      <th>2015-01-07</th>      <td>166.509</td>      <td>163.876</td>      <td>169.448</td>      <td>161.370</td>      <td>54797.0</td>      <td>600519</td>    </tr>    <tr>      <th>2015-01-08</th>      <td>164.776</td>      <td>162.874</td>      <td>165.218</td>      <td>161.498</td>      <td>40525.0</td>      <td>600519</td>    </tr>    <tr>      <th>2015-01-09</th>      <td>161.719</td>      <td>161.642</td>      <td>166.280</td>      <td>161.472</td>      <td>53982.0</td>      <td>600519</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;close&#x27;</span>].shift(<span class="number">1</span>)    <span class="comment"># shift(1)使close整体下移一位,-1为上移；移动后两列相减即可实现开盘-前日收盘</span></span><br><span class="line">df.loc[(df[<span class="string">&#x27;open&#x27;</span>]-df[<span class="string">&#x27;close&#x27;</span>].shift(<span class="number">1</span>))/df[<span class="string">&#x27;close&#x27;</span>].shift(<span class="number">1</span>)&lt;-<span class="number">0.02</span>].index</span><br></pre></td></tr></table></figure><pre><code>DatetimeIndex([&#39;2015-01-19&#39;, &#39;2015-05-25&#39;, &#39;2015-07-03&#39;, &#39;2015-07-08&#39;,               &#39;2015-07-13&#39;, &#39;2015-08-24&#39;, &#39;2015-09-02&#39;, &#39;2015-09-15&#39;,               &#39;2017-11-17&#39;, &#39;2018-02-06&#39;, &#39;2018-02-09&#39;, &#39;2018-03-23&#39;,               &#39;2018-03-28&#39;, &#39;2018-07-11&#39;, &#39;2018-10-11&#39;, &#39;2018-10-24&#39;,               &#39;2018-10-25&#39;, &#39;2018-10-29&#39;, &#39;2018-10-30&#39;, &#39;2019-05-06&#39;,               &#39;2019-05-08&#39;, &#39;2019-10-16&#39;, &#39;2020-01-02&#39;, &#39;2020-02-03&#39;,               &#39;2020-03-13&#39;, &#39;2020-03-23&#39;, &#39;2020-10-26&#39;, &#39;2021-02-26&#39;,               &#39;2021-03-04&#39;],              dtype=&#39;datetime64[ns]&#39;, name=&#39;date&#39;, freq=None)</code></pre><p>4.假如从2017年1月1日开始，每月第一个交易日买入1手股票，每年最后一个交易日卖出所有股票，迄今为止收益如何？<br>①时间节点拆分：2017-2021<br>②一手股票：100股<br>③买股票：<br>    找出每个月第一个交易日–&gt;每月第一行数据(每年共1200股)<br> 卖股票：<br>    每年最后一个交易日将所有股票全部卖出（特殊情况：该分析进行时，当年买入的股票由于没到该年最后一天所以无法卖出）<br>    最后手中剩余的股票要估量其价值计算到总收益当中<br> 买卖股票的单价：可以开盘价为准</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">new_df = df[<span class="string">&#x27;2017-01&#x27;</span>:<span class="string">&#x27;2021-03&#x27;</span>]    <span class="comment"># 只有在索引为时间序列时才可如此切分（pd.to_datetime()）</span></span><br><span class="line"><span class="built_in">print</span>(new_df)</span><br><span class="line">new_df.resample(<span class="string">&#x27;M&#x27;</span>).first()    <span class="comment"># 根据月份重新取样;取每月的第一行数据;此处索引有问题但数据确为每月第一行</span></span><br><span class="line">df_monthly = new_df.resample(<span class="string">&#x27;M&#x27;</span>).first()</span><br><span class="line">cost = df_monthly[<span class="string">&#x27;open&#x27;</span>].<span class="built_in">sum</span>()*<span class="number">100</span> <span class="comment"># 总花费</span></span><br><span class="line"><span class="built_in">print</span>(cost)</span><br></pre></td></tr></table></figure><pre><code>                open     close      high       low   volume    codedate                                                               2017-01-03   324.689   324.961   327.331   323.261  20763.0  6005192017-01-04   325.019   341.813   342.066   325.000  65257.0  6005192017-01-05   339.958   336.792   341.366   335.529  41704.0  6005192017-01-06   336.694   340.696   349.457   336.170  68095.0  6005192017-01-09   337.821   338.511   342.755   336.597  35405.0  600519...              ...       ...       ...       ...      ...     ...2021-03-25  1970.010  1971.000  1988.880  1946.800  31575.0  6005192021-03-26  1985.000  2013.000  2022.000  1958.000  50016.0  6005192021-03-29  2043.200  2034.100  2096.350  2026.150  56992.0  6005192021-03-30  2040.000  2056.050  2086.000  2035.080  32627.0  6005192021-03-31  2045.100  2009.000  2046.020  2000.000  37154.0  600519[1032 rows x 6 columns]4817018.8</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df_yearly = new_df.resample(<span class="string">&#x27;A&#x27;</span>).last()[:-<span class="number">1</span>]   <span class="comment"># 最后2021年一行的数据需要忽略掉</span></span><br><span class="line"><span class="built_in">print</span>(df_yearly)</span><br><span class="line">resv = df_yearly[<span class="string">&#x27;open&#x27;</span>].<span class="built_in">sum</span>()*<span class="number">1200</span> <span class="comment"># 截止2020年末收益</span></span><br><span class="line">resv = <span class="number">300</span>*df[<span class="string">&#x27;close&#x27;</span>][-<span class="number">1</span>] + resv   <span class="comment"># 加上2021年前三个月的收益，该收益以昨日收盘价计价</span></span><br><span class="line">resv = resv-cost</span><br><span class="line"><span class="built_in">print</span>(resv)</span><br></pre></td></tr></table></figure><pre><code>                open     close      high       low   volume    codedate                                                               2017-12-31   707.948   687.725   716.329   681.918  76038.0  6005192018-12-31   563.300   590.010   596.400   560.000  63678.0  6005192019-12-31  1183.000  1183.000  1188.000  1176.510  22588.0  6005192020-12-31  1941.000  1998.000  1998.980  1939.000  38860.0  6005191089960.7999999998</code></pre>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;需求：股票分析&quot;&gt;&lt;a href=&quot;#需求：股票分析&quot; class=&quot;headerlink&quot; title=&quot;需求：股票分析&quot;&gt;&lt;/a&gt;需求：股票分析&lt;/h1&gt;&lt;p&gt;1.使用tushare包获取某股票的历史行情数据&lt;br&gt;2.输出该股票所有收盘比开盘上涨3%以上的日期&lt;br&gt;3.输出该股票所有开盘比前日收盘跌幅超2%的日期&lt;br&gt;4.假如从2017年1月1日开始，每月第一个交易日买入1手股票，每年最后一个交易日卖出所有股票，迄今为止收益如何？&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; tushare &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; ts&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="数据分析" scheme="http://woody0819.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
    <category term="学习笔记" scheme="http://woody0819.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
